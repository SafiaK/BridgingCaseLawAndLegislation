{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Handler for Legal Text Analysis\n",
    "\n",
    "This notebook implements experiments to measure the F1 score of law application detection and the accuracy of legal phrase extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.getcwd())  # Add current directory to Python path\n",
    "\n",
    "# Standard library imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import functions from experiment_utils.py\n",
    "from experiment_utils import (\n",
    "    load_csv_files,\n",
    "    prepare_training_data,\n",
    "    run_experiment,\n",
    "    calculate_metrics,\n",
    "    generate_experiment_report,\n",
    "    visualize_results,\n",
    "    process_legislation_references,\n",
    "    extract_legislation_references,\n",
    "    downloadThelegislationIfNotExist,\n",
    "    measure_phrase_extraction_accuracy,\n",
    "    run_full_case_experiment\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation\n",
    "\n",
    "In this step, we prepare the training and testing files for our experiments. We'll use false positives as negative examples and false negatives as positive examples. For each case law, we'll use it as testing data and all other case laws as training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "notebook_dir = os.path.abspath('..')\n",
    "print(notebook_dir)\n",
    "input_folder_path = os.path.join(notebook_dir, 'data/test2/csv_cases/Experiment1-byPara')\n",
    "output_folder_path = os.path.join(notebook_dir, 'data/test3')\n",
    "training_data_path = os.path.join(notebook_dir, 'data/test2/training_data')\n",
    "false_positives_path = os.path.join(notebook_dir, 'data/test2/csv_cases/Experiment2-fullcaselaw/false_positives.csv')\n",
    "false_negatives_path = os.path.join(notebook_dir, 'data/test2/csv_cases/Experiment2-fullcaselaw/false_negatives.csv')\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "os.makedirs(training_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ewca_civ_2025_215 with 46 rows\n",
      "Loaded ewhc_scco_2025_374 with 16 rows\n",
      "Loaded ukftt_grc_2025_287 with 45 rows\n",
      "Loaded ukftt_grc_2025_251 with 57 rows\n",
      "Loaded ukftt_grc_2025_284 with 45 rows\n",
      "Loaded ukftt_grc_2025_282 with 14 rows\n",
      "Loaded ukftt_grc_2025_283 with 39 rows\n",
      "Loaded eat_2025_29 with 57 rows\n",
      "Loaded 8 case files\n"
     ]
    }
   ],
   "source": [
    "# Load all CSV files from the input folder\n",
    "case_files = load_csv_files(input_folder_path)\n",
    "print(f\"Loaded {len(case_files)} case files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ewca_civ_2025_215',\n",
       " 'ewhc_scco_2025_374',\n",
       " 'ukftt_grc_2025_287',\n",
       " 'ukftt_grc_2025_251',\n",
       " 'ukftt_grc_2025_284',\n",
       " 'ukftt_grc_2025_282',\n",
       " 'ukftt_grc_2025_283',\n",
       " 'eat_2025_29']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(case_files.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21 false positives\n",
      "Loaded 3 false negatives\n"
     ]
    }
   ],
   "source": [
    "# Load false positives and false negatives\n",
    "try:\n",
    "    false_positives_df = pd.read_csv(false_positives_path)\n",
    "    print(f\"Loaded {len(false_positives_df)} false positives\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading false positives: {str(e)}\")\n",
    "    false_positives_df = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    false_negatives_df = pd.read_csv(false_negatives_path)\n",
    "    print(f\"Loaded {len(false_negatives_df)} false negatives\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading false negatives: {str(e)}\")\n",
    "    false_negatives_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing training data for test case: ewca_civ_2025_215\n",
      "Initial training data: 3 positive, 18 negative\n",
      "para_13\n",
      "para_14\n",
      "para_15\n",
      "para_32\n",
      "para_33\n",
      "para_35\n",
      "para_42\n",
      "para_43\n",
      "para_44\n",
      "para_45\n",
      "para_46\n",
      "para_47\n",
      "para_48\n",
      "para_36\n",
      "para_37\n",
      "Final training data: 18 positive, 18 negative\n",
      "Saved training data to /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/training_data/ewca_civ_2025_215_training.json\n",
      "\n",
      "Preparing training data for test case: ewhc_scco_2025_374\n",
      "Initial training data: 3 positive, 21 negative\n",
      "para_15\n",
      "para_20\n",
      "para_25\n",
      "para_26\n",
      "para_32\n",
      "para_33\n",
      "para_35\n",
      "para_42\n",
      "para_43\n",
      "para_44\n",
      "para_45\n",
      "para_46\n",
      "para_47\n",
      "para_48\n",
      "para_36\n",
      "para_37\n",
      "para_12\n",
      "para_13\n",
      "Final training data: 21 positive, 21 negative\n",
      "Saved training data to /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/training_data/ewhc_scco_2025_374_training.json\n",
      "\n",
      "Preparing training data for test case: ukftt_grc_2025_287\n",
      "Initial training data: 2 positive, 18 negative\n",
      "para_15\n",
      "para_20\n",
      "para_25\n",
      "para_26\n",
      "para_13\n",
      "para_14\n",
      "para_15\n",
      "para_42\n",
      "para_43\n",
      "para_44\n",
      "para_45\n",
      "para_46\n",
      "para_47\n",
      "para_48\n",
      "para_36\n",
      "para_37\n",
      "Final training data: 18 positive, 18 negative\n",
      "Saved training data to /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/training_data/ukftt_grc_2025_287_training.json\n",
      "\n",
      "Preparing training data for test case: ukftt_grc_2025_251\n",
      "Initial training data: 2 positive, 19 negative\n",
      "para_15\n",
      "para_20\n",
      "para_25\n",
      "para_26\n",
      "para_13\n",
      "para_14\n",
      "para_15\n",
      "para_32\n",
      "para_33\n",
      "para_35\n",
      "para_36\n",
      "para_37\n",
      "para_12\n",
      "para_13\n",
      "para_35\n",
      "para_36\n",
      "para_37\n",
      "Final training data: 19 positive, 19 negative\n",
      "Saved training data to /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/training_data/ukftt_grc_2025_251_training.json\n",
      "\n",
      "Preparing training data for test case: ukftt_grc_2025_284\n",
      "Initial training data: 3 positive, 19 negative\n",
      "para_15\n",
      "para_20\n",
      "para_25\n",
      "para_26\n",
      "para_13\n",
      "para_14\n",
      "para_15\n",
      "para_32\n",
      "para_33\n",
      "para_35\n",
      "para_42\n",
      "para_43\n",
      "para_44\n",
      "para_45\n",
      "para_46\n",
      "para_47\n",
      "Final training data: 19 positive, 19 negative\n",
      "Saved training data to /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/training_data/ukftt_grc_2025_284_training.json\n",
      "\n",
      "Preparing training data for test case: ukftt_grc_2025_282\n",
      "Initial training data: 3 positive, 20 negative\n",
      "para_15\n",
      "para_20\n",
      "para_25\n",
      "para_26\n",
      "para_13\n",
      "para_14\n",
      "para_15\n",
      "para_32\n",
      "para_33\n",
      "para_35\n",
      "para_42\n",
      "para_43\n",
      "para_44\n",
      "para_45\n",
      "para_46\n",
      "para_47\n",
      "para_48\n",
      "Final training data: 20 positive, 20 negative\n",
      "Saved training data to /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/training_data/ukftt_grc_2025_282_training.json\n",
      "\n",
      "Preparing training data for test case: ukftt_grc_2025_283\n",
      "Initial training data: 2 positive, 19 negative\n",
      "para_15\n",
      "para_20\n",
      "para_25\n",
      "para_26\n",
      "para_13\n",
      "para_14\n",
      "para_15\n",
      "para_32\n",
      "para_33\n",
      "para_35\n",
      "para_42\n",
      "para_43\n",
      "para_44\n",
      "para_45\n",
      "para_46\n",
      "para_47\n",
      "para_48\n",
      "Final training data: 19 positive, 19 negative\n",
      "Saved training data to /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/training_data/ukftt_grc_2025_283_training.json\n",
      "\n",
      "Preparing training data for test case: eat_2025_29\n",
      "Initial training data: 3 positive, 13 negative\n",
      "para_15\n",
      "para_20\n",
      "para_25\n",
      "para_26\n",
      "para_13\n",
      "para_14\n",
      "para_15\n",
      "para_32\n",
      "para_33\n",
      "para_35\n",
      "Final training data: 13 positive, 13 negative\n",
      "Saved training data to /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/training_data/eat_2025_29_training.json\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data for each case\n",
    "#read data/test2/testing-data.json and data/test2/training-data.json\n",
    "#combine them into one json file\n",
    "with open(os.path.join(notebook_dir, 'data/test2/testing-data.json'), 'r') as f:\n",
    "    testing_data = json.load(f)\n",
    "\n",
    "with open(os.path.join(notebook_dir, 'data/test2/training-data.json'), 'r') as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "# combine testing and training\n",
    "all_cases_data = testing_data + training_data\n",
    "\n",
    "#convert all_cases_data_list to dictionary by picking by para_id from each json object and making it a key in the dictionary\n",
    "all_cases_data_dict = {case[\"para_id\"]: case for case in all_cases_data}\n",
    "\n",
    "\n",
    "for test_case_name in case_files.keys():\n",
    "    print(f\"\\nPreparing training data for test case: {test_case_name}\")\n",
    "    training_examples = prepare_training_data(case_files, test_case_name, false_positives_df, false_negatives_df,all_cases_data_dict)\n",
    "    \n",
    "    # Save training data to JSON file\n",
    "    training_file_path = os.path.join(training_data_path, f\"{test_case_name}_training.json\")\n",
    "    with open(training_file_path, 'w') as f:\n",
    "        json.dump(training_examples, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved training data to {training_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run Experiments and Measure F1 Scores\n",
    "\n",
    "In this step, we run the experiments using the training data prepared in Step 1. We'll use different LLMs (Claude, GPT-4o, GPT-4o-mini, and Llama-70B) and measure the F1 scores for each case law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment paths\n",
    "experiment_folder_path = os.path.join(notebook_dir, 'data/test2/Experiment1')\n",
    "os.makedirs(experiment_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for ewca_civ_2025_215 with gpt-4o-mini\n",
      "===========processing ewca_civ_2025_215 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini'],\n",
      "      dtype='object')\n",
      "Running experiment for ewca_civ_2025_215 with gpt-4o\n",
      "===========processing ewca_civ_2025_215 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o'],\n",
      "      dtype='object')\n",
      "Running experiment for ewca_civ_2025_215 with llama-3.3-70b-versatile\n",
      "===========processing ewca_civ_2025_215 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o',\n",
      "       'if_law_applied_llama-3.3-70b-versatile',\n",
      "       'application_of_law_phrases_llama-3.3-70b-versatile',\n",
      "       'reason_llama-3.3-70b-versatile'],\n",
      "      dtype='object')\n",
      "Running experiment for ewhc_scco_2025_374 with gpt-4o-mini\n",
      "===========processing ewhc_scco_2025_374 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini'],\n",
      "      dtype='object')\n",
      "Running experiment for ewhc_scco_2025_374 with gpt-4o\n",
      "===========processing ewhc_scco_2025_374 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o'],\n",
      "      dtype='object')\n",
      "Running experiment for ewhc_scco_2025_374 with llama-3.3-70b-versatile\n",
      "===========processing ewhc_scco_2025_374 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o',\n",
      "       'if_law_applied_llama-3.3-70b-versatile',\n",
      "       'application_of_law_phrases_llama-3.3-70b-versatile',\n",
      "       'reason_llama-3.3-70b-versatile'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_287 with gpt-4o-mini\n",
      "===========processing ukftt_grc_2025_287 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_287 with gpt-4o\n",
      "===========processing ukftt_grc_2025_287 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_287 with llama-3.3-70b-versatile\n",
      "===========processing ukftt_grc_2025_287 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Error in batch processing, processing individually\n",
      "Invalid json output: ```\n",
      "{\n",
      "  \"para_id\": \"para_8\",\n",
      "  \"if_law_applied\": 1,\n",
      "  \"application_of_law_phrases\": [\n",
      "    \"The Commissioner considered that disclosure of the withheld information would more likely than not adversely affect the course of justice, because it would involve public access to privileged information when the matters to which the information relate were still \\x92live\\x92\"\n",
      "  ],\n",
      "  \"reason\": \"The Commissioner applied the law by considering the potential impact of disclosure on the course of justice, specifically the effect of revealing privileged information on ongoing proceedings.\"\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "starting again...\n",
      "Error in batch processing, processing individually\n",
      "Invalid json output: ```\n",
      "{\n",
      "  \"para_id\": \"para_37\",\n",
      "  \"if_law_applied\": true,\n",
      "  \"application_of_law_phrases\": [\n",
      "    \"There would be an even stronger public interest in maintaining the exception where the matter to which the advice relates was \\x91live\\x92 at the relevant date.\"\n",
      "  ],\n",
      "  \"reason\": \"The paragraph applies the law by considering the public interest in maintaining the exception for legal advice, particularly when the matter is still 'live' and there is a risk of future litigation.\"\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o',\n",
      "       'if_law_applied_llama-3.3-70b-versatile',\n",
      "       'application_of_law_phrases_llama-3.3-70b-versatile',\n",
      "       'reason_llama-3.3-70b-versatile'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_251 with gpt-4o-mini\n",
      "===========processing ukftt_grc_2025_251 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_251 with gpt-4o\n",
      "===========processing ukftt_grc_2025_251 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_251 with llama-3.3-70b-versatile\n",
      "===========processing ukftt_grc_2025_251 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Error in batch processing, processing individually\n",
      "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j5z5wmdgfj1t5r5y0pt0gans` service tier `on_demand` on tokens per minute (TPM): Limit 300000, Used 335316, Requested 9840. Please try again in 9.0312s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error in individuall processing as well\n",
      "Invalid json output: para_id: para_38\n",
      "if_law_applied: 1\n",
      "application_of_law_phrases: [\"The burden imposed on the public authority by the request\", \"The motive of the requester\", \"The value or serious purpose\", \"Any harassment of, or distress caused to, the public authority’s staff\"]\n",
      "reason: The paragraph applies the law by setting out four non-exhaustive broad issues which can be helpful in assessing whether a request is vexatious, as outlined by the UT.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o',\n",
      "       'if_law_applied_llama-3.3-70b-versatile',\n",
      "       'application_of_law_phrases_llama-3.3-70b-versatile',\n",
      "       'reason_llama-3.3-70b-versatile'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_284 with gpt-4o-mini\n",
      "===========processing ukftt_grc_2025_284 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_284 with gpt-4o\n",
      "===========processing ukftt_grc_2025_284 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_284 with llama-3.3-70b-versatile\n",
      "===========processing ukftt_grc_2025_284 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Error in batch processing, processing individually\n",
      "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j5z5wmdgfj1t5r5y0pt0gans` service tier `on_demand` on tokens per minute (TPM): Limit 300000, Used 306711, Requested 10339. Please try again in 3.41s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o',\n",
      "       'if_law_applied_llama-3.3-70b-versatile',\n",
      "       'application_of_law_phrases_llama-3.3-70b-versatile',\n",
      "       'reason_llama-3.3-70b-versatile'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_282 with gpt-4o-mini\n",
      "===========processing ukftt_grc_2025_282 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_282 with gpt-4o\n",
      "===========processing ukftt_grc_2025_282 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_282 with llama-3.3-70b-versatile\n",
      "===========processing ukftt_grc_2025_282 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o',\n",
      "       'if_law_applied_llama-3.3-70b-versatile',\n",
      "       'application_of_law_phrases_llama-3.3-70b-versatile',\n",
      "       'reason_llama-3.3-70b-versatile'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_283 with gpt-4o-mini\n",
      "===========processing ukftt_grc_2025_283 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_283 with gpt-4o\n",
      "===========processing ukftt_grc_2025_283 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o'],\n",
      "      dtype='object')\n",
      "Running experiment for ukftt_grc_2025_283 with llama-3.3-70b-versatile\n",
      "===========processing ukftt_grc_2025_283 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Error in batch processing, processing individually\n",
      "Invalid json output: The assistant \n",
      "\n",
      "The: \"application_of_risk: \"application of law\"\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o',\n",
      "       'if_law_applied_llama-3.3-70b-versatile',\n",
      "       'application_of_law_phrases_llama-3.3-70b-versatile',\n",
      "       'reason_llama-3.3-70b-versatile'],\n",
      "      dtype='object')\n",
      "Running experiment for eat_2025_29 with gpt-4o-mini\n",
      "===========processing eat_2025_29 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini'],\n",
      "      dtype='object')\n",
      "Running experiment for eat_2025_29 with gpt-4o\n",
      "===========processing eat_2025_29 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o'],\n",
      "      dtype='object')\n",
      "Running experiment for eat_2025_29 with llama-3.3-70b-versatile\n",
      "===========processing eat_2025_29 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Error in batch processing, processing individually\n",
      "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j5z5wmdgfj1t5r5y0pt0gans` service tier `on_demand` on tokens per minute (TPM): Limit 300000, Used 317379, Requested 7074. Please try again in 4.8906s. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "starting again...\n",
      "Error in batch processing, processing individually\n",
      "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j5z5wmdgfj1t5r5y0pt0gans` service tier `on_demand` on tokens per minute (TPM): Limit 300000, Used 295704, Requested 7138. Please try again in 568.4ms. Need more tokens? Visit https://groq.com/self-serve-support/ to request higher limits.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Done\n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references',\n",
      "       'if_law_applied_actual', 'application_of_law_phrases_actual',\n",
      "       'if_law_applied_gpt-4o-mini', 'application_of_law_phrases_gpt-4o-mini',\n",
      "       'reason_gpt-4o-mini', 'if_law_applied_gpt-4o',\n",
      "       'application_of_law_phrases_gpt-4o', 'reason_gpt-4o',\n",
      "       'if_law_applied_llama-3.3-70b-versatile',\n",
      "       'application_of_law_phrases_llama-3.3-70b-versatile',\n",
      "       'reason_llama-3.3-70b-versatile'],\n",
      "      dtype='object')\n",
      "Saved all experiment results to /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test3/experiment_results.json\n"
     ]
    }
   ],
   "source": [
    "# Define models to test\n",
    "models = ['gpt-4o-mini','gpt-4o','llama-3.3-70b-versatile']\n",
    "input_folder_path = os.path.join(notebook_dir, 'data/test3')\n",
    "experiment_folder_path= os.path.join(notebook_dir, 'data/test3')\n",
    "# Run experiments for each case and model\n",
    "all_results = []\n",
    "\n",
    "for test_case_name in case_files.keys():\n",
    "    for model_name in models:\n",
    "        \n",
    "        result = run_experiment(test_case_name, model_name, training_data_path, input_folder_path, experiment_folder_path)\n",
    "        all_results.append(result)\n",
    "\n",
    "# Save all results to a JSON file\n",
    "results_file_path = os.path.join(experiment_folder_path, \"experiment_results.json\")\n",
    "with open(results_file_path, 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "\n",
    "print(f\"Saved all experiment results to {results_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Case</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewca_civ_2025_215</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewca_civ_2025_215</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewca_civ_2025_215</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewhc_scco_2025_374</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ewhc_scco_2025_374</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ewhc_scco_2025_374</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ukftt_grc_2025_287</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ukftt_grc_2025_287</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ukftt_grc_2025_287</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ukftt_grc_2025_251</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ukftt_grc_2025_251</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ukftt_grc_2025_251</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ukftt_grc_2025_284</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ukftt_grc_2025_284</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ukftt_grc_2025_284</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ukftt_grc_2025_282</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ukftt_grc_2025_282</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ukftt_grc_2025_282</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ukftt_grc_2025_283</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ukftt_grc_2025_283</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ukftt_grc_2025_283</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>eat_2025_29</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>eat_2025_29</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>eat_2025_29</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.340030</td>\n",
       "      <td>0.654266</td>\n",
       "      <td>0.397163</td>\n",
       "      <td>0.782987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Average</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.181373</td>\n",
       "      <td>0.554067</td>\n",
       "      <td>0.247962</td>\n",
       "      <td>0.612652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Average</td>\n",
       "      <td>llama-3.3-70b-versatile</td>\n",
       "      <td>0.214073</td>\n",
       "      <td>0.822421</td>\n",
       "      <td>0.327768</td>\n",
       "      <td>0.608999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Test Case                    Model  Precision    Recall  \\\n",
       "0    ewca_civ_2025_215              gpt-4o-mini   0.136364  0.750000   \n",
       "1    ewca_civ_2025_215                   gpt-4o   0.333333  0.750000   \n",
       "2    ewca_civ_2025_215  llama-3.3-70b-versatile   0.333333  1.000000   \n",
       "3   ewhc_scco_2025_374              gpt-4o-mini   0.500000  0.666667   \n",
       "4   ewhc_scco_2025_374                   gpt-4o   1.000000  0.666667   \n",
       "5   ewhc_scco_2025_374  llama-3.3-70b-versatile   0.375000  1.000000   \n",
       "6   ukftt_grc_2025_287              gpt-4o-mini   0.083333  0.666667   \n",
       "7   ukftt_grc_2025_287                   gpt-4o   0.000000  0.000000   \n",
       "8   ukftt_grc_2025_287  llama-3.3-70b-versatile   0.093750  1.000000   \n",
       "9   ukftt_grc_2025_251              gpt-4o-mini   0.363636  0.571429   \n",
       "10  ukftt_grc_2025_251                   gpt-4o   0.375000  0.428571   \n",
       "11  ukftt_grc_2025_251  llama-3.3-70b-versatile   0.315789  0.857143   \n",
       "12  ukftt_grc_2025_284              gpt-4o-mini   0.117647  1.000000   \n",
       "13  ukftt_grc_2025_284                   gpt-4o   0.142857  1.000000   \n",
       "14  ukftt_grc_2025_284  llama-3.3-70b-versatile   0.100000  1.000000   \n",
       "15  ukftt_grc_2025_282              gpt-4o-mini   0.000000  0.000000   \n",
       "16  ukftt_grc_2025_282                   gpt-4o   0.250000  0.500000   \n",
       "17  ukftt_grc_2025_282  llama-3.3-70b-versatile   0.142857  0.500000   \n",
       "18  ukftt_grc_2025_283              gpt-4o-mini   0.000000  0.000000   \n",
       "19  ukftt_grc_2025_283                   gpt-4o   0.333333  1.000000   \n",
       "20  ukftt_grc_2025_283  llama-3.3-70b-versatile   0.055556  0.333333   \n",
       "21         eat_2025_29              gpt-4o-mini   0.250000  0.777778   \n",
       "22         eat_2025_29                   gpt-4o   0.285714  0.888889   \n",
       "23         eat_2025_29  llama-3.3-70b-versatile   0.296296  0.888889   \n",
       "0              Average                   gpt-4o   0.340030  0.654266   \n",
       "1              Average              gpt-4o-mini   0.181373  0.554067   \n",
       "2              Average  llama-3.3-70b-versatile   0.214073  0.822421   \n",
       "\n",
       "    F1 Score  Accuracy  True Positives  False Positives  True Negatives  \\\n",
       "0   0.230769  0.565217             3.0             19.0            23.0   \n",
       "1   0.461538  0.847826             3.0              6.0            36.0   \n",
       "2   0.500000  0.826087             4.0              8.0            34.0   \n",
       "3   0.571429  0.812500             2.0              2.0            11.0   \n",
       "4   0.800000  0.937500             2.0              0.0            13.0   \n",
       "5   0.545455  0.687500             3.0              5.0             8.0   \n",
       "6   0.148148  0.488889             2.0             22.0            20.0   \n",
       "7   0.000000  0.711111             0.0             10.0            32.0   \n",
       "8   0.171429  0.355556             3.0             29.0            13.0   \n",
       "9   0.444444  0.824561             4.0              7.0            43.0   \n",
       "10  0.400000  0.842105             3.0              5.0            45.0   \n",
       "11  0.461538  0.750000             6.0             13.0            36.0   \n",
       "12  0.210526  0.666667             2.0             15.0            28.0   \n",
       "13  0.250000  0.733333             2.0             12.0            31.0   \n",
       "14  0.181818  0.590909             2.0             18.0            24.0   \n",
       "15  0.000000  0.357143             0.0              7.0             5.0   \n",
       "16  0.333333  0.714286             1.0              3.0             9.0   \n",
       "17  0.222222  0.500000             1.0              6.0             6.0   \n",
       "18  0.000000  0.589744             0.0             13.0            23.0   \n",
       "19  0.500000  0.846154             3.0              6.0            30.0   \n",
       "20  0.095238  0.512821             1.0             17.0            19.0   \n",
       "21  0.378378  0.596491             7.0             21.0            27.0   \n",
       "22  0.432432  0.631579             8.0             20.0            28.0   \n",
       "23  0.444444  0.649123             8.0             19.0            29.0   \n",
       "0   0.397163  0.782987             NaN              NaN             NaN   \n",
       "1   0.247962  0.612652             NaN              NaN             NaN   \n",
       "2   0.327768  0.608999             NaN              NaN             NaN   \n",
       "\n",
       "    False Negatives  \n",
       "0               1.0  \n",
       "1               1.0  \n",
       "2               0.0  \n",
       "3               1.0  \n",
       "4               1.0  \n",
       "5               0.0  \n",
       "6               1.0  \n",
       "7               3.0  \n",
       "8               0.0  \n",
       "9               3.0  \n",
       "10              4.0  \n",
       "11              1.0  \n",
       "12              0.0  \n",
       "13              0.0  \n",
       "14              0.0  \n",
       "15              2.0  \n",
       "16              1.0  \n",
       "17              1.0  \n",
       "18              3.0  \n",
       "19              0.0  \n",
       "20              2.0  \n",
       "21              2.0  \n",
       "22              1.0  \n",
       "23              1.0  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate and display experiment report\n",
    "report_df = generate_experiment_report(all_results)\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "visualize_results(report_df, experiment_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Process Legislation References and Extract Phrases\n",
    "\n",
    "In this step, we process legislation references from the case laws and extract key phrases that show how the law is applied. We'll also measure the accuracy of the extracted phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for legislation processing\n",
    "legislation_dir = os.path.join(notebook_dir, 'data/test2/csv_cases/legislation')\n",
    "temp_folder_path = os.path.join(notebook_dir, 'data/test2/csv_cases/temp')\n",
    "os.makedirs(legislation_dir, exist_ok=True)\n",
    "os.makedirs(temp_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process legislation references\n",
    "process_legislation_references(input_folder_path, legislation_dir, temp_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract phrases from case laws\n",
    "import keyPhraseExtractor\n",
    "\n",
    "case_act_pickle_file = os.path.join(temp_folder_path, 'cleaned_case_legislation_map.pkl')\n",
    "input_dir = temp_folder_path\n",
    "output_dir = os.path.join(temp_folder_path, 'output')\n",
    "output_folder_path_for_aggregated_result = output_dir\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "keyPhraseExtractor.extractThePhrases(case_act_pickle_file, input_dir, output_dir, legislation_dir, output_folder_path_for_aggregated_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure accuracy of phrase extraction\n",
    "actual_file = os.path.join(notebook_dir, 'data/test2/Experiments2- Full caselaw/temp/output/ExplodedPhrases.csv')\n",
    "predicted_file = os.path.join(output_dir, 'ExplodedPhrases.csv')\n",
    "\n",
    "accuracy_metrics = measure_phrase_extraction_accuracy(actual_file, predicted_file)\n",
    "print(\"Phrase extraction accuracy metrics:\")\n",
    "for metric, value in accuracy_metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Full Case Law Experiments\n",
    "\n",
    "In this step, we run experiments with full case laws instead of sending paragraphs one by one. We'll measure the precision, recall, and F1 score for the law application detection and also measure the accuracy of the extracted phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for full case experiments\n",
    "json_cases_dir = os.path.join(notebook_dir, 'data/test2/Json_cases')\n",
    "full_case_output_dir = os.path.join(notebook_dir, 'data/test4/Full_case_experiments')\n",
    "os.makedirs(json_cases_dir, exist_ok=True)\n",
    "os.makedirs(full_case_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found paragraphs: 57\n",
      "Converted eat_2025_29.xml to JSON\n",
      "Found paragraphs: 52\n",
      "Converted ewfc_2025_41.xml to JSON\n",
      "Found paragraphs: 18\n",
      "Converted ukftt_grc_2025_289.xml to JSON\n",
      "Found paragraphs: 37\n",
      "Converted ewhc_admin_2025_462.xml to JSON\n",
      "Found paragraphs: 45\n",
      "Converted ukftt_grc_2025_284.xml to JSON\n",
      "Found paragraphs: 0\n",
      "Converted ukftt_grc_2025_251.xml to JSON\n",
      "Found paragraphs: 0\n",
      "Converted ukftt_grc_2025_287.xml to JSON\n",
      "Found paragraphs: 39\n",
      "Converted ukftt_grc_2025_283.xml to JSON\n",
      "Found paragraphs: 0\n",
      "Converted ukftt_grc_2025_282.xml to JSON\n",
      "Found paragraphs: 16\n",
      "Converted ewhc_scco_2025_374.xml to JSON\n",
      "Found paragraphs: 0\n",
      "Converted ewca_civ_2025_215.xml to JSON\n"
     ]
    }
   ],
   "source": [
    "# Convert XML cases to JSON\n",
    "from JudgementHandler import JudgmentParser\n",
    "import json\n",
    "\n",
    "xml_cases_dir = os.path.join(notebook_dir, 'data/test2/xml_cases')\n",
    "xml_files = [f for f in os.listdir(xml_cases_dir) if f.endswith('.xml')]\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    xml_path = os.path.join(xml_cases_dir, xml_file)\n",
    "    json_path = os.path.join(json_cases_dir, f\"{xml_file.replace('.xml', '')}.json\")\n",
    "    \n",
    "    handler = JudgmentParser(xml_path)\n",
    "    results = handler.get_judgment_body_paragraphs_text()\n",
    "    \n",
    "    output = []\n",
    "    for case_uri, para_id, text, refs in results:\n",
    "        output.append({\n",
    "            'caseUri': case_uri,\n",
    "            'paragraphId': para_id, \n",
    "            'text': text,\n",
    "            'references': refs\n",
    "        })\n",
    "    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "    \n",
    "    print(f\"Converted {xml_file} to JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n[\\n    {\"para_id\": \"para_1\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_2\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_3\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_4\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_5\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_6\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_7\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_8\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_9\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_10\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_11\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_12\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_13\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_14\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_15\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_16\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_17\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_18\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_19\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_20\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_21\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_22\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_23\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_24\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_25\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_26\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_27\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_28\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_29\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_30\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_31\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_32\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_33\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_34\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_35\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_36\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_37\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_38\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_39\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_40\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_41\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_42\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_43\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_44\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_45\", \"if_law_applied\": 1, \"section\": \"Decision\"}\\n]\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1177, 'prompt_tokens': 22002, 'total_tokens': 23179, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-0ee54727-401e-4fb4-b4a1-3c719c7b53d6-0' usage_metadata={'input_tokens': 22002, 'output_tokens': 1177, 'total_tokens': 23179, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='```json\\n[\\n    {\"para_id\": \"ukftt_grc_2025_251_para_1\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_2\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_3\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_4\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_5\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_6\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_7\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_8\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_9\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_10\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_11\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_12\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_13\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_14\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_15\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_16\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_17\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_18\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_19\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_20\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_21\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_22\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_23\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_24\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_25\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_26\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_27\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_28\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_29\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_30\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_31\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_32\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_33\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_34\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_35\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_36\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_37\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_38\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_39\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_40\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_41\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_42\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_43\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_44\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_45\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_46\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_47\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_48\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_49\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_50\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_51\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_52\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"ukftt_grc_2025_251_para_53\", \"if_law_applied\": 1, \"section\": \"Decision\"}\\n]\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1915, 'prompt_tokens': 22446, 'total_tokens': 24361, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-cef6605e-9af6-4430-a0d3-3677bf85cae0-0' usage_metadata={'input_tokens': 22446, 'output_tokens': 1915, 'total_tokens': 24361, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "No training data found for ewhc_admin_2025_462\n",
      "content='```json\\n[\\n    {\\n        \"para_id\": \"para_1\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_2\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_3\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_4\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_5\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_6\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_7\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_8\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_9\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_10\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_11\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_12\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_13\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_14\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_15\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_16\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_17\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_18\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_19\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_20\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_21\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_22\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_23\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_24\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_25\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_26\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_27\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_28\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_29\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_30\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_31\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_32\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_33\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    }\\n]\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1063, 'prompt_tokens': 19868, 'total_tokens': 20931, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-017369c8-3473-49b0-b2f2-e93fad6cff4b-0' usage_metadata={'input_tokens': 19868, 'output_tokens': 1063, 'total_tokens': 20931, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "No training data found for ukftt_grc_2025_289\n",
      "content='Here is the JSON object representing the paragraphs from the case law, with each paragraph\\'s label indicating whether the application of law to facts is evident:\\n\\n```json\\n[\\n    {\\n        \"para_id\": \"para_1\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_2\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_3\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_4\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_5\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_6\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_7\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_8\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_9\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_10\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_11\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_12\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\",\\n        \"application_of_law_phrases\": [\\n            \"It has entirely discounted them.\",\\n            \"I am entirely satisfied that this behaviour unambiguously indicates that \\'the Respondent has acted unfairly\\'.\"\\n        ]\\n    },\\n    {\\n        \"para_id\": \"para_13\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\",\\n        \"application_of_law_phrases\": [\\n            \"It appears to discount the possibility of moderating a sanction during a review using s43(6).\"\\n        ]\\n    },\\n    {\\n        \"para_id\": \"para_14\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\",\\n        \"application_of_law_phrases\": [\\n            \"I direct that the amount payable under the notice is £0.\"\\n        ]\\n    }\\n]\\n```\\n\\nThis JSON object includes identification of whether the application of law to specific facts is demonstrated in each paragraph, the section of the case law where the paragraph is located, and, if applicable, the specific phrases indicating this application of law.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 640, 'prompt_tokens': 14486, 'total_tokens': 15126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2560}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-5bced4f6-6f96-4e70-981c-d37a8048dd87-0' usage_metadata={'input_tokens': 14486, 'output_tokens': 640, 'total_tokens': 15126, 'input_token_details': {'audio': 0, 'cache_read': 2560}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Error running full case experiment: Expecting value: line 1 column 1 (char 0)\n",
      "content='```json\\n[\\n    {\"para_id\": \"para_1\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_2\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_3\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_4\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_5\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_6\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_7\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_8\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_9\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_10\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_11\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_12\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_13\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_14\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_15\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_16\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_17\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_18\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_19\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_20\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_21\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_22\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_23\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_24\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_25\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_26\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_27\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_28\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_29\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_30\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_31\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_32\", \"if_law_applied\": false, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_33\", \"if_law_applied\": false, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_34\", \"if_law_applied\": false, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_35\", \"if_law_applied\": false, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_36\", \"if_law_applied\": false, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_37\", \"if_law_applied\": false, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_38\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_39\", \"if_law_applied\": true, \"section\": \"Decision\"}\\n]\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 982, 'prompt_tokens': 16997, 'total_tokens': 17979, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-78ea514b-d34e-4a0a-b541-34b79cfd3158-0' usage_metadata={'input_tokens': 16997, 'output_tokens': 982, 'total_tokens': 17979, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='```json\\n[\\n    {\\n        \"para_id\": \"para_1\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_2\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_3\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_4\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_5\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_6\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_7\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_8\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_9\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_10\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_11\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_12\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_13\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_14\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_15\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_16\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    }\\n]\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 519, 'prompt_tokens': 15619, 'total_tokens': 16138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1664}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-52c1285e-8b0b-4ec0-8d80-1a4a8d5af51c-0' usage_metadata={'input_tokens': 15619, 'output_tokens': 519, 'total_tokens': 16138, 'input_token_details': {'audio': 0, 'cache_read': 1664}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='```json\\n[\\n    {\"para_id\": \"para_1\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_2\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_3\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_4\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_5\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_6\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_7\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_8\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_9\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_10\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_11\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_12\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_13\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_14\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_15\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_16\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_17\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_18\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_19\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_20\", \"if_law_applied\": false, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_21\", \"if_law_applied\": false, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_22\", \"if_law_applied\": false, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_23\", \"if_law_applied\": false, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_24\", \"if_law_applied\": false, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_25\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_26\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_27\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_28\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_29\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_30\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_31\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_32\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_33\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_34\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_35\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_36\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_37\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_38\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_39\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_40\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_41\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_42\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_43\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_44\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_45\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_46\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_47\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_48\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_49\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_50\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_51\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_52\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_53\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_54\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_55\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_56\", \"if_law_applied\": true, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_57\", \"if_law_applied\": true, \"section\": \"Decision\"}\\n]\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1432, 'prompt_tokens': 18212, 'total_tokens': 19644, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 3200}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-b563fe81-5683-4eb4-a26a-ae7e42f467cd-0' usage_metadata={'input_tokens': 18212, 'output_tokens': 1432, 'total_tokens': 19644, 'input_token_details': {'audio': 0, 'cache_read': 3200}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "No training data found for ewfc_2025_41\n",
      "content='```json\\n[\\n    {\"para_id\": \"para_1\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_2\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_3\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_4\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_5\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_6\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_7\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_8\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_9\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_10\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_11\", \"if_law_applied\": 0, \"section\": \"Facts\"},\\n    {\"para_id\": \"para_12\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_13\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_14\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_15\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_16\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_17\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_18\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_19\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_20\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_21\", \"if_law_applied\": 0, \"section\": \"Issues\"},\\n    {\"para_id\": \"para_22\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_23\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_24\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_25\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_26\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_27\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_28\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_29\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_30\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_31\", \"if_law_applied\": 0, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_32\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_33\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_34\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_35\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_36\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_37\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_38\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_39\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_40\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_41\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_42\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_43\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_44\", \"if_law_applied\": 1, \"section\": \"Decision\"},\\n    {\"para_id\": \"para_45\", \"if_law_applied\": 0, \"section\": \"Decision\"}\\n]\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1177, 'prompt_tokens': 16466, 'total_tokens': 17643, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-38e6b489-f794-4705-b0a7-6e03ea8e69b3-0' usage_metadata={'input_tokens': 16466, 'output_tokens': 1177, 'total_tokens': 17643, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Run full case experiments\n",
    "full_case_results = []\n",
    "\n",
    "for json_file in os.listdir(json_cases_dir):\n",
    "    if json_file.endswith('.json'):\n",
    "        case_name = json_file.replace('.json', '')\n",
    "        json_path = os.path.join(json_cases_dir, json_file)\n",
    "        \n",
    "        # Load training examples for this case\n",
    "        training_file_path = os.path.join(training_data_path, f\"{case_name}_training.json\")\n",
    "        if os.path.exists(training_file_path):\n",
    "            with open(training_file_path, 'r') as f:\n",
    "                training_examples = json.load(f)\n",
    "            \n",
    "            # Run experiment for gpt-4o model\n",
    "            output_path = os.path.join(full_case_output_dir, f\"{case_name}.json\")\n",
    "            result = run_full_case_experiment(json_path, training_examples, output_path)\n",
    "            full_case_results.append(result)\n",
    "        else:\n",
    "            print(f\"No training data found for {case_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negatives (missed applications of law):\n",
      "    para_id\n",
      "14  para_15\n",
      "19  para_20\n",
      "\n",
      "case_name: ewca_civ_2025_215\n",
      "Precision: 0.2\n",
      "Recall: 0.5\n",
      "F1 Score: 0.2857142857142857\n",
      "False Negatives (missed applications of law):\n",
      "Empty DataFrame\n",
      "Columns: [para_id]\n",
      "Index: []\n",
      "\n",
      "case_name: ewhc_scco_2025_374\n",
      "Precision: 0.75\n",
      "Recall: 1.0\n",
      "F1 Score: 0.8571428571428571\n",
      "False Negatives (missed applications of law):\n",
      "Empty DataFrame\n",
      "Columns: [para_id]\n",
      "Index: []\n",
      "\n",
      "case_name: ukftt_grc_2025_287\n",
      "Precision: 0.23076923076923078\n",
      "Recall: 1.0\n",
      "F1 Score: 0.375\n",
      "False Negatives (missed applications of law):\n",
      "Empty DataFrame\n",
      "Columns: [para_id]\n",
      "Index: []\n",
      "\n",
      "case_name: ukftt_grc_2025_251\n",
      "Precision: 0.7\n",
      "Recall: 1.0\n",
      "F1 Score: 0.8235294117647058\n",
      "False Negatives (missed applications of law):\n",
      "Empty DataFrame\n",
      "Columns: [para_id]\n",
      "Index: []\n",
      "\n",
      "case_name: ukftt_grc_2025_284\n",
      "Precision: 0.2222222222222222\n",
      "Recall: 1.0\n",
      "F1 Score: 0.36363636363636365\n",
      "False Negatives (missed applications of law):\n",
      "Empty DataFrame\n",
      "Columns: [para_id]\n",
      "Index: []\n",
      "\n",
      "case_name: ukftt_grc_2025_282\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 1.0\n",
      "F1 Score: 0.8\n",
      "False Negatives (missed applications of law):\n",
      "    para_id\n",
      "34  para_35\n",
      "35  para_36\n",
      "36  para_37\n",
      "\n",
      "case_name: ukftt_grc_2025_283\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "False Negatives (missed applications of law):\n",
      "Empty DataFrame\n",
      "Columns: [para_id]\n",
      "Index: []\n",
      "\n",
      "case_name: eat_2025_29\n",
      "Precision: 0.2727272727272727\n",
      "Recall: 1.0\n",
      "F1 Score: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Read the csv file with actual values\n",
    "f1_list = []\n",
    "base_input_folder = os.path.join(notebook_dir, 'data/test2/csv_cases/Experiment1-byPara')\n",
    "experiment_folder_path = os.path.join(notebook_dir, 'data/test4/Full_case_experiments')\n",
    "\n",
    "cases = list(case_files.keys())\n",
    "for case_name in cases:\n",
    "    base_input_file = os.path.join(base_input_folder, case_name)\n",
    "    experiment_file = os.path.join(experiment_folder_path, case_name)\n",
    "\n",
    "    base_df = pd.read_csv(base_input_file+'.csv',index_col=False)\n",
    "    experiment_df = pd.read_csv(experiment_file+'.csv',index_col=False)\n",
    "    # Merge the dataframes on 'para_id'\n",
    "\n",
    "    merged_df = pd.merge(base_df[['para_id', 'if_law_applied_actual']],\n",
    "                        experiment_df[['para_id', 'if_law_applied']],\n",
    "                        on='para_id')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Find false negatives (actual=1, predicted=0)\n",
    "    false_negatives = merged_df[\n",
    "        (merged_df['if_law_applied_actual'] == 1) & \n",
    "        (merged_df['if_law_applied'] == False)\n",
    "    ]\n",
    "\n",
    "    # Find false positives (actual=0, predicted=1)\n",
    "    false_positives = merged_df[\n",
    "        (merged_df['if_law_applied_actual'] == 0) & \n",
    "        (merged_df['if_law_applied'] == True)\n",
    "    ]\n",
    "\n",
    "    print(\"False Negatives (missed applications of law):\")\n",
    "    print(false_negatives[['para_id']])\n",
    "    \n",
    "    print(\"\\ncase_name:\", case_name)\n",
    "    #measure precision ,recall and f1 score using scikit-learn\n",
    "    y_true = merged_df['if_law_applied_actual']\n",
    "    y_pred = merged_df['if_law_applied'].astype(int)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    f1_list.append(f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2857142857142857,\n",
       " 0.8571428571428571,\n",
       " 0.375,\n",
       " 0.8235294117647058,\n",
       " 0.36363636363636365,\n",
       " 0.8,\n",
       " 0.0,\n",
       " 0.42857142857142855]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score across all cases: 0.49169929335370516\n"
     ]
    }
   ],
   "source": [
    "average_f1 = sum(f1_list) / len(f1_list)\n",
    "print(f\"Average F1 score across all cases: {average_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare full case results with paragraph-by-paragraph results\n",
    "full_case_metrics = []\n",
    "\n",
    "for result in full_case_results:\n",
    "    if \"error\" in result:\n",
    "        continue\n",
    "    \n",
    "    case_name = result[\"case\"]\n",
    "    model_name = result[\"model\"]\n",
    "    output_path = result[\"output_path\"]\n",
    "    \n",
    "    # Load actual data\n",
    "    actual_file_path = os.path.join(input_folder_path, f\"{case_name}.csv\")\n",
    "    if os.path.exists(actual_file_path):\n",
    "        actual_df = pd.read_csv(actual_file_path)\n",
    "        \n",
    "        # Load predicted data\n",
    "        predicted_df = pd.read_csv(output_path)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(actual_df, predicted_df)\n",
    "        \n",
    "        full_case_metrics.append({\n",
    "            \"case\": case_name,\n",
    "            \"model\": model_name,\n",
    "            \"metrics\": metrics\n",
    "        })\n",
    "\n",
    "# Generate report\n",
    "full_case_report_df = generate_experiment_report(full_case_metrics)\n",
    "full_case_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare paragraph-by-paragraph vs full case approach\n",
    "paragraph_report_df = report_df[report_df[\"Test Case\"] != \"Average\"].copy()\n",
    "paragraph_report_df[\"Approach\"] = \"Paragraph-by-paragraph\"\n",
    "\n",
    "full_case_report_df_filtered = full_case_report_df[full_case_report_df[\"Test Case\"] != \"Average\"].copy()\n",
    "full_case_report_df_filtered[\"Approach\"] = \"Full case\"\n",
    "\n",
    "combined_df = pd.concat([paragraph_report_df, full_case_report_df_filtered])\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=\"Model\", y=\"F1 Score\", hue=\"Approach\", data=combined_df)\n",
    "plt.title(\"F1 Score by Model and Approach\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend(title=\"Approach\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(full_case_output_dir, \"approach_comparison.png\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Odyssey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
