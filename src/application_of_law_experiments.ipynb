{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.chdir('..')\n",
    "notebook_dir = os.getcwd()\n",
    "print(notebook_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/apple/Documents/Swansea/Projects/data/test2/if_law_applied.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnotebook_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/test2/if_law_applied.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the dataframe\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/apple/Documents/Swansea/Projects/data/test2/if_law_applied.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(notebook_dir + '/data/test2/if_law_applied.csv', encoding='latin1')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the df2 sample_case_annotation.csv\n",
    "df2 = pd.read_csv(notebook_dir + '/data/test2/sample_case_annotation.csv', encoding='latin1')\n",
    "#merge rows of two df linke stacking\n",
    "df = pd.concat([df, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://caselaw.nationalarchives.gov.uk/ewhc/admin/2003/2779'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/civ/2004/988'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/civ/2005/647'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/civ/2006/4'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/civ/2007/826'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/crim/2008/468'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/crim/2009/1942'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewhc/admin/2010/2929'\n",
      " 'https://caselaw.nationalarchives.gov.uk/uksc/2011/41'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/civ/2012/543'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewhc/ch/2013/4630'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewhc/qb/2014/4729'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/civ/2015/414'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewhc/qb/2016/2355'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewhc/admin/2017/576'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/civ/2018/764'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/crim/2019/2056'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewhc/admin/2020/1850'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewhc/ch/2021/324'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ukut/aac/2022/263'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/251'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewhc/scco/2025/374'\n",
      " 'https://caselaw.nationalarchives.gov.uk/eat/2025/29'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/289'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/283'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/287'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/282'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/284'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewhc/admin/2025/462'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewca/civ/2025/215'\n",
      " 'https://caselaw.nationalarchives.gov.uk/ewfc/2025/41']\n"
     ]
    }
   ],
   "source": [
    "#drop the rows where all the cells are empty\n",
    "df = df.dropna(how='all')\n",
    "# \n",
    "\n",
    "\n",
    "# Get the unique URLs\n",
    "unique_urls = df['URL'].dropna().unique()\n",
    "\n",
    "print(unique_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_urls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43munique_urls\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_urls' is not defined"
     ]
    }
   ],
   "source": [
    "len(unique_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(notebook_dir + '/data/test2/if_law_applied_combined.csv', index=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewhc_admin_2003_2779.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_civ_2004_988.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_civ_2005_647.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_civ_2006_4.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_civ_2007_826.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_crim_2008_468.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_crim_2009_1942.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewhc_admin_2010_2929.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/uksc_2011_41.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_civ_2012_543.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewhc_ch_2013_4630.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewhc_qb_2014_4729.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_civ_2015_414.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewhc_qb_2016_2355.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewhc_admin_2017_576.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_civ_2018_764.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_crim_2019_2056.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewhc_admin_2020_1850.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewhc_ch_2021_324.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ukut_aac_2022_263.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ukftt_grc_2025_251.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewhc_scco_2025_374.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/eat_2025_29.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ukftt_grc_2025_289.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ukftt_grc_2025_283.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ukftt_grc_2025_287.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ukftt_grc_2025_282.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ukftt_grc_2025_284.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewhc_admin_2025_462.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewca_civ_2025_215.xml\n",
      "✅ Saved: /Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/xml_cases/ewfc_2025_41.xml\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "def download_xml_case(case_url, SAVE_DIR):\n",
    "    try:\n",
    "        xml_url = case_url + \"/data.xml\"\n",
    "        response = requests.get(xml_url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            save_path = os.path.join(SAVE_DIR)\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "            # Clean up filename\n",
    "            title = case_url.split(\"https://caselaw.nationalarchives.gov.uk/\")[1].replace(\"/\", \"_\")\n",
    "            file_name = util.sanitize_filename(title) + \".xml\"\n",
    "            file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            print(f\"✅ Saved: {file_path}\")\n",
    "        else:\n",
    "            print(f\"❌ Failed to download XML for {title} - {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error downloading {title}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "for url in unique_urls:\n",
    "    download_xml_case(url, notebook_dir + '/data/test2/xml_cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/eat_2025_29.csv\n",
      "Found paragraphs: 57\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_civ_2012_543.csv\n",
      "Found paragraphs: 26\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewhc_admin_2010_2929.csv\n",
      "Found paragraphs: 46\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewfc_2025_41.csv\n",
      "Found paragraphs: 52\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_crim_2009_1942.csv\n",
      "Found paragraphs: 0\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_civ_2007_826.csv\n",
      "Found paragraphs: 0\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_civ_2015_414.csv\n",
      "Found paragraphs: 24\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_crim_2019_2056.csv\n",
      "Found paragraphs: 22\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ukut_aac_2022_263.csv\n",
      "Found paragraphs: 36\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ukftt_grc_2025_289.csv\n",
      "Found paragraphs: 18\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewhc_admin_2025_462.csv\n",
      "Found paragraphs: 37\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewhc_admin_2020_1850.csv\n",
      "Found paragraphs: 42\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ukftt_grc_2025_284.csv\n",
      "Found paragraphs: 45\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/uksc_2011_41.csv\n",
      "Found paragraphs: 39\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ukftt_grc_2025_251.csv\n",
      "Found paragraphs: 0\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_civ_2004_988.csv\n",
      "Found paragraphs: 0\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewhc_qb_2016_2355.csv\n",
      "Found paragraphs: 31\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ukftt_grc_2025_287.csv\n",
      "Found paragraphs: 0\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ukftt_grc_2025_283.csv\n",
      "Found paragraphs: 39\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewhc_admin_2003_2779.csv\n",
      "Found paragraphs: 31\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ukftt_grc_2025_282.csv\n",
      "Found paragraphs: 0\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_civ_2018_764.csv\n",
      "Found paragraphs: 0\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewhc_ch_2013_4630.csv\n",
      "Found paragraphs: 51\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_civ_2006_4.csv\n",
      "Found paragraphs: 0\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewhc_scco_2025_374.csv\n",
      "Found paragraphs: 16\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_civ_2025_215.csv\n",
      "Found paragraphs: 0\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewhc_qb_2014_4729.csv\n",
      "Found paragraphs: 9\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_crim_2008_468.csv\n",
      "Found paragraphs: 18\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewhc_ch_2021_324.csv\n",
      "Found paragraphs: 50\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewca_civ_2005_647.csv\n",
      "Found paragraphs: 46\n",
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction-Journal/data/test2/csv_cases/ewhc_admin_2017_576.csv\n",
      "Found paragraphs: 35\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "input_dir = Path(notebook_dir) / 'data/test2/xml_cases'\n",
    "output_dir = Path(notebook_dir) / 'data/test2/csv_cases'\n",
    "\n",
    "# Check if directories exist, otherwise create them\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for xml_file in input_dir.glob(\"*.xml\"):\n",
    "    csv_file = output_dir / f\"{xml_file.stem}.csv\"\n",
    "    print(csv_file)\n",
    "    try:\n",
    "        # Call the conversion function (assumed to be defined elsewhere)\n",
    "        util.Convert_CSVs_xml_to_Csv(str(xml_file), str(csv_file),False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {xml_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    para_id\n",
      "0   para_42\n",
      "1   para_42\n",
      "2   para_43\n",
      "3   para_44\n",
      "4   para_45\n",
      "5   para_46\n",
      "6   para_47\n",
      "7   para_48\n",
      "8   para_48\n",
      "10  para_13\n",
      "11  para_13\n",
      "12  para_14\n",
      "13  para_14\n",
      "14  para_15\n",
      "20  para_29\n",
      "21  para_31\n",
      "22  para_33\n",
      "23  para_37\n",
      "24  para_40\n",
      "25  para_41\n",
      "26  para_48\n",
      "27  para_51\n",
      "28  para_52\n",
      "32  para_14\n",
      "36  para_35\n",
      "37  para_36\n",
      "38  para_37\n",
      "42  para_32\n",
      "43  para_33\n",
      "44  para_35\n",
      "47  para_12\n",
      "48  para_13\n",
      "51  para_36\n",
      "52  para_37\n",
      "56  para_27\n",
      "59  para_15\n",
      "60  para_20\n",
      "61  para_25\n",
      "62  para_26\n",
      "66  para_38\n",
      "67  para_42\n",
      "68  para_43\n"
     ]
    }
   ],
   "source": [
    "df['para_id'] = 'para_' + df['para_id'].astype(int).astype(str)\n",
    "print(df[['para_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  URL  para_id if_law_applied  \\\n",
      "0   https://caselaw.nationalarchives.gov.uk/ewhc/a...  para_13            yes   \n",
      "1   https://caselaw.nationalarchives.gov.uk/ewhc/a...  para_14            yes   \n",
      "2   https://caselaw.nationalarchives.gov.uk/ewhc/a...  para_17            yes   \n",
      "3   https://caselaw.nationalarchives.gov.uk/ewhc/a...  para_18            yes   \n",
      "4   https://caselaw.nationalarchives.gov.uk/ewhc/a...  para_19            yes   \n",
      "..                                                ...      ...            ...   \n",
      "61  https://caselaw.nationalarchives.gov.uk/ewca/c...  para_25            yes   \n",
      "62  https://caselaw.nationalarchives.gov.uk/ewca/c...  para_26            yes   \n",
      "66  https://caselaw.nationalarchives.gov.uk/ewfc/2...  para_38            yes   \n",
      "67  https://caselaw.nationalarchives.gov.uk/ewfc/2...  para_42            yes   \n",
      "68  https://caselaw.nationalarchives.gov.uk/ewfc/2...  para_43            yes   \n",
      "\n",
      "   reason(optional)                               phrase from case law  \\\n",
      "0               NaN                                                NaN   \n",
      "1               NaN                                                NaN   \n",
      "2               NaN                                                NaN   \n",
      "3               NaN                                                NaN   \n",
      "4               NaN                                                NaN   \n",
      "..              ...                                                ...   \n",
      "61              NaN  That plainly means that in a dependency case i...   \n",
      "62              NaN   The phrase and continues to be in Regulatio...   \n",
      "66              NaN  I could only do so if I were to consider that ...   \n",
      "67              NaN  In this respect, I recognise that there would ...   \n",
      "68              NaN  A declaration that Mr J is not in law the fath...   \n",
      "\n",
      "   applied provision                                                act  \\\n",
      "0                NaN                                                NaN   \n",
      "1                NaN                                                NaN   \n",
      "2                NaN                                                NaN   \n",
      "3                NaN                                                NaN   \n",
      "4                NaN                                                NaN   \n",
      "..               ...                                                ...   \n",
      "61   regulation_8(2)      https://www.legislation.gov.uk/uksi/2016/1052   \n",
      "62   regulation_8(2)      https://www.legislation.gov.uk/uksi/2016/1052   \n",
      "66  section _55A(5)   https://www.legislation.gov.uk/ukpga/1986/55/c...   \n",
      "67  section _55A(5)   https://www.legislation.gov.uk/ukpga/1986/55/c...   \n",
      "68  section _55A(5)   https://www.legislation.gov.uk/ukpga/1986/55/c...   \n",
      "\n",
      "                 legislative term  \n",
      "0                             NaN  \n",
      "1                             NaN  \n",
      "2                             NaN  \n",
      "3                             NaN  \n",
      "4                             NaN  \n",
      "..                            ...  \n",
      "61  dependency on an EEA national  \n",
      "62  dependency on an EEA national  \n",
      "66   best interests of the child   \n",
      "67   best interests of the child   \n",
      "68   best interests of the child   \n",
      "\n",
      "[231 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df['if_law_applied'] = 'yes'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     para_id                                           case_uri  \\\n",
      "0    para_10  https://caselaw.nationalarchives.gov.uk/ewca/c...   \n",
      "1    para_11  https://caselaw.nationalarchives.gov.uk/ewca/c...   \n",
      "2    para_12  https://caselaw.nationalarchives.gov.uk/ewca/c...   \n",
      "3    para_12  https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
      "4    para_12  https://caselaw.nationalarchives.gov.uk/ukftt/...   \n",
      "..       ...                                                ...   \n",
      "221  para_51  https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
      "222  para_52  https://caselaw.nationalarchives.gov.uk/eat/20...   \n",
      "223   para_7  https://caselaw.nationalarchives.gov.uk/ewca/c...   \n",
      "224   para_8  https://caselaw.nationalarchives.gov.uk/ewhc/q...   \n",
      "225   para_9  https://caselaw.nationalarchives.gov.uk/ewhc/q...   \n",
      "\n",
      "                                  phrase from case law  \n",
      "0                                                [nan]  \n",
      "1                                                [nan]  \n",
      "2                                                [nan]  \n",
      "3                                                [nan]  \n",
      "4    [The Regulator, having satisfied itself that t...  \n",
      "..                                                 ...  \n",
      "221                                              [nan]  \n",
      "222  [On the findings of fact made by the tribunal ...  \n",
      "223                                              [nan]  \n",
      "224                                              [nan]  \n",
      "225                                              [nan]  \n",
      "\n",
      "[226 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by 'para_id' and 'URL' and aggregate the 'phrase from case law' into a list\n",
    "#grouped_df = df.groupby(['para_id', 'URL'])['phrase from case law'].apply(list).reset_index()\n",
    "df.rename(columns={'URL': 'case_uri'}, inplace=True)\n",
    "\n",
    "print(grouped_df)\n",
    "# now for each csv file in output_dir = Path(notebook_dir) / 'data/test2/csv_cases'\n",
    "# make a column 'phrase from case law' and add the corresponding list of phrases from grouped_df where para_id and url matches\n",
    "for csv_file in output_dir.glob(\"*.csv\"):\n",
    "    csv_df = pd.read_csv(csv_file)\n",
    "    df.rename(columns={'URL': 'case_uri'}, inplace=True)\n",
    "    \n",
    "    # csv_df['phrase from case law'] = csv_df.apply(\n",
    "    #     lambda row: grouped_df[(grouped_df['para_id'] == row['para_id']) & (grouped_df['case_uri'] == row['case_uri'])]['phrase from case law'].values[0] \n",
    "    #     if not grouped_df[(grouped_df['para_id'] == row['para_id']) & (grouped_df['case_uri'] == row['case_uri'])].empty else [], axis=1)\n",
    "    # rename 'phrase from case law' to 'application_of_law_phrases'\n",
    "    \n",
    "    # Merge all columns from df into csv_df\n",
    "    csv_df = csv_df.merge(df, on=['para_id', 'case_uri'], how='left', suffixes=('', '_df'))\n",
    "    \n",
    "    # Fill missing values in 'if_law_applied' with 'no'\n",
    "    csv_df['if_law_applied'] = csv_df['if_law_applied'].fillna('no')\n",
    "    csv_df.rename(columns={'phrase from case law': 'application_of_law_phrases'}, inplace=True)\n",
    "\n",
    "    csv_df.to_csv(csv_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             case_uri  para_id  \\\n",
      "13  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_14   \n",
      "37  https://caselaw.nationalarchives.gov.uk/ewfc/2...  para_38   \n",
      "41  https://caselaw.nationalarchives.gov.uk/ewfc/2...  para_42   \n",
      "42  https://caselaw.nationalarchives.gov.uk/ewfc/2...  para_43   \n",
      "26  https://caselaw.nationalarchives.gov.uk/ewhc/a...  para_27   \n",
      "45  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_42   \n",
      "46  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_43   \n",
      "47  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_44   \n",
      "48  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_45   \n",
      "49  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_46   \n",
      "50  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_47   \n",
      "51  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_48   \n",
      "11  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_12   \n",
      "12  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_13   \n",
      "34  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_35   \n",
      "35  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_36   \n",
      "36  https://caselaw.nationalarchives.gov.uk/ukftt/...  para_37   \n",
      "\n",
      "                                           paragraphs  \\\n",
      "13  \\n\\t   \\n\\t 14. \\n\\t   \\n\\t     \\n\\t \\n\\t   Th...   \n",
      "37  \\n\\t   \\n\\t 38. \\n\\t   \\n\\t     \\n\\t   Having ...   \n",
      "41  \\n\\t   \\n\\t 42. \\n\\t   \\n\\t     \\n\\t In this r...   \n",
      "42  \\n\\t   \\n\\t 43. \\n\\t   \\n\\t     \\n\\t But that ...   \n",
      "26  \\n\\t   \\n\\t 27. \\n\\t   \\n\\t     \\n\\t It is ess...   \n",
      "45  \\n\\t     \\n\\t   42. \\n\\t     \\n\\t       \\n\\t  ...   \n",
      "46  \\n\\t     \\n\\t   43. \\n\\t     \\n\\t       \\n\\t  ...   \n",
      "47  \\n\\t     \\n\\t   44. \\n\\t     \\n\\t       \\n\\t  ...   \n",
      "48  \\n\\t     \\n\\t   45. \\n\\t     \\n\\t       \\n\\t  ...   \n",
      "49  \\n\\t     \\n\\t   46. \\n\\t     \\n\\t       \\n\\t  ...   \n",
      "50  \\n\\t     \\n\\t   47. \\n\\t     \\n\\t       \\n\\t  ...   \n",
      "51  \\n\\t     \\n\\t   48. \\n\\t     \\n\\t       \\n\\t  ...   \n",
      "11  \\n\\t     \\n\\t   12. \\n\\t     \\n\\t       \\n\\t  ...   \n",
      "12  \\n\\t     \\n\\t   13. \\n\\t     \\n\\t       \\n\\t  ...   \n",
      "34  \\n\\t   \\n\\t 35. \\n\\t   \\n\\t     \\n\\t \\n\\t   It...   \n",
      "35  \\n\\t   \\n\\t 36. \\n\\t   \\n\\t     \\n\\t \\n\\t   As...   \n",
      "36  \\n\\t   \\n\\t 37. \\n\\t   \\n\\t     \\n\\t \\n\\t   Ho...   \n",
      "\n",
      "                                           references  if_law_applied  \\\n",
      "13  [{'text': 'section 166', 'href': 'http://www.l...               1   \n",
      "37  [{'text': 'section 55', 'href': 'http://www.le...               1   \n",
      "41                                                 []               1   \n",
      "42  [{'text': 'HFEA 2008', 'href': 'http://www.leg...               1   \n",
      "26                                                 []               1   \n",
      "45                                                 []               1   \n",
      "46                                                 []               1   \n",
      "47                                                 []               1   \n",
      "48                                                 []               1   \n",
      "49                                                 []               1   \n",
      "50                                                 []               1   \n",
      "51                                                 []               1   \n",
      "11                                                 []               1   \n",
      "12                                                 []               1   \n",
      "34                                                 []               1   \n",
      "35                                                 []               1   \n",
      "36                                                 []               1   \n",
      "\n",
      "                           application_of_law_phrases  \n",
      "13  ['The Applicant misunderstands the remit the a...  \n",
      "37  ['I could only do so if I were to consider tha...  \n",
      "41  ['In this respect, I recognise that there woul...  \n",
      "42  ['A declaration that Mr J is not in law the fa...  \n",
      "26  ['It is essential to Ground 1 of the Claimant\\...  \n",
      "45  ['had the information not been provided in suc...  \n",
      "46  ['There is nothing to suggest the Appellant ha...  \n",
      "47  ['there is a genuine motive from the complaina...  \n",
      "48  ['There is nothing to suggest (and there has b...  \n",
      "49  ['the Tribunal is to take a rounded and holist...  \n",
      "50  ['this was not a request that had no reasonabl...  \n",
      "51  ['If the Council had sent the links that were ...  \n",
      "11  ['The Regulator, having satisfied itself that ...  \n",
      "12  ['The Regulator appears to consider that the p...  \n",
      "34  ['It would appear to the Tribunal that the dri...  \n",
      "35  ['It appears from the documentation provided t...  \n",
      "36  ['However, the Tribunal did have some concerns...  \n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied',\n",
      "       'application_of_law_phrases', 'reason'],\n",
      "      dtype='object')\n",
      "examples2.json file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# URLs to process\n",
    "\n",
    "urls_to_process = [\n",
    "    \"https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/289\",\n",
    "    \"https://caselaw.nationalarchives.gov.uk/ewfc/2025/41\",\n",
    "    \"https://caselaw.nationalarchives.gov.uk/ewhc/admin/2025/462\"\n",
    "]\n",
    "\n",
    "# Read the CSV files corresponding to the URLs\n",
    "csv_files = [\n",
    "    notebook_dir + '/data/test2/csv_cases/ukftt_grc_2025_289.csv',\n",
    "    notebook_dir + '/data/test2/csv_cases/ewfc_2025_41.csv',\n",
    "    notebook_dir + '/data/test2/csv_cases/ewhc_admin_2025_462.csv',\n",
    "    notebook_dir + '/data/test2/csv_cases/ukftt_grc_2025_251.csv',\n",
    "    notebook_dir + '/data/test2/csv_cases/ukftt_grc_2025_282.csv',\n",
    "    notebook_dir + '/data/test2/csv_cases/ukftt_grc_2025_283.csv',\n",
    "]\n",
    "\n",
    "# Combine the data from all CSV files into a single dataframe\n",
    "case_df = pd.concat([pd.read_csv(file) for file in csv_files])\n",
    "\n",
    "\n",
    "# Filter the dataframe for the given URLs\n",
    "#filtered_df = case_df[case_df['case_uri'].isin(urls_to_process)]\n",
    "\n",
    "# Separate rows where 'if_law_applied' is 1 and 0\n",
    "applied_df = case_df[case_df['if_law_applied'] == 1]\n",
    "not_applied_df = case_df[case_df['if_law_applied'] == 0]\n",
    "print(applied_df)\n",
    "# Sample the same number of rows from not_applied_df as in applied_df\n",
    "sampled_not_applied_df = not_applied_df.sample(n=len(applied_df), random_state=1)\n",
    "\n",
    "# Combine the dataframes\n",
    "combined_df = pd.concat([applied_df, sampled_not_applied_df])\n",
    "\n",
    "#read the data/test2/testing-data.json file\n",
    "with open(notebook_dir + '/data/test2/testing-data.json') as f:\n",
    "    testing_data = json.load(f)\n",
    "\n",
    "# make the paragraph id split the case_uri on https://caselaw.nationalarchives.gov.uk\"\n",
    "#joing the split from[1:] with \"_\"\n",
    "def get_para_id(case_uri):\n",
    "    part2 = case_uri.split(\"https://caselaw.nationalarchives.gov.uk\")[1]\n",
    "    part2 = part2.replace(\"/\", \"_\")\n",
    "    return part2\n",
    "\n",
    "testing_data_df = pd.DataFrame(testing_data)\n",
    "combined_df['para_id'] = combined_df['case_uri'].apply(get_para_id)\n",
    "\n",
    "#merge the combined_df with the testing_data_df on para_id\n",
    "combined_df = combined_df.merge(testing_data_df[['para_id','reason']], on='para_id', how='left')\n",
    "print(combined_df.columns)\n",
    "# Create the examples list\n",
    "examples = []\n",
    "for _, row in combined_df.iterrows():\n",
    "    example = {\n",
    "        \"para_id\": row['para_id'],\n",
    "        \"para_content\": row['paragraphs'],\n",
    "        \"if_law_applied\": row['if_law_applied'],\n",
    "        \"application_of_law_phrases\": row['application_of_law_phrases'],\n",
    "        \"reason\": row['reason']\n",
    "    }\n",
    "    examples.append(example)\n",
    "\n",
    "# Save to examples.json\n",
    "with open('data/test2/examples.json', 'w') as f:\n",
    "    json.dump(examples, f, indent=4)\n",
    "\n",
    "print(\"examples2.json file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['ewca_2025_29.csv',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test2/csv_cases/ewhc_ch_2021_324.csv\n",
      "===========processing ewhc_ch_2021_324 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewhc_ch_2021_324 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_crim_2008_468.csv\n",
      "===========processing ewca_crim_2008_468 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_crim_2008_468 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_civ_2025_215.csv\n",
      "===========processing ewca_civ_2025_215 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_civ_2025_215 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewhc_qb_2014_4729.csv\n",
      "===========processing ewhc_qb_2014_4729 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewhc_qb_2014_4729 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewhc_scco_2025_374.csv\n",
      "===========processing ewhc_scco_2025_374 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewhc_scco_2025_374 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_civ_2006_4.csv\n",
      "===========processing ewca_civ_2006_4 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_civ_2006_4 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewhc_admin_2017_576.csv\n",
      "===========processing ewhc_admin_2017_576 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewhc_admin_2017_576 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_civ_2005_647.csv\n",
      "===========processing ewca_civ_2005_647 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_civ_2005_647 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewhc_qb_2016_2355.csv\n",
      "===========processing ewhc_qb_2016_2355 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewhc_qb_2016_2355 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ukftt_grc_2025_287.csv\n",
      "===========processing ukftt_grc_2025_287 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ukftt_grc_2025_287 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_civ_2004_988.csv\n",
      "===========processing ewca_civ_2004_988 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_civ_2004_988 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ukftt_grc_2025_251.csv\n",
      "===========processing ukftt_grc_2025_251 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ukftt_grc_2025_251 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/uksc_2011_41.csv\n",
      "===========processing uksc_2011_41 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing uksc_2011_41 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ukftt_grc_2025_284.csv\n",
      "===========processing ukftt_grc_2025_284 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ukftt_grc_2025_284 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewhc_admin_2020_1850.csv\n",
      "===========processing ewhc_admin_2020_1850 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewhc_admin_2020_1850 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewhc_ch_2013_4630.csv\n",
      "===========processing ewhc_ch_2013_4630 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewhc_ch_2013_4630 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_civ_2018_764.csv\n",
      "===========processing ewca_civ_2018_764 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_civ_2018_764 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewhc_admin_2003_2779.csv\n",
      "===========processing ewhc_admin_2003_2779 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewhc_admin_2003_2779 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ukftt_grc_2025_282.csv\n",
      "===========processing ukftt_grc_2025_282 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "===========processing ukftt_grc_2025_282 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ukftt_grc_2025_283.csv\n",
      "===========processing ukftt_grc_2025_283 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ukftt_grc_2025_283 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ukut_aac_2022_263.csv\n",
      "===========processing ukut_aac_2022_263 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ukut_aac_2022_263 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_crim_2019_2056.csv\n",
      "===========processing ewca_crim_2019_2056 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_crim_2019_2056 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_civ_2015_414.csv\n",
      "===========processing ewca_civ_2015_414 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_civ_2015_414 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ukftt_grc_2025_289.csv\n",
      "===========processing ukftt_grc_2025_289 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "===========processing ukftt_grc_2025_289 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewhc_admin_2025_462.csv\n",
      "===========processing ewhc_admin_2025_462 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewhc_admin_2025_462 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewhc_admin_2010_2929.csv\n",
      "===========processing ewhc_admin_2010_2929 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewhc_admin_2010_2929 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_civ_2012_543.csv\n",
      "===========processing ewca_civ_2012_543 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_civ_2012_543 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/eat_2025_29.csv\n",
      "===========processing eat_2025_29 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing eat_2025_29 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_civ_2007_826.csv\n",
      "===========processing ewca_civ_2007_826 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_civ_2007_826 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewca_crim_2009_1942.csv\n",
      "===========processing ewca_crim_2009_1942 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewca_crim_2009_1942 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "data/test2/csv_cases/ewfc_2025_41.csv\n",
      "===========processing ewfc_2025_41 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n",
      "===========processing ewfc_2025_41 =============================\n",
      "batch size is 30\n",
      "starting again...\n",
      "starting again...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from classifier import process_csv_with_openai\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = 'data/test2/csv_cases'\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        \n",
    "        # Extract case number from filename\n",
    "        case_number = filename.split('.')[0]\n",
    "        csv_path = os.path.join(folder_path, filename)\n",
    "        print(csv_path)\n",
    "        # read the csv file and rename column if_law_applied to if_law_applied_actual\n",
    "        # rename application_of_law_phrases to application_of_law_phrases_actual \n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'if_law_applied' in df.columns:\n",
    "            df.rename(columns={'if_law_applied': 'if_law_applied_actual'}, inplace=True)\n",
    "        if 'application_of_law_phrases' in df.columns:\n",
    "            df.rename(columns={'application_of_law_phrases': 'application_of_law_phrases_actual'}, inplace=True)\n",
    "      \n",
    "        df.to_csv(csv_path, index=False)\n",
    "        LLMS = ['gpt-4o-mini','gpt-4o']\n",
    "        #LLMS = ['llama-3.3-70b-versatile','claude-3-7-sonnet-latest']\n",
    "\n",
    "        for model in LLMS:\n",
    "            print(f\"===========processing {case_number} =============================\")\n",
    "            delay = 0\n",
    "            batch_size = 20\n",
    "            max_tokens = 500,000\n",
    "            #if model == 'llama-3.3-70b-versatile': # for free toer\n",
    "               # delay = 60\n",
    "            #else:\n",
    "                #delay = 0\n",
    "            if model == 'claude-3-7-sonnet-latest':\n",
    "                batch_size = 5\n",
    "                max_tokens = 20,000\n",
    "            else:\n",
    "                batch_size = 30\n",
    "                #max_tokens = 500,000\n",
    "            process_csv_with_openai('data/test2/examples.json', csv_path, model,batch_size,delay)\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df.rename(columns={\n",
    "                'if_law_applied': f'if_law_applied_{model}', \n",
    "                'application_of_law_phrases': f'application_of_law_phrases_{model}',\n",
    "                'reason_of_choosing_it_as_application': f'reason_{model}'\n",
    "            }, inplace=True)\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(\"Done\")\n",
    "        # print(f\"===========processing {case_number} =============================\")\n",
    "        # process_csv_with_openai('data/test2/examples.json', csv_path,model)\n",
    "        # print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'no'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Convert the columns to proper data type\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mif_law_applied_actual\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mif_law_applied_actual\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue counts for ground truth \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mif_law_applied_actual\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mif_law_applied_actual\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/core/generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6233\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   6235\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   6236\u001b[0m     ]\n\u001b[1;32m   6238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6239\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6240\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6243\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/core/internals/managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/core/internals/blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    524\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 526\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    529\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    227\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ETPADV/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:170\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'no'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Read all the csv files in data/test2/Done\n",
    "done_folder_path = 'data/test2/csv_cases'\n",
    "all_dfs = []\n",
    "for filename in os.listdir(done_folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(done_folder_path, filename)\n",
    "        all_dfs.append(pd.read_csv(file_path))\n",
    "\n",
    "# Combine the data from all CSV files into a single dataframe\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Convert the columns to proper data type\n",
    "combined_df['if_law_applied_actual'] = combined_df['if_law_applied_actual'].astype(int)\n",
    "\n",
    "print(\"Value counts for ground truth 'if_law_applied_actual':\")\n",
    "print(combined_df['if_law_applied_actual'].value_counts())\n",
    "for model in LLMS:\n",
    "    combined_df[f'if_law_applied_{model}'] = combined_df[f'if_law_applied_{model}'].astype(int)\n",
    "\n",
    "# Compute the true positive, true negative, false positive, false negative for each model\n",
    "results = {}\n",
    "for model in LLMS:\n",
    "    y_true = combined_df['if_law_applied_actual']\n",
    "    y_pred = combined_df[f'if_law_applied_{model}']\n",
    "    \n",
    "    tp = ((y_true == 1) & (y_pred == 1)).sum()\n",
    "    tn = ((y_true == 0) & (y_pred == 0)).sum()\n",
    "    fp = ((y_true == 0) & (y_pred == 1)).sum()\n",
    "    fn = ((y_true == 1) & (y_pred == 0)).sum()\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    results[model] = {\n",
    "        'True Positive': tp,\n",
    "        'True Negative': tn,\n",
    "        'False Positive': fp,\n",
    "        'False Negative': fn,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "#get me a dataframe with all the false negative\n",
    "# Get a dataframe with all the false negatives for all of the models\n",
    "false_negatives = combined_df[(combined_df['if_law_applied_actual'] == 1) & (combined_df[[f'if_law_applied_{model}' for model in LLMS]] == 0).all(axis=1)]\n",
    "false_negatives.to_csv('data/test2/csv_cases/false_negatives.csv', index=False)\n",
    "\n",
    "# Get a dataframe with all the false positives for all of the models\n",
    "false_positives = combined_df[(combined_df['if_law_applied_actual'] == 0) & (combined_df[[f'if_law_applied_{model}' for model in LLMS]] == 1).all(axis=1)]\n",
    "false_positives.to_csv('data/test2/csv_cases/false_positives.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the results in a table format\n",
    "# Display the results\n",
    "for model, metrics in results.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found paragraphs: 57\n"
     ]
    }
   ],
   "source": [
    "# Get the Caselaw in the Json \n",
    "# Modify the prompt \n",
    "# And test\n",
    "from JudgementHandler import JudgmentParser\n",
    "import json\n",
    "xml_file = 'data/test2/xml_cases/eat_2025_29.xml'\n",
    "handler = JudgmentParser(xml_file)\n",
    "    \n",
    "# Get all paragraphs with legislation references\n",
    "results = handler.get_judgment_body_paragraphs_text()\n",
    "\n",
    "# Print results in JSON format\n",
    "output = []\n",
    "for case_uri, para_id, text, refs in results:\n",
    "    output.append({\n",
    "        'caseUri': case_uri,\n",
    "        'paragraphId': para_id, \n",
    "        'text': text,\n",
    "        'references': refs\n",
    "    })\n",
    "\n",
    "with open('data/test2/Json_cases/eat_2025_29.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/apple/Documents/Swansea/Projects/Odyssey-Terms-Extraction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.chdir('..')\n",
    "notebook_dir = os.getcwd()\n",
    "print(notebook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n[\\n    {\\n        \"para_id\": \"para_1\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_2\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_3\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_4\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_5\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_6\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_7\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_8\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_9\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Facts\"\\n    },\\n    {\\n        \"para_id\": \"para_10\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_11\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_12\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_13\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Issues\"\\n    },\\n    {\\n        \"para_id\": \"para_14\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_15\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_16\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_17\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_18\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_19\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_20\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_21\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_22\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_23\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_24\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_25\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_26\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_27\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_28\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_29\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_30\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_31\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_32\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_33\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_34\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_35\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_36\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_37\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_38\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_39\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_40\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_41\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_42\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_43\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_44\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_45\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_46\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_47\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_48\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_49\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_50\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_51\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_52\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_53\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_54\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_55\",\\n        \"if_law_applied\": 0,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_56\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    },\\n    {\\n        \"para_id\": \"para_57\",\\n        \"if_law_applied\": 1,\\n        \"section\": \"Decision\"\\n    }\\n]\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1831, 'prompt_tokens': 19913, 'total_tokens': 21744, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 14336}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None} id='run-072e825b-0743-4bc8-b397-207aef8b5344-0' usage_metadata={'input_tokens': 19913, 'output_tokens': 1831, 'total_tokens': 21744, 'input_token_details': {'audio': 0, 'cache_read': 14336}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openAIHandler import getLegalClassifierUsingJson\n",
    "with open('data/test2/Json_cases/eat_2025_29.json', 'r') as file:\n",
    "        case_law_paragraphs = json.load(file)\n",
    "with open('data/test2/examples.json', 'r') as file:\n",
    "        examples = json.load(file)\n",
    "#print(examples)\n",
    "response = getLegalClassifierUsingJson(case_law_paragraphs,examples)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    para_id  if_law_applied   section\n",
      "0    para_1               0     Facts\n",
      "1    para_2               0     Facts\n",
      "2    para_3               0     Facts\n",
      "3    para_4               0     Facts\n",
      "4    para_5               0     Facts\n",
      "5    para_6               0     Facts\n",
      "6    para_7               0     Facts\n",
      "7    para_8               0     Facts\n",
      "8    para_9               0     Facts\n",
      "9   para_10               0    Issues\n",
      "10  para_11               0    Issues\n",
      "11  para_12               0    Issues\n",
      "12  para_13               0    Issues\n",
      "13  para_14               1  Decision\n",
      "14  para_15               0  Decision\n",
      "15  para_16               0  Decision\n",
      "16  para_17               1  Decision\n",
      "17  para_18               1  Decision\n",
      "18  para_19               1  Decision\n",
      "19  para_20               1  Decision\n",
      "20  para_21               0  Decision\n",
      "21  para_22               0  Decision\n",
      "22  para_23               0  Decision\n",
      "23  para_24               0  Decision\n",
      "24  para_25               0  Decision\n",
      "25  para_26               0  Decision\n",
      "26  para_27               0  Decision\n",
      "27  para_28               0  Decision\n",
      "28  para_29               1  Decision\n",
      "29  para_30               1  Decision\n",
      "30  para_31               1  Decision\n",
      "31  para_32               0  Decision\n",
      "32  para_33               0  Decision\n",
      "33  para_34               0  Decision\n",
      "34  para_35               0  Decision\n",
      "35  para_36               0  Decision\n",
      "36  para_37               0  Decision\n",
      "37  para_38               0  Decision\n",
      "38  para_39               0  Decision\n",
      "39  para_40               1  Decision\n",
      "40  para_41               1  Decision\n",
      "41  para_42               1  Decision\n",
      "42  para_43               1  Decision\n",
      "43  para_44               0  Decision\n",
      "44  para_45               0  Decision\n",
      "45  para_46               1  Decision\n",
      "46  para_47               0  Decision\n",
      "47  para_48               1  Decision\n",
      "48  para_49               0  Decision\n",
      "49  para_50               0  Decision\n",
      "50  para_51               1  Decision\n",
      "51  para_52               1  Decision\n",
      "52  para_53               1  Decision\n",
      "53  para_54               0  Decision\n",
      "54  para_55               0  Decision\n",
      "55  para_56               1  Decision\n",
      "56  para_57               1  Decision\n"
     ]
    }
   ],
   "source": [
    "response_updated = response.content.replace(\"```json\\n\",\"\")\n",
    "response_updated = response_updated.replace(\"\\n```\",\"\")\n",
    "#put response_updated in a json file\n",
    "with open('data/test2/Json_cases/eat_2025_29_response.json', 'w') as f:\n",
    "    f.write(response_updated)\n",
    "# convert the json file to csv simple\n",
    "df = pd.read_json('data/test2/Json_cases/eat_2025_29_response.json')\n",
    "df.to_csv('data/test2/csv_cases/eat_2025_29_response.csv', index=False)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negatives (missed applications of law):\n",
      "    para_id\n",
      "32  para_33\n",
      "36  para_37\n",
      "\n",
      "False Positives (incorrectly identified as law application):\n",
      "    para_id\n",
      "13  para_14\n",
      "16  para_17\n",
      "17  para_18\n",
      "18  para_19\n",
      "19  para_20\n",
      "29  para_30\n",
      "41  para_42\n",
      "42  para_43\n",
      "45  para_46\n",
      "52  para_53\n",
      "55  para_56\n",
      "56  para_57\n"
     ]
    }
   ],
   "source": [
    "# Read the csv file with actual values\n",
    "actual_df = pd.read_csv('data/test2/csv_cases/Experiment1- With Few Shot learning/eat_2025_29.csv')\n",
    "\n",
    "# Compare with our predictions (df)\n",
    "merged_df = pd.merge(actual_df[['para_id', 'if_law_applied_actual']], \n",
    "                    df[['para_id', 'if_law_applied']], \n",
    "                    on='para_id')\n",
    "\n",
    "# Find false negatives (actual=1, predicted=0)\n",
    "false_negatives = merged_df[\n",
    "    (merged_df['if_law_applied_actual'] == 1) & \n",
    "    (merged_df['if_law_applied'] == False)\n",
    "]\n",
    "\n",
    "# Find false positives (actual=0, predicted=1)\n",
    "false_positives = merged_df[\n",
    "    (merged_df['if_law_applied_actual'] == 0) & \n",
    "    (merged_df['if_law_applied'] == True)\n",
    "]\n",
    "\n",
    "print(\"False Negatives (missed applications of law):\")\n",
    "print(false_negatives[['para_id']])\n",
    "print(\"\\nFalse Positives (incorrectly identified as law application):\")\n",
    "print(false_positives[['para_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files not in 'csv_with_legislation':\n",
      "['ewhc_admin_2025_462.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the paths\n",
    "csv_cases_path = os.path.join(notebook_dir, 'data/test2/csv_cases')\n",
    "csv_with_legislation_path = os.path.join(csv_cases_path, 'csv_with_legislation')\n",
    "\n",
    "# Get the list of all CSV files in both directories that end with _[somedigit].csv\n",
    "csv_cases_files = set(f for f in os.listdir(csv_cases_path) if f.endswith('.csv') and any(char.isdigit() for char in f.split('_')[-1].split('.')[0]))\n",
    "csv_with_legislation_files = set(f for f in os.listdir(csv_with_legislation_path) if f.endswith('.csv') and any(char.isdigit() for char in f.split('_')[-1].split('.')[0]))\n",
    "\n",
    "# Find the files that are in csv_cases but not in csv_with_legislation\n",
    "files_not_in_legislation = list(csv_cases_files - csv_with_legislation_files)\n",
    "\n",
    "print(\"Files not in 'csv_with_legislation':\")\n",
    "print(files_not_in_legislation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ewhc_scco_2025_374.csv', 'ewhc_admin_2025_462.csv']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_not_in_legislation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ewhc_scco_2025_374.csv\n",
      "URLs found in sample_case_annotation.csv:\n",
      "['https://caselaw.nationalarchives.gov.uk/ewhc/scco/2025/374']\n",
      "URLs found in if_law_applied.csv:\n",
      "[]\n",
      "\n",
      "\n",
      "File: ewhc_admin_2025_462.csv\n",
      "URLs found in sample_case_annotation.csv:\n",
      "['https://caselaw.nationalarchives.gov.uk/ewhc/admin/2025/462']\n",
      "URLs found in if_law_applied.csv:\n",
      "[]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the required files\n",
    "sample_case_annotation_path = notebook_dir + '/data/test2/sample_case_annotation.csv'\n",
    "if_law_applied_path = notebook_dir + '/data/test2/if_law_applied.csv'\n",
    "\n",
    "# Read the sample_case_annotation.csv and if_law_applied.csv\n",
    "sample_case_annotation_df = pd.read_csv(sample_case_annotation_path, encoding='latin1')\n",
    "if_law_applied_df = pd.read_csv(if_law_applied_path, encoding='latin1')\n",
    "\n",
    "# Iterate over files in files_not_in_legislation\n",
    "for file_name in files_not_in_legislation:\n",
    "    file_path = os.path.join(csv_cases_path, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        # Read the CSV file\n",
    "        file_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Extract the URLs from the file\n",
    "        file_urls = file_df['case_uri'].unique()\n",
    "        \n",
    "        # Check which URLs are present in sample_case_annotation.csv\n",
    "        in_sample_case_annotation = sample_case_annotation_df[sample_case_annotation_df['URL'].isin(file_urls)]\n",
    "        \n",
    "        # Check which URLs are present in if_law_applied.csv\n",
    "        in_if_law_applied = if_law_applied_df[if_law_applied_df['URL'].isin(file_urls)]\n",
    "        \n",
    "        print(f\"File: {file_name}\")\n",
    "        print(\"URLs found in sample_case_annotation.csv:\")\n",
    "        print(in_sample_case_annotation['URL'].unique())\n",
    "        print(\"URLs found in if_law_applied.csv:\")\n",
    "        print(in_if_law_applied['URL'].unique())\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openAIHandler import law_application_matcher\n",
    "from openAIHandler import ModelSelector\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def analyze_caselaw_paragraphs_from_csv(caselaw_csv_path, legislation_sections, paragraph_column='text', id_column=None, llm=None):\n",
    "    \"\"\"\n",
    "    Analyzes case law paragraphs from a CSV file and matches them with legislation sections.\n",
    "    \n",
    "    Args:\n",
    "        caselaw_csv_path (str): Path to the CSV file containing case law paragraphs\n",
    "        legislation_sections (dict or list): Dictionary mapping legislation IDs to texts,\n",
    "                                            or list of legislation texts\n",
    "        paragraph_column (str): Name of the column containing paragraph text\n",
    "        id_column (str, optional): Name of the column containing paragraph IDs\n",
    "        llm: Language model to use (defaults to ModelSelector's current model)\n",
    "    \n",
    "    Returns:\n",
    "        list: Results of the analysis with matches between paragraphs and legislation\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    \n",
    "    # Validate input path\n",
    "    if not os.path.exists(caselaw_csv_path):\n",
    "        raise FileNotFoundError(f\"CSV file not found at {caselaw_csv_path}\")\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(caselaw_csv_path)\n",
    "    \n",
    "    # Validate columns exist\n",
    "    if paragraph_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{paragraph_column}' not found in CSV\")\n",
    "    \n",
    "    if id_column and id_column not in df.columns:\n",
    "        raise ValueError(f\"ID column '{id_column}' not found in CSV\")\n",
    "    \n",
    "    # Use the ModelSelector to get the LLM if not provided\n",
    "    if llm is None:\n",
    "        llm = ModelSelector.get_llm(temperature=0)\n",
    "    \n",
    "    # Prepare legislation sections\n",
    "    if isinstance(legislation_sections, dict):\n",
    "        # If it's a dictionary, use the values\n",
    "        leg_texts = list(legislation_sections.values())\n",
    "        leg_ids = list(legislation_sections.keys())\n",
    "    else:\n",
    "        # If it's a list, use it directly\n",
    "        leg_texts = legislation_sections\n",
    "        leg_ids = [f\"Section_{i+1}\" for i in range(len(legislation_sections))]\n",
    "    \n",
    "    # Initialize results\n",
    "    all_results = []\n",
    "    \n",
    "    # Process each paragraph\n",
    "    for i, row in df.iterrows():\n",
    "        # Get paragraph text and ID\n",
    "        para_text = row[paragraph_column]\n",
    "        para_id = row[id_column] if id_column else i\n",
    "        \n",
    "        # Skip empty paragraphs\n",
    "        if pd.isna(para_text) or not para_text.strip():\n",
    "            continue\n",
    "        \n",
    "        para_result = {\n",
    "            \"paragraph_id\": para_id,\n",
    "            \"paragraph_text\": para_text[:150] + \"...\" if len(para_text) > 150 else para_text,\n",
    "            \"matches\": []\n",
    "        }\n",
    "        \n",
    "        # Check each legislation section\n",
    "        for leg_id, leg_text in zip(leg_ids, leg_texts):\n",
    "            # Skip empty legislation text\n",
    "            if pd.isna(leg_text) or not leg_text.strip():\n",
    "                continue\n",
    "                \n",
    "            # Analyze the paragraph against this legislation section\n",
    "            match_result = law_application_matcher(para_text, leg_text, llm)\n",
    "            \n",
    "            # If there's an application and it matches this legislation, add to results\n",
    "            if match_result.get(\"contains_application\", False) and \\\n",
    "               match_result.get(\"legislation_match\", {}).get(\"is_match\", False):\n",
    "                para_result[\"matches\"].append({\n",
    "                    \"legislation_id\": leg_id,\n",
    "                    \"legislation_text\": leg_text[:150] + \"...\" if len(leg_text) > 150 else leg_text,\n",
    "                    \"match_details\": match_result[\"legislation_match\"][\"matches\"]\n",
    "                })\n",
    "        \n",
    "        # Only include paragraphs with at least one match\n",
    "        if para_result[\"matches\"]:\n",
    "            all_results.append(para_result)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "def analyze_caselaw_df(caselaw_df, legislation_sections, paragraph_column='text', id_column=None, llm=None):\n",
    "    \"\"\"\n",
    "    Analyzes case law paragraphs from a pandas DataFrame and matches them with legislation sections.\n",
    "    \n",
    "    Args:\n",
    "        caselaw_df (DataFrame): Pandas DataFrame containing case law paragraphs\n",
    "        legislation_sections (dict or list): Dictionary mapping legislation IDs to texts,\n",
    "                                            or list of legislation texts\n",
    "        paragraph_column (str): Name of the column containing paragraph text\n",
    "        id_column (str, optional): Name of the column containing paragraph IDs\n",
    "        llm: Language model to use (defaults to ModelSelector's current model)\n",
    "    \n",
    "    Returns:\n",
    "        list: Results of the analysis with matches between paragraphs and legislation\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Validate columns exist\n",
    "    if paragraph_column not in caselaw_df.columns:\n",
    "        raise ValueError(f\"Column '{paragraph_column}' not found in DataFrame\")\n",
    "    \n",
    "    if id_column and id_column not in caselaw_df.columns:\n",
    "        raise ValueError(f\"ID column '{id_column}' not found in DataFrame\")\n",
    "    \n",
    "    # Use the ModelSelector to get the LLM if not provided\n",
    "    if llm is None:\n",
    "        llm = ModelSelector.get_llm(temperature=0)\n",
    "    \n",
    "    # Prepare legislation sections\n",
    "    if isinstance(legislation_sections, dict):\n",
    "        # If it's a dictionary, use the values\n",
    "        leg_texts = list(legislation_sections.values())\n",
    "        leg_ids = list(legislation_sections.keys())\n",
    "    else:\n",
    "        # If it's a list, use it directly\n",
    "        leg_texts = legislation_sections\n",
    "        leg_ids = [f\"Section_{i+1}\" for i in range(len(legislation_sections))]\n",
    "    \n",
    "    # Initialize results\n",
    "    all_results = []\n",
    "    \n",
    "    # Process each paragraph\n",
    "    for i, row in caselaw_df.iterrows():\n",
    "        # Get paragraph text and ID\n",
    "        para_text = row[paragraph_column]\n",
    "        para_id = row[id_column] if id_column else i\n",
    "        \n",
    "        # Skip empty paragraphs\n",
    "        if pd.isna(para_text) or not para_text.strip():\n",
    "            continue\n",
    "        \n",
    "        para_result = {\n",
    "            \"paragraph_id\": para_id,\n",
    "            \"paragraph_text\": para_text[:150] + \"...\" if len(para_text) > 150 else para_text,\n",
    "            \"matches\": []\n",
    "        }\n",
    "        \n",
    "        # Check each legislation section\n",
    "        for leg_id, leg_text in zip(leg_ids, leg_texts):\n",
    "            # Skip empty legislation text\n",
    "            if pd.isna(leg_text) or not leg_text.strip():\n",
    "                continue\n",
    "                \n",
    "            # Analyze the paragraph against this legislation section\n",
    "            match_result = law_application_matcher(para_text, leg_text, llm)\n",
    "            \n",
    "            # If there's an application and it matches this legislation, add to results\n",
    "            if match_result.get(\"contains_application\", False) and \\\n",
    "               match_result.get(\"legislation_match\", {}).get(\"is_match\", False):\n",
    "                para_result[\"matches\"].append({\n",
    "                    \"legislation_id\": leg_id,\n",
    "                    \"legislation_text\": leg_text[:150] + \"...\" if len(leg_text) > 150 else leg_text,\n",
    "                    \"match_details\": match_result[\"legislation_match\"][\"matches\"]\n",
    "                })\n",
    "        \n",
    "        # Only include paragraphs with at least one match\n",
    "        if para_result[\"matches\"]:\n",
    "            all_results.append(para_result)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "def save_analysis_results(results, output_path):\n",
    "    \"\"\"\n",
    "    Saves analysis results to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        results (list): Analysis results from analyze_caselaw_paragraphs_*\n",
    "        output_path (str): Path where to save the JSON file\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Save results to JSON file\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"Results saved to {output_path}\")\n",
    "    \n",
    "    # Return count of paragraphs with matches\n",
    "    return len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"path/to/your/caselaw.csv\")\n",
    "\n",
    "# Load legislation sections\n",
    "legislation_sections = {\n",
    "    \"Section 1\": \"The text of legislation section 1...\",\n",
    "    \"Section 2\": \"The text of legislation section 2...\"\n",
    "}\n",
    "\n",
    "# Run the analysis directly on the DataFrame\n",
    "results = analyze_caselaw_df(\n",
    "    caselaw_df=df,\n",
    "    legislation_sections=legislation_sections,\n",
    "    paragraph_column=\"text\",\n",
    "    id_column=\"para_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage function to demonstrate how to use the matcher\n",
    "def example_law_application_analysis(case_paras, legislation_sections):\n",
    "    \"\"\"\n",
    "    Example function showing how to use the law_application_matcher on multiple paragraphs\n",
    "    and legislation sections.\n",
    "    \n",
    "    Args:\n",
    "        case_paras (list): List of paragraph texts from case law\n",
    "        legislation_sections (list): List of legislation section texts to match against\n",
    "    \n",
    "    Returns:\n",
    "        list: Results of the analysis for each paragraph\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get LLM once for all analyses\n",
    "    llm = ModelSelector.get_llm(temperature=0)\n",
    "    \n",
    "    # For each paragraph, analyze application and match with legislation\n",
    "    for para in case_paras:\n",
    "        para_result = {\n",
    "            \"paragraph\": para[:100] + \"...\" if len(para) > 100 else para,\n",
    "            \"matches\": []\n",
    "        }\n",
    "        \n",
    "        # For each legislation section, check if there's a match\n",
    "        for section in legislation_sections:\n",
    "            match_result = law_application_matcher(para, section, llm)\n",
    "            \n",
    "            # If there's an application and it matches this legislation section, add to results\n",
    "            if match_result.get(\"contains_application\", False) and \\\n",
    "               match_result.get(\"legislation_match\", {}).get(\"is_match\", False):\n",
    "                para_result[\"matches\"].append({\n",
    "                    \"legislation_section\": section[:100] + \"...\" if len(section) > 100 else section,\n",
    "                    \"match_details\": match_result[\"legislation_match\"][\"matches\"]\n",
    "                })\n",
    "        \n",
    "        # Only include paragraphs that have at least one match\n",
    "        if para_result[\"matches\"]:\n",
    "            results.append(para_result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: ewca_crim_2019_2056.csv\n",
    "# URLs found in sample_case_annotation.csv:\n",
    "# []\n",
    "# URLs found in if_law_applied.csv:\n",
    "# ['https://caselaw.nationalarchives.gov.uk/ewca/crim/2019/2056']\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ETPADV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
