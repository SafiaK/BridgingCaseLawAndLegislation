{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the combined CSV file\n",
    "df = pd.read_csv('../data/test2/csvs_for_skip_phase_1/combined.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_uri</th>\n",
       "      <th>para_id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>references</th>\n",
       "      <th>application_of_law_phrases_actual</th>\n",
       "      <th>if_law_applied_actual</th>\n",
       "      <th>reason(optional)</th>\n",
       "      <th>application_of_law_phrases.1</th>\n",
       "      <th>applied provision</th>\n",
       "      <th>act</th>\n",
       "      <th>legislative term</th>\n",
       "      <th>if_law_applied_gpt-4o-mini</th>\n",
       "      <th>application_of_law_phrases_gpt-4o-mini</th>\n",
       "      <th>reason_gpt-4o-mini</th>\n",
       "      <th>if_law_applied_gpt-4o</th>\n",
       "      <th>application_of_law_phrases_gpt-4o</th>\n",
       "      <th>reason_gpt-4o</th>\n",
       "      <th>sections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2021_324#para_1</td>\n",
       "      <td>\\t    \\t 1.  \\t    \\t      \\t These proceedin...</td>\n",
       "      <td>[{'text': 'Charities Act 2011', 'href': 'http:...</td>\n",
       "      <td>[]</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph provides background information ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph provides background information ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            case_uri                  para_id  \\\n",
       "0  https://caselaw.nationalarchives.gov.uk/ewhc/c...  ewhc_ch_2021_324#para_1   \n",
       "\n",
       "                                          paragraphs  \\\n",
       "0   \\t    \\t 1.  \\t    \\t      \\t These proceedin...   \n",
       "\n",
       "                                          references  \\\n",
       "0  [{'text': 'Charities Act 2011', 'href': 'http:...   \n",
       "\n",
       "  application_of_law_phrases_actual if_law_applied_actual reason(optional)  \\\n",
       "0                                []                    no              NaN   \n",
       "\n",
       "  application_of_law_phrases.1 applied provision  act legislative term  \\\n",
       "0                          NaN               NaN  NaN              NaN   \n",
       "\n",
       "   if_law_applied_gpt-4o-mini application_of_law_phrases_gpt-4o-mini  \\\n",
       "0                           0                                     []   \n",
       "\n",
       "                                  reason_gpt-4o-mini  if_law_applied_gpt-4o  \\\n",
       "0  The paragraph provides background information ...                      0   \n",
       "\n",
       "  application_of_law_phrases_gpt-4o  \\\n",
       "0                                []   \n",
       "\n",
       "                                       reason_gpt-4o sections  \n",
       "0  The paragraph provides background information ...       {}  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_excel = pd.read_excel('../data/test2/csvs_for_skip_phase_1/response_with_Sections.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if_law_applied_gpt-4o value counts:\n",
      "if_law_applied_gpt-4o\n",
      "0    706\n",
      "1    232\n",
      "Name: count, dtype: int64\n",
      "\n",
      "if_law_applied_gpt-4o-mini value counts:\n",
      "if_law_applied_gpt-4o-mini\n",
      "0    529\n",
      "1    409\n",
      "Name: count, dtype: int64\n",
      "\n",
      "if_law_applied_actual value counts:\n",
      "if_law_applied_actual\n",
      "0    752\n",
      "1    186\n",
      "Name: count, dtype: int64\n",
      "\n",
      "contains_application value counts:\n",
      "contains_application\n",
      "0    685\n",
      "1    253\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert 'contains_application' from bool to int (0, 1)\n",
    "df_excel['contains_application'] = df_excel['contains_application'].astype(int)\n",
    "\n",
    "# Get value counts for each column\n",
    "print(\"if_law_applied_gpt-4o value counts:\")\n",
    "print(df_excel['if_law_applied_gpt-4o'].value_counts())\n",
    "\n",
    "print(\"\\nif_law_applied_gpt-4o-mini value counts:\")\n",
    "print(df_excel['if_law_applied_gpt-4o-mini'].value_counts())\n",
    "\n",
    "print(\"\\nif_law_applied_actual value counts:\")\n",
    "print(df_excel['if_law_applied_actual'].value_counts())\n",
    "\n",
    "print(\"\\ncontains_application value counts:\")\n",
    "print(df_excel['contains_application'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel.to_excel('../data/test2/csvs_for_skip_phase_1/response_with_Sections.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if_law_applied_gpt-4o: Precision=0.491, Recall=0.613, F1=0.545\n",
      "if_law_applied_gpt-4o-mini: Precision=0.320, Recall=0.704, F1=0.440\n",
      "contains_application: Precision=0.387, Recall=0.527, F1=0.446\n",
      "populated: Precision=0.491, Recall=0.613, F1=0.545\n",
      "populated2: Precision=0.320, Recall=0.704, F1=0.440\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# List of columns to evaluate\n",
    "columns_to_check = [\n",
    "    'if_law_applied_gpt-4o',\n",
    "    'if_law_applied_gpt-4o-mini',\n",
    "    'contains_application',\n",
    "    'populated',\n",
    "    'populated2'\n",
    "]\n",
    "\n",
    "y_true = df_excel['if_law_applied_actual']\n",
    "\n",
    "for col in columns_to_check:\n",
    "    y_pred = df_excel[col]\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"{col}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many matches are actual matches -- so for a legit match the caselaw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of legit matches: 80\n",
      "Total rows with at least one match: 245\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Check how many matches are actual matches\n",
    "def is_legit_match(row):\n",
    "    try:\n",
    "        matches = row['matches']\n",
    "        if isinstance(matches, str):\n",
    "            matches = ast.literal_eval(matches)\n",
    "        if not matches or not isinstance(matches, list):\n",
    "            return 0\n",
    "        para_text = row['paragraphs']\n",
    "        sections = row['sections']\n",
    "        if isinstance(sections, str):\n",
    "            try:\n",
    "                sections = ast.literal_eval(sections)\n",
    "            except Exception:\n",
    "                return 0\n",
    "        if not isinstance(sections, dict):\n",
    "            return 0\n",
    "        for match in matches:\n",
    "            # Check caselaw_excerpt in paragraph text\n",
    "            if not match.get('caselaw_excerpt') or match['caselaw_excerpt'] not in para_text:\n",
    "                continue\n",
    "            # Check section_id, legislation_excerpt, key_concept in sections\n",
    "            section_id = match.get('section_id')\n",
    "            legislation_excerpt = match.get('legislation_excerpt')\n",
    "            key_concept = match.get('key_concept')\n",
    "            if section_id not in sections:\n",
    "                continue\n",
    "            section_text = sections[section_id]\n",
    "            if (legislation_excerpt and legislation_excerpt in section_text) and (key_concept and key_concept in section_text):\n",
    "                return 1\n",
    "        return 0\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "df_excel['legit_match'] = df_excel.apply(is_legit_match, axis=1)\n",
    "print(\"Number of legit matches:\", df_excel['legit_match'].sum())\n",
    "print(\"Total rows with at least one match:\", (df_excel['matches'].apply(lambda x: len(ast.literal_eval(x)) if isinstance(x, str) and x.strip().startswith('[') else 0) > 0).sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the precision,recall,fmeasure\n",
    "#con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create populated column based on sections and if_law_applied_gpt-4o\n",
    "df['populated'] = df.apply(lambda row: 1 if (row['sections'] != {} and row['if_law_applied_gpt-4o'] == 1) else 0, axis=1)\n",
    "\n",
    "# Create populated2 column based on sections and if_law_applied_gpt-4o-mini\n",
    "df['populated2'] = df.apply(lambda row: 1 if (row['sections'] != {} and row['if_law_applied_gpt-4o-mini'] == 1) else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.49140893470790376, Recall: 0.6217391304347826, F1-score: 0.5489443378119002\n",
      "Precision: 0.3159922928709056, Recall: 0.7130434782608696, F1-score: 0.4379172229639519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "y_pred = df['populated']\n",
    "y_true = df['if_law_applied_actual']\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
    "\n",
    "y_pred = df['populated2']\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_positive = df[df['if_law_applied_actual']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_positive = selected_positive[selected_positive['sections'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>case_uri</th>\n",
       "      <th>para_id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>references</th>\n",
       "      <th>application_of_law_phrases_actual</th>\n",
       "      <th>if_law_applied_actual</th>\n",
       "      <th>reason(optional)</th>\n",
       "      <th>application_of_law_phrases.1</th>\n",
       "      <th>...</th>\n",
       "      <th>legislative term</th>\n",
       "      <th>if_law_applied_gpt-4o-mini</th>\n",
       "      <th>application_of_law_phrases_gpt-4o-mini</th>\n",
       "      <th>reason_gpt-4o-mini</th>\n",
       "      <th>if_law_applied_gpt-4o</th>\n",
       "      <th>application_of_law_phrases_gpt-4o</th>\n",
       "      <th>reason_gpt-4o</th>\n",
       "      <th>sections</th>\n",
       "      <th>populated</th>\n",
       "      <th>populated2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2021_324#para_12</td>\n",
       "      <td>\\n\\t   \\n\\t 12. \\n\\t   \\n\\t     \\n\\t Moreover,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>['clauses 4.3 and 4.5, read together, are quit...</td>\n",
       "      <td>The paragraph applies legal principles regardi...</td>\n",
       "      <td>1</td>\n",
       "      <td>['clauses 4.3 and 4.5, read together, are quit...</td>\n",
       "      <td>The paragraph applies specific clauses of a co...</td>\n",
       "      <td>{'id/ukpga/2011/25_section_344': '344 Other mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1  Unnamed: 0  \\\n",
       "11            11          11   \n",
       "\n",
       "                                             case_uri  \\\n",
       "11  https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "\n",
       "                     para_id  \\\n",
       "11  ewhc_ch_2021_324#para_12   \n",
       "\n",
       "                                           paragraphs references  \\\n",
       "11  \\n\\t   \\n\\t 12. \\n\\t   \\n\\t     \\n\\t Moreover,...         []   \n",
       "\n",
       "   application_of_law_phrases_actual  if_law_applied_actual reason(optional)  \\\n",
       "11                             [nan]                      1              NaN   \n",
       "\n",
       "   application_of_law_phrases.1  ... legislative term  \\\n",
       "11                          NaN  ...              NaN   \n",
       "\n",
       "   if_law_applied_gpt-4o-mini  \\\n",
       "11                          1   \n",
       "\n",
       "               application_of_law_phrases_gpt-4o-mini  \\\n",
       "11  ['clauses 4.3 and 4.5, read together, are quit...   \n",
       "\n",
       "                                   reason_gpt-4o-mini if_law_applied_gpt-4o  \\\n",
       "11  The paragraph applies legal principles regardi...                     1   \n",
       "\n",
       "                    application_of_law_phrases_gpt-4o  \\\n",
       "11  ['clauses 4.3 and 4.5, read together, are quit...   \n",
       "\n",
       "                                        reason_gpt-4o  \\\n",
       "11  The paragraph applies specific clauses of a co...   \n",
       "\n",
       "                                             sections populated populated2  \n",
       "11  {'id/ukpga/2011/25_section_344': '344 Other mi...         1          1  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_positive.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 1152\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Get all CSV files in the directory\n",
    "csv_files = glob.glob('../data/test2/csv_cases/*.csv')\n",
    "\n",
    "# Read and combine all CSV files\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Print total number of rows\n",
    "print(f\"Total number of rows: {len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df['sections']=df['sections'].apply(ast.literal_eval)\n",
    "# Select rows where sections column is not an empty dictionary\n",
    "df_with_sections = df[df['sections'].apply(lambda x: isinstance(x, dict) and len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_with_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sections.to_csv('../data/test2/csvs_for_skip_phase_1/withsections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sections = pd.read_csv('../data/test2/csvs_for_skip_phase_1/withsections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input saved to: ../data/test2/csvs_for_skip_phase_1/_openai_batch_input_with_Sections2.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/test2/csvs_for_skip_phase_1/_openai_batch_input_with_Sections2.jsonl'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "#make a jsonl file now\n",
    "def make_batch_jsonl_from_csv(df, system_prompt,output_dir_file_path=\".\"):\n",
    "    \n",
    "\n",
    "    required_columns = ['para_id', 'paragraphs']\n",
    "    paragraph_column = 'paragraphs'\n",
    "    para_id_col = 'para_id'\n",
    "    \n",
    "\n",
    "    jsonl_lines =[]\n",
    "    rid=1\n",
    "    for idx, row in df.iterrows():\n",
    "        para_text = row[paragraph_column]\n",
    "        para_id_val = row[para_id_col]\n",
    "        sections_dict = row['sections']\n",
    "\n",
    "        # Skip empty paragraphs\n",
    "        if pd.isna(para_text) or not str(para_text).strip():\n",
    "            continue\n",
    "        if not sections_dict:\n",
    "            continue\n",
    "        sections_str  = json.dumps(sections_dict)\n",
    "        system_prompt = \"\"\"\n",
    "        \n",
    "        You are a specialized legal analyst evaluating case law paragraphs and matching them with legislation.\n",
    "        Follow this chain-of-thought process to analyze legal text:\n",
    "        \n",
    "        STEP 1: DETERMINE IF PARAGRAPH CONTAINS APPLICATION OF LAW\n",
    "        First, analyze if the paragraph applies law to specific facts using these criteria:\n",
    "        \n",
    "        APPLICATION OF LAW DEFINITION:\n",
    "        An application of law is where statutory legal provisions are applied to the specific facts of the case at hand. This goes beyond merely citing or discussing law in the abstract and without specific reference to the facts of the case at hand\n",
    "\n",
    "        \n",
    "        INDICATORS OF APPLICATION OF LAW:\n",
    "        - The judge connects specific statutory legal provisions to the specific factual circumstances.  \n",
    "        - Text shows reasoning that explains how the law resolves the specific facts\n",
    "        - Contains judicial analysis leading to a conclusion based on legal principles\n",
    "        - Legal tests or criteria are applied to case facts\n",
    "        \n",
    "        NOT APPLICATIONS OF LAW:\n",
    "        - Mere citations without application to facts\n",
    "        - Background information or case history\n",
    "        - Statements about jurisdiction or general legal explanations\n",
    "        - Summaries of arguments without judicial analysis\n",
    "        - Restatements of previous cases without connecting to current facts                                                                      \n",
    "        ### Focus Areas for Your Decision:\n",
    "        1. **Look for legal reasoning** that directly connects the law to the facts.\n",
    "        2. Ensure the text demonstrates the judge’s thought process, not just a citation of legal principles or case history.\n",
    "                      \n",
    "        \n",
    "        STEP 2: IF APPLICATION EXISTS, MATCH WITH LEGISLATION\n",
    "        Only if the paragraph contains application of law, analyze whether the the given legislation sections contain the clause that is applied:\n",
    "        \n",
    "        MATCHING CRITERIA:\n",
    "        - Which law/clause is applied in the paragraph\n",
    "        - Clear interpretative relationship (case law explains/applies the legislation)\n",
    "        - Substantive connection (not merely tangential mentions)                            \n",
    "        Your response must follow this exact format with chain-of-thought reasoning:\n",
    "        1. First explicitly state your STEP 1 reasoning about whether application exists\n",
    "        2. Give a clear YES/NO decision on whether application of law exists\n",
    "        3. Only if YES, continue with STEP 2 reasoning about legislation matching\n",
    "        4. End with a properly formatted JSON that includes all analysis results\n",
    "        \n",
    "        YOUR OUTPUT MUST BE FORMATTED AS A VALID JSON OBJECT. Do not include any explanations, notes, or text outside of the JSON object.\n",
    "\n",
    "        The final JSON should follow this structure:\n",
    "        {{\n",
    "         \"para_id\": paragraph identifier(para_id) sent as an idntifier of record,\n",
    "          \"contains_application\": true/false,\n",
    "          \"application_reasoning\": \"explanation of why paragraph does/doesn't contain application\",\n",
    "          \"matches\": [\n",
    "              {{\n",
    "                \"caselaw_excerpt\": \"phrase/excerpt from case law\",\n",
    "                \"section_id\":\"section_id from which the law is applied\",\n",
    "                \"legislation_excerpt: \"corresponding phrase/excerpt from legislation\",\n",
    "                \"key_concept\": \"core legal concept being applied(from legislation_excerpt) should be an excerpt/verbatim \",\n",
    "                \"confidence\"`: \"High\", \"Medium\", or \"Low\" based on how confident you are that it is actually where law is applied.\n",
    "            ]\n",
    "          }}\n",
    "        }}\n",
    "        \n",
    "\n",
    "        Examples:\n",
    "        \"Para_id\" : \"ewfc_2025_41#para_38\"\n",
    "        \"Para_text\" : \"38. Having weighed the arguments outlined above, I am satisfied that I should not refuse to determine Mr J‚Äôs application ( section 55 A(5)  FLA 1986 ).  As I have made clear, I could only do so if I were to consider that the determination of the application would ‚Äúnot be in the best interests of‚Äù A and/or B.  In this case, I have approached the jurisdictional gateway issue by considering four key issues:  \n",
    "\t   i) The children‚Äôs ascertainable views about the application; \n",
    "\t   ii) Whether there is evidence that the mere fact of considering the application would be likely to be harmful to the children; \n",
    "\t  iii) Whether the application, if granted, would be likely to have such deleterious consequences for the children that I should not even proceed to determine it; \n",
    "\t    iv) How determination of the application fits with the  \n",
    "\t     Article 8  ECHR rights of the individual members of the family.\"\n",
    "\n",
    "    \"Legislation text\": \"{'id/ukpga/1986/55_section_55A': '55A Declarations of parentage. (1) Subject to the following provisions of this section, any person may apply to the High Court or the family court for a declaration as to whether or not a person named in the application is or was the parent of another person so named. (2) A court shall have jurisdiction to entertain an application under subsection (1) above if, and only if, either of the persons named in it for the purposes of that subsection‚Äî (a) is domiciled in England and Wales on the date of the application, or (b) has been habitually resident in England and Wales throughout the period of one year ending with that date, or (c) died before that date and either‚Äî (i) was at death domiciled in England and Wales, or (ii) had been habitually resident in England and Wales throughout the period of one year ending with the date of death. (3) Except in a case falling within subsection (4) below, the court shall refuse to hear an application under subsection (1) above unless it considers that the applicant has a sufficient personal interest in the determination of the application (but this is subject to section 27 of the Child Support Act 1991). (4) The excepted cases are where the declaration sought is as to whether or not‚Äî (a) the applicant is the parent of a named person; (b) a named person is the parent of the applicant; or (c) a named person is the other parent of a named child of the applicant. (5) Where an application under subsection (1) above is made and one of the persons named in it for the purposes of that subsection is a child, the court may refuse to hear the application if it considers that the determination of the application would not be in the best interests of the child. (6) Where a court refuses to hear an application under subsection (1) above it may order that the applicant may not apply again for the same declaration without leave of the court. (7) Where a declaration is made by a court on an application under subsection (1) above, the prescribed officer of the court shall notify the Registrar General, in such a manner and within such period as may be prescribed, of the making of that declaration.'}\"\n",
    "\n",
    "    Response:\n",
    "        {\n",
    "         \"para_id\": ewfc_2025_41#para_38,\n",
    "          \"contains_application\": true,\n",
    "          \"application_reasoning\": \"The paragraph demonstrates an application of law by considering specific legal criteria (best interests of the children) in the context of the case facts, which is a direct application of section 55 A(5) FLA 1986.\",\n",
    "          \"matches\": [\n",
    "              {\n",
    "                \"caselaw_excerpt\": \"I could only do so if I were to consider that the determination of the application would 'not be in the best interests of' A and/or B.\",\n",
    "                \"section_id\":'id_ukpga_1986_55_section_55A',\n",
    "                \"legislation_excerpt:\"application would not be in the best interests of the child\" ,\n",
    "                \"key_concept\": \"application would not be in the best interests of the child\",\n",
    "                \"confidence\"`: \"High\"\n",
    "            \n",
    "          }]\n",
    "        }\n",
    "        \n",
    "        If there's no application of law, the \"legislation_match\" field should be null.\n",
    "        Always include proper chain-of-thought reasoning before providing the final JSON.\n",
    "        Never make anything up or provide false information.\n",
    "        Make your to extract the \"caselaw_excerpt\" from the \"Para_text\" and \"legislation_excerpt\" and \"key_concept\" must be from \"Legislation text\" .\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        \"Para_id\":{para_id_val}\n",
    "\n",
    "        \"Para_text\":{para_text}\n",
    "        \n",
    "        \"Legislation text\":{sections_str}\n",
    "        \"\"\"\n",
    "\n",
    "        jsonl_lines.append({\n",
    "            \"custom_id\":f\"request_{rid}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": { \"model\": \"gpt-4o\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]}\n",
    "        })\n",
    "        rid = rid + 1\n",
    "    output_path = os.path.join(output_dir, f\"_openai_batch_input_with_Sections2.jsonl\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for obj in jsonl_lines:\n",
    "            f.write(json.dumps(obj) + \"\\n\")\n",
    "\n",
    "    print(f\"Batch input saved to: {output_path}\")\n",
    "    return output_path\n",
    "make_batch_jsonl_from_csv(df_with_sections,\"../data/test2/csvs_for_skip_phase_1\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_with_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_uri', 'para_id_x', 'paragraphs', 'references',\n",
       "       'application_of_law_phrases_actual', 'if_law_applied_actual',\n",
       "       'reason(optional)', 'application_of_law_phrases.1', 'applied provision',\n",
       "       'act', 'legislative term', 'if_law_applied_gpt-4o-mini',\n",
       "       'application_of_law_phrases_gpt-4o-mini', 'reason_gpt-4o-mini',\n",
       "       'if_law_applied_gpt-4o', 'application_of_law_phrases_gpt-4o',\n",
       "       'reason_gpt-4o', 'sections', 'populated', 'populated2', 'index_y',\n",
       "       'para_id_y', 'contains_application', 'application_reasoning', 'matches',\n",
       "       'request_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_sections = df_merged_sections.drop(['index_x', 'Unnamed: 0.1', 'Unnamed: 0'], axis=1)\n",
    "df_merged_sections.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "251023.93s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import openpyxl\n",
    "except ImportError:\n",
    "    !pip install openpyxl\n",
    "    import openpyxl\n",
    "\n",
    "# First clean up the dataframe\n",
    "df_merged_sections_up = df_merged_sections.dropna(how='all', axis=1)  # Remove empty columns\n",
    "df_merged_sections_up = df_merged_sections_up.drop_duplicates()  # Remove duplicate rows\n",
    "\n",
    "# Convert all columns to string type to prevent Excel formatting issues\n",
    "for col in df_merged_sections_up.columns:\n",
    "    df_merged_sections_up[col] = df_merged_sections_up[col].astype(str)\n",
    "\n",
    "# Save as Excel file\n",
    "df_merged_sections_up.to_excel('../data/test2/csvs_for_skip_phase_1/response_with_Sections.xlsx',\n",
    "                         index=False,  # Don't save index\n",
    "                         engine='openpyxl')  # Use openpyxl engine for Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_sections = df_merged_sections_up.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching values: 799\n",
      "Number of different values: 139\n"
     ]
    }
   ],
   "source": [
    "# Convert contains_application to binary values (0,1)\n",
    "df_merged_sections['contains_application'] = df_merged_sections['contains_application'].map({'True': 1, 'False': 0})\n",
    "\n",
    "df_merged_sections['if_law_applied_gpt-4o'] = df_merged_sections['if_law_applied_gpt-4o'].astype(int)\n",
    "df_merged_sections['contains_application'] = df_merged_sections['contains_application'].astype(int)\n",
    "# Compare contains_application with if_law_applied_gpt-4o to check if they have same values\n",
    "comparison = df_merged_sections['contains_application'] == df_merged_sections['if_law_applied_gpt-4o']\n",
    "print(\"Number of matching values:\", comparison.sum())\n",
    "print(\"Number of different values:\", (~comparison).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = df_merged_sections['contains_application'] == df_merged_sections['if_law_applied_actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching values: 0\n",
      "Number of different values: 938\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of matching values:\", comparison.sum())\n",
    "print(\"Number of different values:\", (~comparison).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if_law_applied_gpt-4o\n",
       "0    706\n",
       "1    232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_sections['if_law_applied_gpt-4o'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contains_application</th>\n",
       "      <th>if_law_applied_gpt-4o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>938 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     contains_application if_law_applied_gpt-4o\n",
       "0                       0                     0\n",
       "1                       0                     0\n",
       "2                       0                     0\n",
       "3                       0                     0\n",
       "4                       0                     0\n",
       "..                    ...                   ...\n",
       "933                     0                     0\n",
       "934                     0                     0\n",
       "935                     1                     1\n",
       "936                     0                     0\n",
       "937                     0                     0\n",
       "\n",
       "[938 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_sections[['contains_application','if_law_applied_gpt-4o']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sections_index = df_with_sections.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>case_uri</th>\n",
       "      <th>para_id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>references</th>\n",
       "      <th>application_of_law_phrases_actual</th>\n",
       "      <th>if_law_applied_actual</th>\n",
       "      <th>reason(optional)</th>\n",
       "      <th>...</th>\n",
       "      <th>legislative term</th>\n",
       "      <th>if_law_applied_gpt-4o-mini</th>\n",
       "      <th>application_of_law_phrases_gpt-4o-mini</th>\n",
       "      <th>reason_gpt-4o-mini</th>\n",
       "      <th>if_law_applied_gpt-4o</th>\n",
       "      <th>application_of_law_phrases_gpt-4o</th>\n",
       "      <th>reason_gpt-4o</th>\n",
       "      <th>sections</th>\n",
       "      <th>populated</th>\n",
       "      <th>populated2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2021_324#para_2</td>\n",
       "      <td>\\n\\t   \\n\\t 2. \\n\\t   \\n\\t     \\n\\t In summary...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph discusses a dispute regarding a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph describes a factual dispute rega...</td>\n",
       "      <td>{'id/ukpga/2011/25_section_344': '344 Other mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2021_324#para_3</td>\n",
       "      <td>\\n\\t   \\n\\t 3. \\n\\t   \\n\\t     \\n\\t The practi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph discusses the practical signific...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph discusses the practical implicat...</td>\n",
       "      <td>{'id/ukpga/2011/25_section_181': '181 Power to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0.1  Unnamed: 0  \\\n",
       "0      1             1           1   \n",
       "1      2             2           2   \n",
       "\n",
       "                                            case_uri                  para_id  \\\n",
       "0  https://caselaw.nationalarchives.gov.uk/ewhc/c...  ewhc_ch_2021_324#para_2   \n",
       "1  https://caselaw.nationalarchives.gov.uk/ewhc/c...  ewhc_ch_2021_324#para_3   \n",
       "\n",
       "                                          paragraphs references  \\\n",
       "0  \\n\\t   \\n\\t 2. \\n\\t   \\n\\t     \\n\\t In summary...         []   \n",
       "1  \\n\\t   \\n\\t 3. \\n\\t   \\n\\t     \\n\\t The practi...         []   \n",
       "\n",
       "  application_of_law_phrases_actual  if_law_applied_actual reason(optional)  \\\n",
       "0                                []                      0              NaN   \n",
       "1                                []                      0              NaN   \n",
       "\n",
       "   ... legislative term if_law_applied_gpt-4o-mini  \\\n",
       "0  ...              NaN                          0   \n",
       "1  ...              NaN                          0   \n",
       "\n",
       "  application_of_law_phrases_gpt-4o-mini  \\\n",
       "0                                     []   \n",
       "1                                     []   \n",
       "\n",
       "                                  reason_gpt-4o-mini  if_law_applied_gpt-4o  \\\n",
       "0  The paragraph discusses a dispute regarding a ...                      0   \n",
       "1  The paragraph discusses the practical signific...                      0   \n",
       "\n",
       "  application_of_law_phrases_gpt-4o  \\\n",
       "0                                []   \n",
       "1                                []   \n",
       "\n",
       "                                       reason_gpt-4o  \\\n",
       "0  The paragraph describes a factual dispute rega...   \n",
       "1  The paragraph discusses the practical implicat...   \n",
       "\n",
       "                                            sections populated populated2  \n",
       "0  {'id/ukpga/2011/25_section_344': '344 Other mi...         0          0  \n",
       "1  {'id/ukpga/2011/25_section_181': '181 Power to...         0          0  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_sections_index.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selcted_processed = df_selcted_processed.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file '../data/test2/csvs_for_skip_phase_1/_openai_batch_input_with_Sections.jsonl'\n",
    "#every line is a json\n",
    "#make a df with custom_id and in messages get the \n",
    "request_id and paragrapgh -- embed with orignal df to get para_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "\n",
    "OPENAI_API_KEY= os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai_api_key = OPENAI_API_KEY\n",
    "\n",
    "print(openai_api_key)\n",
    "\n",
    "# Assuming you have your OpenAI API key set up\n",
    "\n",
    "# 1. Prepare the input file (e.g., batch_input.jsonl)\n",
    "\n",
    "# 2. Upload the file\n",
    "def get_batch_job(input_file):\n",
    "    client = openai.OpenAI()\n",
    "    batch_input_file = client.files.create(file=open(input_file, \"rb\"), purpose=\"batch\")\n",
    "\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch_job = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    )\n",
    "    return batch_job\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job =get_batch_job('../data/newData/combined_law_application_batch.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: in_progress\n",
      "Job status: in_progress\n",
      "Job status: completed\n"
     ]
    }
   ],
   "source": [
    "client = openai.OpenAI()\n",
    "# 4. Monitor the job (example using a simple loop)\n",
    "while batch_job.status != \"completed\":\n",
    "    batch_job = client.batches.retrieve(batch_job.id)\n",
    "    print(f\"Job status: {batch_job.status}\")\n",
    "    # Add a delay to avoid excessive API calls\n",
    "    \n",
    "    time.sleep(40)\n",
    "\n",
    "# 5. Download the results\n",
    "output_file = client.files.retrieve(batch_job.output_file_id)\n",
    "\n",
    "# Download the file from the URL (using a library like requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-5cUc4rTC35g1FxAmw8SQ5p'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.list().data[0].output_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[Batch](data=[Batch(id='batch_683a26e3f7348190b06d2e3c890da271', completion_window='24h', created_at=1748641507, endpoint='/v1/chat/completions', input_file_id='file-MopbzxrafAsPKVWboreWiq', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748643783, error_file_id=None, errors=None, expired_at=None, expires_at=1748727907, failed_at=None, finalizing_at=1748643623, in_progress_at=1748641510, metadata=None, output_file_id='file-5cUc4rTC35g1FxAmw8SQ5p', request_counts=BatchRequestCounts(completed=1858, failed=0, total=1858)), Batch(id='batch_6835f8fc705c8190b9d09dee7b122788', completion_window='24h', created_at=1748367612, endpoint='/v1/chat/completions', input_file_id='file-MpXcBTCoYiCXohBW9d6tMk', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748368713, error_file_id=None, errors=None, expired_at=None, expires_at=1748454012, failed_at=None, finalizing_at=1748368627, in_progress_at=1748367613, metadata=None, output_file_id='file-9KVE4C7wK1kWXJqrEDek54', request_counts=BatchRequestCounts(completed=1108, failed=0, total=1108)), Batch(id='batch_6830b939b04c81908695504aa9423f7b', completion_window='24h', created_at=1748023609, endpoint='/v1/chat/completions', input_file_id='file-NSAJTF2ra8hedzVba8QXZh', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748024834, error_file_id=None, errors=None, expired_at=None, expires_at=1748110009, failed_at=None, finalizing_at=1748024742, in_progress_at=1748023612, metadata=None, output_file_id='file-4CwqRuC4Pt8kfTaNbw3MNb', request_counts=BatchRequestCounts(completed=938, failed=0, total=938)), Batch(id='batch_682ef3c4b2348190a077a2faadacbc28', completion_window='24h', created_at=1747907524, endpoint='/v1/chat/completions', input_file_id='file-DZWFu7W4c9BrgNWzXYsi7P', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747907759, error_file_id=None, errors=None, expired_at=None, expires_at=1747993924, failed_at=None, finalizing_at=1747907697, in_progress_at=1747907526, metadata=None, output_file_id='file-UPsWKGcBEsiaMFZp7Yoj4m', request_counts=BatchRequestCounts(completed=938, failed=0, total=938)), Batch(id='batch_682dd555c8908190856ecdac4fa784a5', completion_window='24h', created_at=1747834197, endpoint='/v1/chat/completions', input_file_id='file-FqQ4ryRRUMzd4Egvor2jVo', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747834277, error_file_id=None, errors=None, expired_at=None, expires_at=1747920597, failed_at=None, finalizing_at=1747834266, in_progress_at=1747834199, metadata=None, output_file_id='file-RRg4A9Naez6mekbEiDA9at', request_counts=BatchRequestCounts(completed=177, failed=0, total=177)), Batch(id='batch_68266d92253c8190aeb7376380bd0fd0', completion_window='24h', created_at=1747348882, endpoint='/v1/chat/completions', input_file_id='file-VftBYNSVsnv8KQTcJ26SDc', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747352130, error_file_id=None, errors=None, expired_at=None, expires_at=1747435282, failed_at=None, finalizing_at=1747352123, in_progress_at=1747348883, metadata=None, output_file_id='file-BPT7ypSADWNkAZvEKAqvYL', request_counts=BatchRequestCounts(completed=57, failed=0, total=57)), Batch(id='batch_68266aed0c688190aa94530e77958a55', completion_window='24h', created_at=1747348205, endpoint='/v1/chat/completions', input_file_id='file-VLwcgvbukHp4iBViPb9U7q', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='unknown_parameter', line=1, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=2, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=3, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=4, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=5, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=6, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=7, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=8, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=9, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=10, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=11, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=12, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=13, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=14, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=15, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=16, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=17, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=18, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=19, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=20, message=\"Unknown parameter: 'metadata'.\", param='metadata')], object='list'), expired_at=None, expires_at=1747434605, failed_at=1747348206, finalizing_at=None, in_progress_at=None, metadata={'description': 'test extraction job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_68266acf9bcc8190961f3d88f45f5e62', completion_window='24h', created_at=1747348175, endpoint='/v1/chat/completions', input_file_id='file-XdJqiew38Y5LyYfjeMRM26', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='unknown_parameter', line=1, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=2, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=3, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=4, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=5, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=6, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=7, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=8, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=9, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=10, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=11, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=12, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=13, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=14, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=15, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=16, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=17, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=18, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=19, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=20, message=\"Unknown parameter: 'metadata'.\", param='metadata')], object='list'), expired_at=None, expires_at=1747434575, failed_at=1747348176, finalizing_at=None, in_progress_at=None, metadata={'description': 'test extraction job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_67ee51b58ab08190ae274a77e1ade182', completion_window='24h', created_at=1743671733, endpoint='/v1/chat/completions', input_file_id='file-YFgWFryRgXLoZhYH8SJQJA', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1743671801, error_file_id=None, errors=None, expired_at=None, expires_at=1743758133, failed_at=None, finalizing_at=1743671796, in_progress_at=1743671734, metadata=None, output_file_id='file-JEnmAkPEp2TYfUezvyMiit', request_counts=BatchRequestCounts(completed=93, failed=0, total=93)), Batch(id='batch_67bc62da9aa48190a4d93ec4adf842f5', completion_window='24h', created_at=1740399322, endpoint='/v1/chat/completions', input_file_id='file-L3E35zP8bkiJk6Xz89VsQp', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740399407, error_file_id=None, errors=None, expired_at=None, expires_at=1740485722, failed_at=None, finalizing_at=1740399406, in_progress_at=1740399323, metadata=None, output_file_id='file-9nbt441wVrvG9PFVxo4w56', request_counts=BatchRequestCounts(completed=10, failed=0, total=10)), Batch(id='batch_67bc6010ef048190bbecc2a2e77df890', completion_window='24h', created_at=1740398608, endpoint='/v1/chat/completions', input_file_id='file-YDzdjyrZbkYQGSbWrK5YG8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740398636, error_file_id='file-Qk1vjL3mZSXvESCxLk6KVt', errors=None, expired_at=None, expires_at=1740485008, failed_at=None, finalizing_at=1740398635, in_progress_at=1740398610, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=10, total=10)), Batch(id='batch_anewRG8OxTExjD4VUZV0wweY', completion_window='24h', created_at=1726660563, endpoint='/v1/chat/completions', input_file_id='file-rIBLKbZWNaNDCjSFNJIMx1AS', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726660831, error_file_id=None, errors=None, expired_at=None, expires_at=1726746963, failed_at=None, finalizing_at=1726660799, in_progress_at=1726660564, metadata=None, output_file_id='file-ClMe1o26UdQkBDCvTTOjTcaq', request_counts=BatchRequestCounts(completed=463, failed=0, total=463)), Batch(id='batch_ch2WCKqPhN4V44K9hgyVK8ry', completion_window='24h', created_at=1726141576, endpoint='/v1/chat/completions', input_file_id='file-XE8dejaINS2aJDflZh0Czz6H', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726142629, error_file_id=None, errors=None, expired_at=None, expires_at=1726227976, failed_at=None, finalizing_at=1726142586, in_progress_at=1726141578, metadata=None, output_file_id='file-erZQ4MaPSyd5MvkBemwP6nbS', request_counts=BatchRequestCounts(completed=512, failed=0, total=512)), Batch(id='batch_9ZQNztkTB89OYVr2ljqvBLcb', completion_window='24h', created_at=1725218550, endpoint='/v1/chat/completions', input_file_id='file-iiLHhBALE8TPrDA4G84NX2kn', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1725218926, error_file_id=None, errors=None, expired_at=None, expires_at=1725304950, failed_at=None, finalizing_at=1725218909, in_progress_at=1725218552, metadata=None, output_file_id='file-YThU64m6UnOyX2dZ8tUYyUvA', request_counts=BatchRequestCounts(completed=410, failed=0, total=410)), Batch(id='batch_7FgiISEC41hZRPipIIVFeTYi', completion_window='24h', created_at=1724966952, endpoint='/v1/chat/completions', input_file_id='file-Z1ZpAz3tTNtlreZLOq1NtHVf', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1724967136, error_file_id=None, errors=None, expired_at=None, expires_at=1725053352, failed_at=None, finalizing_at=1724967133, in_progress_at=1724966953, metadata=None, output_file_id='file-3YoaidQZFdVtN3xXHZdVwRra', request_counts=BatchRequestCounts(completed=60, failed=0, total=60)), Batch(id='batch_ugGDmT7GjUGmLaLCD6cuNjxc', completion_window='24h', created_at=1724959852, endpoint='/v1/chat/completions', input_file_id='file-uDoh4f2vZ6ppaZWHK2Iw0eng', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1724960020, error_file_id=None, errors=None, expired_at=None, expires_at=1725046252, failed_at=None, finalizing_at=1724959935, in_progress_at=1724959853, metadata=None, output_file_id='file-TEI8L8Ch48QYZoOAPF4G0SJs', request_counts=BatchRequestCounts(completed=20, failed=0, total=20)), Batch(id='batch_0pxvEMYR0nDQZp4AIl5H3pc6', completion_window='24h', created_at=1724853879, endpoint='/v1/chat/completions', input_file_id='file-ppK6pYedOGmMD5TaKSn49D7R', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1724854186, error_file_id=None, errors=None, expired_at=None, expires_at=1724940279, failed_at=None, finalizing_at=1724854185, in_progress_at=1724853880, metadata=None, output_file_id='file-Yf18YSxGv2Hevlg11Mbf9zbX', request_counts=BatchRequestCounts(completed=20, failed=0, total=20)), Batch(id='batch_zCBDLyAkFPSKNTYIfQSi8BaA', completion_window='24h', created_at=1724791165, endpoint='/v1/chat/completions', input_file_id='file-zWqS0lgEsQOb07qf8Qiqe39l', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1724791220, error_file_id=None, errors=None, expired_at=None, expires_at=1724877565, failed_at=None, finalizing_at=1724791219, in_progress_at=1724791166, metadata=None, output_file_id='file-L48bCgD8EUwsTRmU5fYDLYY7', request_counts=BatchRequestCounts(completed=13, failed=0, total=13)), Batch(id='batch_CmpIELqfZ0eDUuUGsDmMlyVR', completion_window='24h', created_at=1724150284, endpoint='/v1/chat/completions', input_file_id='file-7vZ6FXbeTTkuj4QjC2xDhYse', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1724150318, error_file_id=None, errors=None, expired_at=None, expires_at=1724236684, failed_at=None, finalizing_at=1724150317, in_progress_at=1724150285, metadata=None, output_file_id='file-lNAZGlWgKhZil457Zy1eukj3', request_counts=BatchRequestCounts(completed=8, failed=0, total=8)), Batch(id='batch_Pk8Rched1OYAjVdeUm5HNpI3', completion_window='24h', created_at=1723560091, endpoint='/v1/chat/completions', input_file_id='file-7nxh7AYn7ZX1qCnWI1NvpJLm', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1723560182, error_file_id=None, errors=None, expired_at=None, expires_at=1723646491, failed_at=None, finalizing_at=1723560181, in_progress_at=1723560092, metadata=None, output_file_id='file-ruOfG6CuTIGGhHnQxkt0Yhqr', request_counts=BatchRequestCounts(completed=5, failed=0, total=5))], object='list', first_id='batch_683a26e3f7348190b06d2e3c890da271', last_id='batch_Pk8Rched1OYAjVdeUm5HNpI3', has_more=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = 'file-5cUc4rTC35g1FxAmw8SQ5p'\n",
    "file_response = client.files.content(file_id)\n",
    "with open(\"../data/newData/output.jsonl\", \"wb\") as f:\n",
    "    f.write(file_response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai._legacy_response.HttpxBinaryResponseContent at 0x13829aed0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: Expecting ':' delimiter: line 11 column 19 (char 1156)\n",
      "Problematic content:\n",
      "{\n",
      "  \"para_id\": \"ewhc_qb_2016_2355#para_1\",\n",
      "  \"contains_application\": true,\n",
      "  \"application_reasoning\": \"The paragraph contains an application of law because it reflects judicial reasoning by connecting the specific statutory duty under section 2(2) of the Occupier's Liability Act 1957 to the factual circumstances of the case, where the judge found that G4S Care & Justice Services (UK) Ltd. breached their duty by not restoring electricity within a reasonable time, which caused injury to the claimant.\",\n",
      "  \"matches\": [\n",
      "    {\n",
      "      \"caselaw_excerpt\": \"the judge found that the Defendant, G4S Care & Justice Services (UK) Ltd., were in breach of their duty under section 2(2) of the Occupier’s Liability Act 1957 to take reasonable care to ensure that the Claimant was reasonably safe in using certain premises\",\n",
      "      \"section_id\": \"id_ukpga_Eliz2_5-6_31_section_2\",\n",
      "      \"legislation_excerpt\": \"The common duty of care is a duty to take such care as in all the circumstances of the case is reasonable to see that the visitor will be reasonably safe in using the premises\",\n",
      "      \"key_concept\": \"reasonably safe in using the premises\",\n",
      "      \"confidence\"`: \"High\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the JSONL file\n",
    "with open('../data/test2/csvs_for_skip_phase_1/_openai_batch_output_with_Sections2.jsonl', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Parse each line and extract the content\n",
    "results = []\n",
    "for line in lines:\n",
    "    data = json.loads(line)\n",
    "    content = data['response']['body']['choices'][0]['message']['content']\n",
    "    request_id = data['custom_id']\n",
    "    # Remove ```json and ``` strings\n",
    "    content = content.replace('```json\\n', '').replace('\\n```', '')\n",
    "    \n",
    "    try:\n",
    "        # Fix the JSON syntax error by replacing the missing colon\n",
    "        content = content.replace('\"legislation_excerpt: \"', '\"legislation_excerpt\": \"')\n",
    "        \n",
    "        # Parse the JSON content\n",
    "        result = json.loads(content)\n",
    "        # Add request_id to the result dictionary\n",
    "        result['request_id'] = request_id\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        print(\"Problematic content:\")\n",
    "        print(content)\n",
    "        # Try to fix common JSON issues (e.g., stray backticks or wrong quotes)\n",
    "        # Remove stray backticks or misplaced quote in \"confidence\"` key\n",
    "        content_fixed = re.sub(r'\"confidence\"`', '\"confidence\"', content)\n",
    "        try:\n",
    "            result = json.loads(content_fixed)\n",
    "            result['request_id'] = request_id\n",
    "            results.append(result)\n",
    "        except Exception as e2:\n",
    "            print(f\"Secondary error parsing JSON: {e2}\")\n",
    "            print(\"Still problematic content:\")\n",
    "            print(content_fixed)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_selcted_processed = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join columns on index df_selcted_processed and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_selcted_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v6/ylm2sy9s6ygbm9wjf__vgfqw0000gn/T/ipykernel_37076/1399893083.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_sections.drop_duplicates(subset=['para_id'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_with_sections.drop_duplicates(subset=['para_id'], inplace=True)\n",
    "\n",
    "df_selcted_processed.drop_duplicates(subset=['para_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join: rows with matching para_id in both DataFrames\n",
    "df_matched = df_with_sections.merge(df_selcted_processed, on='para_id', suffixes=('_orig', '_processed'))\n",
    "\n",
    "# Find para_id values in either DataFrame that do NOT have a match in the other\n",
    "para_ids_with_sections = set(df_with_sections['para_id'])\n",
    "para_ids_processed = set(df_selcted_processed['para_id'])\n",
    "para_ids_diff = (para_ids_with_sections ^ para_ids_processed)  # symmetric difference\n",
    "\n",
    "# Rows from both DataFrames with para_id not present in the other\n",
    "df_with_sections_diff = df_with_sections[df_with_sections['para_id'].isin(para_ids_diff)]\n",
    "df_selcted_processed_diff = df_selcted_processed[df_selcted_processed['para_id'].isin(para_ids_diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matched['contains_application'] = df_matched['contains_application'].map({True: 'yes', False: 'no'})\n",
    "len(df_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if_law_applied_actual\n",
      "0    716\n",
      "1    182\n",
      "Name: count, dtype: int64\n",
      "contains_application\n",
      "0    726\n",
      "1    172\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map 'no' to 0 and 'yes' to 1 for both columns\n",
    "y_true = df_matched['if_law_applied_actual'].map({'no': 0, 'yes': 1})\n",
    "y_pred = df_matched['contains_application'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "print(y_true.value_counts())\n",
    "print(y_pred.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched.to_csv('../data/test2/csvs_for_skip_phase_1/response_with_Sections_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4418604651162791, Recall: 0.4175824175824176, F1-score: 0.4293785310734463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# y_pred = df_matched['contains_application']\n",
    "# y_true = df_matched['if_law_applied_actual']\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the rows where contains_application is not equal to if_law_applied_actual\n",
    "df_mismatch = df_matched[df_matched['contains_application'] != df_matched['if_law_applied_actual']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mismatch.to_csv('../data/test2/csvs_for_skip_phase_1/mismatch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected and copied 400 files to /Users/apple/Documents/Swansea/Projects/pickedup\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Path to the parent folder containing year folders (e.g., '2001', '2002', ..., '2025')\n",
    "parent_folder = '/Users/apple/Documents/Swansea/Projects/Caselaw_having_legislation_reference_and_proper_paragraph_numbering'  # change this to your actual path\n",
    "pickup_folder = '/Users/apple/Documents/Swansea/Projects/pickedup'         # change this to your actual pickup folder\n",
    "\n",
    "# Get all year folders (assuming folder names are years)\n",
    "year_folders = [os.path.join(parent_folder, d) for d in os.listdir(parent_folder) if os.path.isdir(os.path.join(parent_folder, d)) and d.isdigit()]\n",
    "\n",
    "# Gather all CSV files per year\n",
    "year_csvs = {}\n",
    "total_files = 0\n",
    "for year_folder in year_folders:\n",
    "    csvs = glob.glob(os.path.join(year_folder, '*.csv'))\n",
    "    year_csvs[year_folder] = csvs\n",
    "    total_files += len(csvs)\n",
    "\n",
    "# Calculate how many files to pick from each year (proportional to their count)\n",
    "n_pick = 400\n",
    "selected_files = []\n",
    "for year_folder, csvs in year_csvs.items():\n",
    "    n_year = len(csvs)\n",
    "    if n_year == 0:\n",
    "        continue\n",
    "    n_select = int(round(n_pick * n_year / total_files))\n",
    "    # Randomly sample n_select files from this year\n",
    "    selected = random.sample(csvs, min(n_select, n_year))\n",
    "    selected_files.extend(selected)\n",
    "\n",
    "# If rounding caused <400, randomly add more; if >400, randomly remove some\n",
    "if len(selected_files) < n_pick:\n",
    "    all_csvs = [f for files in year_csvs.values() for f in files if f not in selected_files]\n",
    "    selected_files += random.sample(all_csvs, n_pick - len(selected_files))\n",
    "elif len(selected_files) > n_pick:\n",
    "    selected_files = random.sample(selected_files, n_pick)\n",
    "\n",
    "# Copy selected files to pickup folder\n",
    "os.makedirs(pickup_folder, exist_ok=True)\n",
    "for f in selected_files:\n",
    "    shutil.copy(f, pickup_folder)\n",
    "\n",
    "print(f\"Selected and copied {len(selected_files)} files to {pickup_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "pickup_folder = '/Users/apple/Documents/Swansea/Projects/pickedup'\n",
    "cases_folder = '../data/test2/csv_cases'\n",
    "\n",
    "# 1. Read all CSVs in pickup folder, collect their case_uri values\n",
    "pickup_files = glob.glob(os.path.join(pickup_folder, '*.csv'))\n",
    "pickup_case_uris = set()\n",
    "pickup_file_map = {}\n",
    "\n",
    "for f in pickup_files:\n",
    "    try:\n",
    "        df = pd.read_csv(f, nrows=1)\n",
    "        if 'case_uri' in df.columns:\n",
    "            case_uri = df['case_uri'].iloc[0]\n",
    "            pickup_case_uris.add(case_uri)\n",
    "            pickup_file_map[case_uri] = f\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "\n",
    "# 2. Read all CSVs in cases_folder, collect their case_uri values\n",
    "cases_files = glob.glob(os.path.join(cases_folder, '*.csv'))\n",
    "cases_case_uris = set()\n",
    "\n",
    "for f in cases_files:\n",
    "    try:\n",
    "        df = pd.read_csv(f, nrows=1)\n",
    "        if 'case_uri' in df.columns:\n",
    "            case_uri = df['case_uri'].iloc[0]\n",
    "            cases_case_uris.add(case_uri)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "\n",
    "# 3. If a pickup file's case_uri is also in cases_case_uris, delete that file from pickup_folder\n",
    "to_delete = pickup_case_uris & cases_case_uris\n",
    "\n",
    "for case_uri in to_delete:\n",
    "    file_path = pickup_file_map[case_uri]\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_for_legal =pd.read_csv('../data/test2/csvs_for_skip_phase_1/combined_with_sections_processed.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_for_legal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_jsonl_from_csv(df, system_prompt,output_path):\n",
    "    \n",
    "    paragraph_column = 'paragraphs'\n",
    "    para_id_col = 'para_id'\n",
    "    \n",
    "\n",
    "    jsonl_lines =[]\n",
    "    rid=1\n",
    "    for idx, row in df.iterrows():\n",
    "        para_text = row[paragraph_column]\n",
    "        para_id_val = row[para_id_col]\n",
    "\n",
    "        # Skip empty paragraphs\n",
    "        if pd.isna(para_text) or not str(para_text).strip():\n",
    "            continue\n",
    "    \n",
    "        user_prompt = f\"\"\"\n",
    "        \"Para_id\":{para_id_val}\n",
    "\n",
    "        \"para_content\":{para_text}\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        jsonl_lines.append({\n",
    "            \"custom_id\":f\"request_{rid}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": { \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]}\n",
    "        })\n",
    "        rid = rid + 1\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for obj in jsonl_lines:\n",
    "            f.write(json.dumps(obj) + \"\\n\")\n",
    "\n",
    "    print(f\"Batch input saved to: {output_path}\")\n",
    "    return output_path\n",
    "system_prompt = \"\"\"You are a legal language model designed to analyze UK case law for paragraphs that contain legal interpretations. Your task is to identify text that interprets or explains legislative terms and concepts.\n",
    "\n",
    "  1. Accurately identify and analyze any legal interpretations within given texts, focusing on how courts, tribunals, or authoritative bodies explain or clarify the meaning or scope of UK legislation.\n",
    "  2. Distinguish between mere citations/references and actual legal interpretations. Text that simply cites a statute (e.g., “pursuant to s.100(2)(b)”) without any explanatory reasoning or discussion of its meaning does not qualify as interpretation.\n",
    "  3. Focus on:\n",
    "    - UK legislation (i.e., Acts of Parliament or other UK statutory instruments)\n",
    "    - Judicial interpretation and statutory interpretation principles (e.g., purposive approach, mischief rule)\n",
    "  4. Do not consider text as legal interpretation when it:\n",
    "    - Merely mentions the law or quotes statutory wording without explaining it\n",
    "    - Refers to non-UK conventions, treaties, or rulings\n",
    "    - Discusses jurisdictional or procedural issues without interpreting legislative language\n",
    "    - Recites the law verbatim (e.g., “Art. 8 provides…”) without additional interpretive commentary.\n",
    "\n",
    "\n",
    "  Examples [{\n",
    "    user : {\"para_id\": \"306_21\",\n",
    "    \"para_content\": \"Decided cases on the meaning and application of section 116 were summarised by HHJ Paul Matthews (sitting as a Judge of the High Court) in Otitoju v Onwordi [2023] EWHC 2665 (Ch) at [20]-[22]. The position, in sum, appears to be that no gloss should be put on the language of the statute: the power under section 116 may be exercised where, by reason of any special circumstances, it appears to be necessary or expedient to appoint an administrator other than the person who would otherwise be entitled. The power is an entirely general one and may be used to appoint any person, including someone who would otherwise have no entitlement at all to appointment: Gudavadze v Kay [2012] EWHC 1683 (Ch) at [45]-[46] (Sales J)\"}\n",
    "\n",
    "    response: {\"para_id\": \"306_21\",\n",
    "    \"if_interpretation\": 1,\n",
    "    \"interpreted_phrases\": [\n",
    "        \"necessary or expedient to appoint an administrator other than the person who would otherwise be entitled\"\n",
    "    ]}\n",
    "\n",
    "},{\n",
    "    user:{ \"para_id\": \"133_11\",\n",
    "    \"para_content\": \"11. In these circumstances, if a child in V’s position were to be genuinely voluntarily accommodated by the local authority, and wished to remain so, then an application within wardship may, I accept, be justified, provided that it passed the tests mandated by s.100(4) of the 1989 Act, in that there was reasonable cause to believe that without an order being made, the child was likely to suffer significant harm, and there was no other means to achieve the desired orders. I am satisfied that such an order, although highly unusual, might in the right circumstances be an appropriate use of the jurisdiction.\"}\n",
    "\n",
    "    response: {\"para_id\": \"133_11\",\n",
    "    \"if_interpretation\": 1,\n",
    "    \"interpreted_phrases\": [\n",
    "        \"there was reasonable cause to believe that without an order being made, the child was likely to suffer significant harm\"\n",
    "    ]}\n",
    "\n",
    "}, {\n",
    "    user: {\"para_id\": \"2025_989\",\n",
    "    \"para_content\": \" 1.  The Applicant lodged an application notice to the Tribunal dated 21 st  September 2024 but received on 10 th  December 2024.  The form stated that the Applicant was unhappy with a decision of the Information Commissioner as regards a data complaint by not to exercising his powers of enforcement.  No copy of the complaint was enclosed with the application or indeed details of when the complaint was made or any action by the Commissioner.\" }\n",
    "    \n",
    "    response: {\"para_id\": \"2025_989\",\n",
    "    \"if_interpretation\": 0,\n",
    "    \"interpreted_phrases\": []}\n",
    "}]\n",
    "\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input saved to: ../data/test2/csvs_for_skip_phase_1/_openai_batch_input_for_interpretation2.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/test2/csvs_for_skip_phase_1/_openai_batch_input_for_interpretation2.jsonl'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "make_batch_jsonl_from_csv(df_for_legal, system_prompt, '../data/test2/csvs_for_skip_phase_1/_openai_batch_input_for_interpretation2.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jod_for_legal_interpretation =  get_batch_job('../data/test2/csvs_for_skip_phase_1/_openai_batch_input_for_interpretation2.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'validating'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jod_for_legal_interpretation.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "client.batches.list().data[0].status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-9CKMdbCqDAaJ2sd64MJLJL'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.list().data[0].output_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = 'file-9CKMdbCqDAaJ2sd64MJLJL'\n",
    "file_response = client.files.content(file_id)\n",
    "with open(\"../data/test2/csvs_for_skip_phase_1/_openai_batch_output_legal_interpretation2.jsonl\", \"wb\") as f:\n",
    "    f.write(file_response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final error parsing JSON: Expecting ',' delimiter: line 1 column 89 (char 88)\n",
      "Unfixable content:\n",
      "{\"para_id\": \"ewhc_scco_2025_374#para_3\",\"if_interpretation\": 0,\"interpreted_phrases\": [])}\n"
     ]
    }
   ],
   "source": [
    "#write the code that will join the output of json file with the original df_for_legal dataframe\n",
    "import json\n",
    "import re\n",
    "# Read the JSONL file\n",
    "with open('../data/test2/csvs_for_skip_phase_1/_openai_batch_output_legal_interpretation2.jsonl', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "# Parse each line and extract the content\n",
    "results = []    \n",
    "for line in lines:\n",
    "    data = json.loads(line)\n",
    "    content = data['response']['body']['choices'][0]['message']['content']\n",
    "    request_id = data['custom_id']\n",
    "    # Remove ```json and ``` strings\n",
    "    content = content.replace('```json\\n', '').replace('\\n```', '')\n",
    "    \n",
    "    try:\n",
    "        # Fix the JSON syntax error by replacing the missing colon\n",
    "        content = content.replace('\"interpreted_phrases: \"', '\"interpreted_phrases\": \"')\n",
    "        content = re.sub(r'\"If_interpretation\"', '\"if_interpretation\"', content)\n",
    "\n",
    "        # Parse the JSON content\n",
    "        result = json.loads(content)\n",
    "        # Add request_id to the result dictionary\n",
    "        result['request_id'] = request_id\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        \n",
    "        # Try to fix common JSON issues (e.g., stray backticks or wrong quotes)\n",
    "        # Fix common JSON key capitalization and stray backticks\n",
    "        content_fixed = re.sub(r'\"interpreted_phrases\"`', '\"interpreted_phrases\"', content)\n",
    "        content_fixed = re.sub(r'\"if_interpretation\"`', '\"if_interpretation\"', content)\n",
    "        content_fixed = re.sub(r'\"If_interpretation\"`', '\"if_interpretation\"', content)\n",
    "        content_fixed = re.sub(r'\"If_interpretation\"', '\"if_interpretation\"', content_fixed)\n",
    "        \n",
    "        try:\n",
    "            result = json.loads(content_fixed)\n",
    "            result['request_id'] = request_id\n",
    "            results.append(result)\n",
    "        except Exception as e2:\n",
    "            \n",
    "            # Try to fix extra closing brackets/parentheses\n",
    "            content_fixed = re.sub(r'\\)+$', '', content_fixed)\n",
    "            content_fixed = re.sub(r'}+$', '', content_fixed)\n",
    "            try:\n",
    "                result = json.loads(content_fixed)\n",
    "                result['request_id'] = request_id\n",
    "                results.append(result)\n",
    "            except Exception as e3:\n",
    "                # Try to fix missing commas in JSON arrays\n",
    "                content_fixed = re.sub(r'\":\\[\\]', '\": []', content_fixed)\n",
    "                content_fixed = re.sub(r'\":\\[', '\": [', content_fixed)\n",
    "                \n",
    "                try:\n",
    "                    result = json.loads(content_fixed)\n",
    "                    result['request_id'] = request_id\n",
    "                    results.append(result)\n",
    "                except Exception as e4:\n",
    "                    # Try to fix missing commas in arrays\n",
    "                    content_fixed = re.sub(r'\":\\[\\]', '\": []', content_fixed)\n",
    "                    content_fixed = re.sub(r'\":\\[', '\": [', content_fixed)\n",
    "                    content_fixed = re.sub(r'\\]$', ']', content_fixed)\n",
    "                    \n",
    "                    try:\n",
    "                        content_fixed=content_fixed+'}'\n",
    "                        result = json.loads(content_fixed)\n",
    "\n",
    "                        result['request_id'] = request_id\n",
    "                        results.append(result)\n",
    "                    except Exception as e5:\n",
    "                        print(f\"Final error parsing JSON: {e5}\")\n",
    "                        print(\"Unfixable content:\")\n",
    "                        print(content_fixed)\n",
    "                        # Skip this problematic entry\n",
    "                        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_interpretation_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para_id</th>\n",
       "      <th>if_interpretation</th>\n",
       "      <th>interpreted_phrases</th>\n",
       "      <th>request_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewhc_ch_2021_324#para_1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewhc_ch_2021_324#para_2</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewhc_ch_2021_324#para_3</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewhc_ch_2021_324#para_4</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ewhc_ch_2021_324#para_5</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>ewfc_2025_41#para_48</td>\n",
       "      <td>1</td>\n",
       "      <td>[section 28(3) does not treat Mr J as A and B’...</td>\n",
       "      <td>request_1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>ewfc_2025_41#para_49</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>ewfc_2025_41#para_50</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>ewfc_2025_41#para_51</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>ewfc_2025_41#para_52</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_1108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1107 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      para_id  if_interpretation  \\\n",
       "0     ewhc_ch_2021_324#para_1                  0   \n",
       "1     ewhc_ch_2021_324#para_2                  0   \n",
       "2     ewhc_ch_2021_324#para_3                  0   \n",
       "3     ewhc_ch_2021_324#para_4                  0   \n",
       "4     ewhc_ch_2021_324#para_5                  0   \n",
       "...                       ...                ...   \n",
       "1102     ewfc_2025_41#para_48                  1   \n",
       "1103     ewfc_2025_41#para_49                  0   \n",
       "1104     ewfc_2025_41#para_50                  0   \n",
       "1105     ewfc_2025_41#para_51                  0   \n",
       "1106     ewfc_2025_41#para_52                  0   \n",
       "\n",
       "                                    interpreted_phrases    request_id  \n",
       "0                                                    []     request_1  \n",
       "1                                                    []     request_2  \n",
       "2                                                    []     request_3  \n",
       "3                                                    []     request_4  \n",
       "4                                                    []     request_5  \n",
       "...                                                 ...           ...  \n",
       "1102  [section 28(3) does not treat Mr J as A and B’...  request_1104  \n",
       "1103                                                 []  request_1105  \n",
       "1104                                                 []  request_1106  \n",
       "1105                                                 []  request_1107  \n",
       "1106                                                 []  request_1108  \n",
       "\n",
       "[1107 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interpretation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#join the df_interpretation_results with df_for_legal on para_id\n",
    "df_for_legal['para_id'] = df_for_legal['para_id'].astype(str)\n",
    "df_interpretation_results['para_id'] = df_interpretation_results['para_id'].astype(str)\n",
    "df_merged_interpretation = df_for_legal.merge(df_interpretation_results, on='para_id', how='left')\n",
    "# Save the merged DataFrame to a CSV file\n",
    "#df_merged_interpretation.to_csv('../data/test2/csvs_for_skip_phase_1/response_with_interpretation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if_law_applied_actual\n",
       "no     882\n",
       "yes    226\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_interpretation['if_law_applied_actual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_merged_interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if_interpretation\n",
       "0.0    752\n",
       "1.0    356\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_interpretation['if_interpretation']= df_merged_interpretation['if_interpretation'].fillna(0)\n",
    "df_merged_interpretation['if_interpretation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.354\n",
      "Recall: 0.558\n",
      "F1 Score: 0.433\n"
     ]
    }
   ],
   "source": [
    "# Map both columns to binary values (0 and 1)\n",
    "df_merged_interpretation['if_law_applied_actual'] = df_merged_interpretation['if_law_applied_actual'].map({'no': 0, 'yes': 1})\n",
    "df_merged_interpretation['if_interpretation'] = df_merged_interpretation['if_interpretation'].map({0.0: 0, 1.0: 1})\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(df_merged_interpretation['if_law_applied_actual'], \n",
    "                          df_merged_interpretation['if_interpretation'])\n",
    "recall = recall_score(df_merged_interpretation['if_law_applied_actual'], \n",
    "                     df_merged_interpretation['if_interpretation'])\n",
    "f1 = f1_score(df_merged_interpretation['if_law_applied_actual'], \n",
    "              df_merged_interpretation['if_interpretation'])\n",
    "\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "for col in df_merged_interpretation.select_dtypes(include=['object']).columns:\n",
    "    df_merged_interpretation[col] = df_merged_interpretation[col].astype(str).str.replace('\\n', ' ').str.replace('\\r', ' ')\n",
    "\n",
    "df_merged_interpretation.to_csv('../data/test2/csvs_for_skip_phase_1/response_with_interpretation.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_uri</th>\n",
       "      <th>para_id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>references</th>\n",
       "      <th>application_of_law_phrases_actual</th>\n",
       "      <th>if_law_applied_actual</th>\n",
       "      <th>reason(optional)</th>\n",
       "      <th>application_of_law_phrases.1</th>\n",
       "      <th>applied provision</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>if_law_applied_gpt-4o</th>\n",
       "      <th>application_of_law_phrases_gpt-4o</th>\n",
       "      <th>reason_gpt-4o</th>\n",
       "      <th>sections</th>\n",
       "      <th>contains_application</th>\n",
       "      <th>application_reasoning</th>\n",
       "      <th>matches</th>\n",
       "      <th>if_interpretation</th>\n",
       "      <th>interpreted_phrases</th>\n",
       "      <th>request_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2021_324#para_1</td>\n",
       "      <td>\\t    \\t 1.  \\t    \\t      \\t These proceedin...</td>\n",
       "      <td>[{'text': 'Charities Act 2011', 'href': 'http:...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph provides background information ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>no</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2021_324#para_2</td>\n",
       "      <td>\\t    \\t 2.  \\t    \\t      \\t In summary, a d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph describes a factual dispute rega...</td>\n",
       "      <td>{'id/ukpga/2011/25_section_344': '344 Other mi...</td>\n",
       "      <td>no</td>\n",
       "      <td>The paragraph merely outlines the positions of...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2021_324#para_3</td>\n",
       "      <td>\\t    \\t 3.  \\t    \\t      \\t The practical s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph discusses the practical implicat...</td>\n",
       "      <td>{'id/ukpga/2011/25_section_181': \"181 Power to...</td>\n",
       "      <td>no</td>\n",
       "      <td>The paragraph provides background information ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2021_324#para_4</td>\n",
       "      <td>\\t    \\t 4.  \\t    \\t      \\t It is a matter ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph discusses procedural delays and ...</td>\n",
       "      <td>{'id/ukpga/2011/25_section_45B': '45B Power to...</td>\n",
       "      <td>no</td>\n",
       "      <td>The paragraph discusses procedural delays in c...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2021_324#para_5</td>\n",
       "      <td>\\t    \\t 5.  \\t    \\t      \\t   The case was ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph provides procedural information ...</td>\n",
       "      <td>{'id/ukpga/2011/25_section_317': '317 Appeal f...</td>\n",
       "      <td>no</td>\n",
       "      <td>The paragraph provides procedural background r...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewfc/2...</td>\n",
       "      <td>ewfc_2025_41#para_48</td>\n",
       "      <td>\\t    \\t 48.  \\t    \\t      \\t The route to t...</td>\n",
       "      <td>[{'text': 'section 28(3)', 'href': 'http://www...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['The route to the declaration sought by Mr J ...</td>\n",
       "      <td>The paragraph applies section 28(3) of the sta...</td>\n",
       "      <td>{}</td>\n",
       "      <td>no</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "      <td>['section 28(3) does not treat Mr J as A and B...</td>\n",
       "      <td>request_1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewfc/2...</td>\n",
       "      <td>ewfc_2025_41#para_49</td>\n",
       "      <td>\\t    \\t 49.  \\t    \\t      \\t For completene...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph merely states that there is no p...</td>\n",
       "      <td>{'id/ukpga/1986/55_section_63': '63 . . . . . ...</td>\n",
       "      <td>no</td>\n",
       "      <td>The paragraph merely states that there is no p...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewfc/2...</td>\n",
       "      <td>ewfc_2025_41#para_50</td>\n",
       "      <td>\\t    \\t 50.  \\t    \\t      \\t By my order, I...</td>\n",
       "      <td>[{'text': 'section 14', 'href': 'http://www.le...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['By my order, I shall direct a court officer ...</td>\n",
       "      <td>The paragraph demonstrates an application of l...</td>\n",
       "      <td>{'id_ukpga_Eliz2_1-2_20_section_14': '14 Re–re...</td>\n",
       "      <td>no</td>\n",
       "      <td>The paragraph contains a directive to send a c...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewfc/2...</td>\n",
       "      <td>ewfc_2025_41#para_51</td>\n",
       "      <td>\\t    \\t 51.  \\t    \\t      \\t I have written...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph does not demonstrate an applicat...</td>\n",
       "      <td>{'id/ukpga/1984/42_section_35': '35 Considerat...</td>\n",
       "      <td>no</td>\n",
       "      <td>The paragraph does not demonstrate an applicat...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewfc/2...</td>\n",
       "      <td>ewfc_2025_41#para_52</td>\n",
       "      <td>\\t           52.  \\t    \\t      \\t That is my...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>The paragraph is a simple statement indicating...</td>\n",
       "      <td>{'id/ukpga/1986/55_section_63': '63 . . . . . ...</td>\n",
       "      <td>no</td>\n",
       "      <td>The paragraph does not contain any application...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>request_1108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1108 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               case_uri  \\\n",
       "0     https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "1     https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "2     https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "3     https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "4     https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "...                                                 ...   \n",
       "1103  https://caselaw.nationalarchives.gov.uk/ewfc/2...   \n",
       "1104  https://caselaw.nationalarchives.gov.uk/ewfc/2...   \n",
       "1105  https://caselaw.nationalarchives.gov.uk/ewfc/2...   \n",
       "1106  https://caselaw.nationalarchives.gov.uk/ewfc/2...   \n",
       "1107  https://caselaw.nationalarchives.gov.uk/ewfc/2...   \n",
       "\n",
       "                      para_id  \\\n",
       "0     ewhc_ch_2021_324#para_1   \n",
       "1     ewhc_ch_2021_324#para_2   \n",
       "2     ewhc_ch_2021_324#para_3   \n",
       "3     ewhc_ch_2021_324#para_4   \n",
       "4     ewhc_ch_2021_324#para_5   \n",
       "...                       ...   \n",
       "1103     ewfc_2025_41#para_48   \n",
       "1104     ewfc_2025_41#para_49   \n",
       "1105     ewfc_2025_41#para_50   \n",
       "1106     ewfc_2025_41#para_51   \n",
       "1107     ewfc_2025_41#para_52   \n",
       "\n",
       "                                             paragraphs  \\\n",
       "0      \\t    \\t 1.  \\t    \\t      \\t These proceedin...   \n",
       "1      \\t    \\t 2.  \\t    \\t      \\t In summary, a d...   \n",
       "2      \\t    \\t 3.  \\t    \\t      \\t The practical s...   \n",
       "3      \\t    \\t 4.  \\t    \\t      \\t It is a matter ...   \n",
       "4      \\t    \\t 5.  \\t    \\t      \\t   The case was ...   \n",
       "...                                                 ...   \n",
       "1103   \\t    \\t 48.  \\t    \\t      \\t The route to t...   \n",
       "1104   \\t    \\t 49.  \\t    \\t      \\t For completene...   \n",
       "1105   \\t    \\t 50.  \\t    \\t      \\t By my order, I...   \n",
       "1106   \\t    \\t 51.  \\t    \\t      \\t I have written...   \n",
       "1107   \\t           52.  \\t    \\t      \\t That is my...   \n",
       "\n",
       "                                             references  \\\n",
       "0     [{'text': 'Charities Act 2011', 'href': 'http:...   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "1103  [{'text': 'section 28(3)', 'href': 'http://www...   \n",
       "1104                                                 []   \n",
       "1105  [{'text': 'section 14', 'href': 'http://www.le...   \n",
       "1106                                                 []   \n",
       "1107                                                 []   \n",
       "\n",
       "     application_of_law_phrases_actual  if_law_applied_actual  \\\n",
       "0                                   []                      0   \n",
       "1                                   []                      0   \n",
       "2                                   []                      0   \n",
       "3                                   []                      0   \n",
       "4                                   []                      0   \n",
       "...                                ...                    ...   \n",
       "1103                                []                      0   \n",
       "1104                                []                      0   \n",
       "1105                                []                      0   \n",
       "1106                                []                      0   \n",
       "1107                                []                      0   \n",
       "\n",
       "     reason(optional) application_of_law_phrases.1 applied provision  act  \\\n",
       "0                 nan                          nan               nan  nan   \n",
       "1                 nan                          nan               nan  nan   \n",
       "2                 nan                          nan               nan  nan   \n",
       "3                 nan                          nan               nan  nan   \n",
       "4                 nan                          nan               nan  nan   \n",
       "...               ...                          ...               ...  ...   \n",
       "1103              nan                          nan               nan  nan   \n",
       "1104              nan                          nan               nan  nan   \n",
       "1105              nan                          nan               nan  nan   \n",
       "1106              nan                          nan               nan  nan   \n",
       "1107              nan                          nan               nan  nan   \n",
       "\n",
       "      ... if_law_applied_gpt-4o  \\\n",
       "0     ...                     0   \n",
       "1     ...                     0   \n",
       "2     ...                     0   \n",
       "3     ...                     0   \n",
       "4     ...                     0   \n",
       "...   ...                   ...   \n",
       "1103  ...                     1   \n",
       "1104  ...                     0   \n",
       "1105  ...                     1   \n",
       "1106  ...                     0   \n",
       "1107  ...                     0   \n",
       "\n",
       "                      application_of_law_phrases_gpt-4o  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "1103  ['The route to the declaration sought by Mr J ...   \n",
       "1104                                                 []   \n",
       "1105  ['By my order, I shall direct a court officer ...   \n",
       "1106                                                 []   \n",
       "1107                                                 []   \n",
       "\n",
       "                                          reason_gpt-4o  \\\n",
       "0     The paragraph provides background information ...   \n",
       "1     The paragraph describes a factual dispute rega...   \n",
       "2     The paragraph discusses the practical implicat...   \n",
       "3     The paragraph discusses procedural delays and ...   \n",
       "4     The paragraph provides procedural information ...   \n",
       "...                                                 ...   \n",
       "1103  The paragraph applies section 28(3) of the sta...   \n",
       "1104  The paragraph merely states that there is no p...   \n",
       "1105  The paragraph demonstrates an application of l...   \n",
       "1106  The paragraph does not demonstrate an applicat...   \n",
       "1107  The paragraph is a simple statement indicating...   \n",
       "\n",
       "                                               sections  contains_application  \\\n",
       "0                                                    {}                    no   \n",
       "1     {'id/ukpga/2011/25_section_344': '344 Other mi...                    no   \n",
       "2     {'id/ukpga/2011/25_section_181': \"181 Power to...                    no   \n",
       "3     {'id/ukpga/2011/25_section_45B': '45B Power to...                    no   \n",
       "4     {'id/ukpga/2011/25_section_317': '317 Appeal f...                    no   \n",
       "...                                                 ...                   ...   \n",
       "1103                                                 {}                    no   \n",
       "1104  {'id/ukpga/1986/55_section_63': '63 . . . . . ...                    no   \n",
       "1105  {'id_ukpga_Eliz2_1-2_20_section_14': '14 Re–re...                    no   \n",
       "1106  {'id/ukpga/1984/42_section_35': '35 Considerat...                    no   \n",
       "1107  {'id/ukpga/1986/55_section_63': '63 . . . . . ...                    no   \n",
       "\n",
       "                                  application_reasoning matches  \\\n",
       "0                                                   nan     nan   \n",
       "1     The paragraph merely outlines the positions of...     nan   \n",
       "2     The paragraph provides background information ...     nan   \n",
       "3     The paragraph discusses procedural delays in c...     nan   \n",
       "4     The paragraph provides procedural background r...     nan   \n",
       "...                                                 ...     ...   \n",
       "1103                                                nan     nan   \n",
       "1104  The paragraph merely states that there is no p...     nan   \n",
       "1105  The paragraph contains a directive to send a c...     nan   \n",
       "1106  The paragraph does not demonstrate an applicat...     nan   \n",
       "1107  The paragraph does not contain any application...     nan   \n",
       "\n",
       "     if_interpretation                                interpreted_phrases  \\\n",
       "0                    0                                                 []   \n",
       "1                    0                                                 []   \n",
       "2                    0                                                 []   \n",
       "3                    0                                                 []   \n",
       "4                    0                                                 []   \n",
       "...                ...                                                ...   \n",
       "1103                 1  ['section 28(3) does not treat Mr J as A and B...   \n",
       "1104                 0                                                 []   \n",
       "1105                 0                                                 []   \n",
       "1106                 0                                                 []   \n",
       "1107                 0                                                 []   \n",
       "\n",
       "        request_id  \n",
       "0        request_1  \n",
       "1        request_2  \n",
       "2        request_3  \n",
       "3        request_4  \n",
       "4        request_5  \n",
       "...            ...  \n",
       "1103  request_1104  \n",
       "1104  request_1105  \n",
       "1105  request_1106  \n",
       "1106  request_1107  \n",
       "1107  request_1108  \n",
       "\n",
       "[1108 rows x 24 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_for_legal =pd.read_csv('../data/test2/csvs_for_skip_phase_1/combined_with_sections_processed.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by case_uri and create JSON for each case\n",
    "case_groups = df_for_legal.groupby('case_uri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 cases:\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/eat/2025/29\n",
      "Number of paragraphs: 57\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/civ/2004/988\n",
      "Number of paragraphs: 32\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/civ/2005/647\n",
      "Number of paragraphs: 46\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/civ/2006/4\n",
      "Number of paragraphs: 46\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/civ/2007/826\n",
      "Number of paragraphs: 33\n",
      "---\n",
      "\n",
      "Remaining cases:\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/civ/2012/543\n",
      "Number of paragraphs: 26\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/civ/2015/414\n",
      "Number of paragraphs: 24\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/civ/2018/764\n",
      "Number of paragraphs: 31\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/civ/2025/215\n",
      "Number of paragraphs: 34\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/crim/2008/468\n",
      "Number of paragraphs: 18\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/crim/2009/1942\n",
      "Number of paragraphs: 49\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewca/crim/2019/2056\n",
      "Number of paragraphs: 22\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewfc/2025/41\n",
      "Number of paragraphs: 52\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewhc/admin/2003/2779\n",
      "Number of paragraphs: 31\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewhc/admin/2010/2929\n",
      "Number of paragraphs: 46\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewhc/admin/2017/576\n",
      "Number of paragraphs: 35\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewhc/admin/2020/1850\n",
      "Number of paragraphs: 42\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewhc/admin/2025/462\n",
      "Number of paragraphs: 37\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewhc/ch/2013/4630\n",
      "Number of paragraphs: 51\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewhc/ch/2021/324\n",
      "Number of paragraphs: 50\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewhc/qb/2014/4729\n",
      "Number of paragraphs: 9\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewhc/qb/2016/2355\n",
      "Number of paragraphs: 31\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ewhc/scco/2025/374\n",
      "Number of paragraphs: 16\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/251\n",
      "Number of paragraphs: 54\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/282\n",
      "Number of paragraphs: 14\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/283\n",
      "Number of paragraphs: 39\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/284\n",
      "Number of paragraphs: 45\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/287\n",
      "Number of paragraphs: 45\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ukftt/grc/2025/289\n",
      "Number of paragraphs: 18\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/uksc/2011/41\n",
      "Number of paragraphs: 39\n",
      "---\n",
      "Case URI: https://caselaw.nationalarchives.gov.uk/ukut/aac/2022/263\n",
      "Number of paragraphs: 36\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Get first 5 cases and remaining cases\n",
    "first_five_cases = list(case_groups)[:5]\n",
    "remaining_cases = list(case_groups)[5:]\n",
    "\n",
    "# Print info for first 5 cases\n",
    "print(\"First 5 cases:\")\n",
    "for case_uri, case_df in first_five_cases:\n",
    "    print(f\"Case URI: {case_uri}\")\n",
    "    print(f\"Number of paragraphs: {len(case_df)}\")\n",
    "    print(\"---\")\n",
    "\n",
    "# Print info for remaining cases\n",
    "print(\"\\nRemaining cases:\")\n",
    "for case_uri, case_df in remaining_cases:\n",
    "    print(f\"Case URI: {case_uri}\")\n",
    "    print(f\"Number of paragraphs: {len(case_df)}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/miniconda3/envs/Odyssey/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'if_law_applied'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Assuming we have ground truth labels in df_for_legal['if_law_applied_actual']\u001b[39;00m\n\u001b[1;32m     44\u001b[0m y_true \u001b[38;5;241m=\u001b[39m df_for_legal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mif_law_applied_actual\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 45\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mdf_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mif_law_applied\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     47\u001b[0m precision, recall, f1, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/Odyssey/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/Odyssey/lib/python3.11/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'if_law_applied'"
     ]
    }
   ],
   "source": [
    "import openAIHandler\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '../data/test2/csvs_for_skip_phase_1/case_results/v2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each case\n",
    "for case_uri, case_df in first_five_cases[:2]:\n",
    "    # Create JSON input for this case\n",
    "    case_json = []\n",
    "    for _, row in case_df.iterrows():\n",
    "        case_json.append({\n",
    "            'para_id': row['para_id'],\n",
    "            'paragraph': row['paragraphs']\n",
    "        })\n",
    "    \n",
    "    examples_json_file_path = '../data/test2/examples.json'\n",
    "    examples = json.load(open(examples_json_file_path))\n",
    "    # Get classification results using OpenAI\n",
    "    results = openAIHandler.getLegalClassifierUsingJson(case_json, examples)\n",
    "    \n",
    "    # Save results to file\n",
    "    case_filename = f\"{output_dir}/{case_uri.split('/')[-1]}_results.json\"\n",
    "    with open(case_filename, 'w') as f:\n",
    "        json.dump(results.content, f)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "all_results = []\n",
    "for filename in os.listdir(output_dir):\n",
    "    if filename.endswith('_results.json'):\n",
    "        with open(os.path.join(output_dir, filename), 'r') as f:\n",
    "            results = json.load(f)\n",
    "            all_results.extend(results)\n",
    "\n",
    "# Create combined DataFrame\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Assuming we have ground truth labels in df_for_legal['if_law_applied_actual']\n",
    "y_true = df_for_legal['if_law_applied_actual']\n",
    "y_pred = df_results['if_law_applied']\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "\n",
    "# Save combined results\n",
    "#df_results.to_csv('../data/test2/csvs_for_skip_phase_1/combined_classification_results.csv', index=False)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "USAGE EXAMPLES:\n",
      "==================================================\n",
      "1. Convert string to DataFrame:\n",
      "   df = string_to_dataframe(your_string)\n",
      "\n",
      "2. Read single file:\n",
      "   df = read_file_to_dataframe('path/to/file.txt')\n",
      "\n",
      "3. Combine multiple specific files:\n",
      "   files = ['file1.txt', 'file2.txt', 'file3.txt']\n",
      "   combined_df = combine_multiple_files(files)\n",
      "\n",
      "4. Combine all files from directory:\n",
      "   combined_df = combine_files_from_directory('/path/to/directory', '*.txt')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def parse_pseudo_json_string(data_string: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Parse a pseudo-JSON string format into a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        data_string: String containing pseudo-JSON data\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing parsed data\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    \n",
    "    # Split by double newlines to separate records\n",
    "    record_blocks = data_string.strip().split('\\n\\n')\n",
    "    \n",
    "    for block in record_blocks:\n",
    "        if not block.strip():\n",
    "            continue\n",
    "            \n",
    "        record = {}\n",
    "        lines = block.strip().split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            if ':' not in line:\n",
    "                continue\n",
    "                \n",
    "            # Split on first colon only\n",
    "            key, value = line.split(':', 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            \n",
    "            # Handle different value types\n",
    "            if key == 'application_of_law_phrases':\n",
    "                try:\n",
    "                    # Use ast.literal_eval to safely parse the list\n",
    "                    parsed_value = ast.literal_eval(value)\n",
    "                    record[key] = parsed_value\n",
    "                except (ValueError, SyntaxError):\n",
    "                    # If parsing fails, keep as string\n",
    "                    record[key] = value\n",
    "            elif key == 'if_law_applied':\n",
    "                # Convert to integer\n",
    "                try:\n",
    "                    record[key] = int(value)\n",
    "                except ValueError:\n",
    "                    record[key] = value\n",
    "            else:\n",
    "                record[key] = value\n",
    "        \n",
    "        if record:  # Only add non-empty records\n",
    "            records.append(record)\n",
    "    \n",
    "    return records\n",
    "\n",
    "def string_to_dataframe(data_string: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert pseudo-JSON string to pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data_string: String containing pseudo-JSON data\n",
    "        \n",
    "    Returns:\n",
    "        pandas DataFrame\n",
    "    \"\"\"\n",
    "    records = parse_pseudo_json_string(data_string)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def read_file_to_dataframe(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a file containing pseudo-JSON data and convert to DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the file\n",
    "        \n",
    "    Returns:\n",
    "        pandas DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return string_to_dataframe(content)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filepath}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def combine_multiple_files(filepaths: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read multiple files and combine them into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        filepaths: List of file paths\n",
    "        \n",
    "    Returns:\n",
    "        Combined pandas DataFrame\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        df = read_file_to_dataframe(filepath)\n",
    "        if not df.empty:\n",
    "            # Add source file column\n",
    "            df['source_file'] = os.path.basename(filepath)\n",
    "            dataframes.append(df)\n",
    "    \n",
    "    if dataframes:\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def combine_files_from_directory(directory_path: str, file_pattern: str = \"*.txt\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read all files matching a pattern from a directory and combine them.\n",
    "    \n",
    "    Args:\n",
    "        directory_path: Path to directory containing files\n",
    "        file_pattern: Pattern to match files (default: \"*.txt\")\n",
    "        \n",
    "    Returns:\n",
    "        Combined pandas DataFrame\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    \n",
    "    pattern = os.path.join(directory_path, file_pattern)\n",
    "    filepaths = glob.glob(pattern)\n",
    "    \n",
    "    return combine_multiple_files(filepaths)\n",
    "\n",
    "# Example usage with your provided string\n",
    "if __name__ == \"__main__\":\n",
    "    # Your sample data\n",
    "    \n",
    " \n",
    "    # Example: Reading multiple files\n",
    "    # file_paths = [\"file1.txt\", \"file2.txt\", \"file3.txt\"]\n",
    "    # combined_df = combine_multiple_files(file_paths)\n",
    "    \n",
    "    # Example: Reading all files from a directory\n",
    "    combined_df = combine_files_from_directory(\"../data/test2/csvs_for_skip_phase_1/case_results\", \"*.json\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"USAGE EXAMPLES:\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"1. Convert string to DataFrame:\")\n",
    "    print(\"   df = string_to_dataframe(your_string)\")\n",
    "    print()\n",
    "    print(\"2. Read single file:\")\n",
    "    print(\"   df = read_file_to_dataframe('path/to/file.txt')\")\n",
    "    print()\n",
    "    print(\"3. Combine multiple specific files:\")\n",
    "    print(\"   files = ['file1.txt', 'file2.txt', 'file3.txt']\")\n",
    "    print(\"   combined_df = combine_multiple_files(files)\")\n",
    "    print()\n",
    "    print(\"4. Combine all files from directory:\")\n",
    "    print(\"   combined_df = combine_files_from_directory('/path/to/directory', '*.txt')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "\n",
    "def parse_custom_format_file(filepath):\n",
    "    cleaned_entries = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    current = {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"para_id:\"):\n",
    "            if current:\n",
    "                cleaned_entries.append(current)\n",
    "                current = {}\n",
    "            current[\"para_id\"] = line.split(\"para_id:\")[1].strip()\n",
    "        elif line.startswith(\"if_law_applied:\"):\n",
    "            current[\"if_law_applied\"] = int(line.split(\"if_law_applied:\")[1].strip())\n",
    "        elif line.startswith(\"application_of_law_phrases:\"):\n",
    "            raw_phrases = line.split(\"application_of_law_phrases:\")[1].strip()\n",
    "            try:\n",
    "                phrases = ast.literal_eval(raw_phrases)\n",
    "                # Clean boilerplate phrases\n",
    "                cleaned_phrases = [\n",
    "                    p for p in phrases\n",
    "                    if not any(x in p.lower() for x in [\"here is the response\", \"it is submitted\", \"this is\"])\n",
    "                ]\n",
    "                current[\"application_of_law_phrases\"] = cleaned_phrases\n",
    "            except Exception as e:\n",
    "                current[\"application_of_law_phrases\"] = []\n",
    "\n",
    "    if current:\n",
    "        cleaned_entries.append(current)\n",
    "\n",
    "    return cleaned_entries\n",
    "\n",
    "# Usage\n",
    "input_file = '../data/test2/csvs_for_skip_phase_1/case_results/4729_results.json'  # Replace with your real path\n",
    "output_file = '../data/test2/csvs_for_skip_phase_1/case_results/cleaned_4729_results.json'\n",
    "\n",
    "cleaned_data = parse_custom_format_file(input_file)\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(cleaned_data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (1858, 8)\n",
      "Columns: ['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied_actual', 'if_law_applied_4o_mini', 'application_of_law_phrases', 'reason']\n",
      "\n",
      "Distribution before filtering:\n",
      "Actual True: 307\n",
      "4o-mini True: 425\n",
      "Both True: 124\n",
      "Both False: 1250\n",
      "\n",
      "Disagreement cases found: 484\n",
      "actual=True, 4o-mini=False: 183\n",
      "actual=False, 4o-mini=True: 301\n",
      "\n",
      "Disagreement cases saved to: ../data/newData/disagreement_cases.csv\n",
      "Columns in output: ['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied_actual', 'if_law_applied_4o_mini', 'application_of_law_phrases', 'reason', 'disagreement_type']\n",
      "\n",
      "=== DISAGREEMENT ANALYSIS ===\n",
      "\n",
      "Paragraph length statistics:\n",
      "ChatGPT-only cases - Mean length: nan\n",
      "GPT-4o-mini-only cases - Mean length: 922.7\n",
      "\n",
      "=== SAMPLE CHATGPT-ONLY CASES (first 3) ===\n",
      "\n",
      "=== SAMPLE GPT-4O-MINI-ONLY CASES (first 3) ===\n",
      "\n",
      "Para ID: ewhc_fam_2020_2339#para_13\n",
      "Text:  \t    \t 13.  \t    \t      \t Parker J also recorded that she had come to the firm conclusion that the children were undoubtedly habitually resident in Morocco at the date of their removal to England by ...\n",
      "Reason: The judge applies the legal standard for habitual residence to the specific facts surrounding the children's situation and their removal to England, analyzing the context of their living arrangements.\n",
      "\n",
      "Para ID: ewhc_fam_2020_2339#para_27\n",
      "Text:  \t    \t 27.  \t    \t      \t Ms Targett-Parker for the mother made the bold submission that the children acquired habitual residence in England the moment they stepped off the plane.  As I pointed out d...\n",
      "Reason: The judge applies the legal standard for determining 'habitual residence' to the specific facts of the children's situation upon arriving in England, assessing their circumstances to conclude they did not acquire habitual residence immediately.\n",
      "\n",
      "Para ID: ewhc_fam_2020_2339#para_30\n",
      "Text:  \t    \t 30.  \t    \t      \t Having recited the history as I have above, I have no hesitation in concluding that the reason why the father was not seeing his children was because he did not know where t...\n",
      "Reason: The judge applies the Hague Convention's principles regarding custody rights specifically to the father's actions in attempting to maintain contact with his children, analyzing the factual context of these efforts.\n",
      "\n",
      "✅ Successfully created ../data/newData/disagreement_cases.csv with 484 disagreement cases\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def filter_disagreement_cases(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Filter rows where either if_law_applied_chatgpt OR if_law_applied_4o_mini is True, \n",
    "    but not both (XOR condition - disagreement cases)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    print(f\"Original dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Convert boolean columns to proper boolean type if they're strings\n",
    "    # Handle different possible string representations\n",
    "    def convert_to_bool(value):\n",
    "        if pd.isna(value):\n",
    "            return False\n",
    "        if isinstance(value, str):\n",
    "            value = value.lower().strip()\n",
    "            if value in ['true', '1', 'yes']:\n",
    "                return True\n",
    "            elif value in ['false', '0', 'no']:\n",
    "                return False\n",
    "            else:\n",
    "                return False\n",
    "        return bool(value)\n",
    "    \n",
    "    # Apply conversion to both boolean columns\n",
    "    df['if_law_applied_actual'] = df['if_law_applied_actual'].apply(convert_to_bool)\n",
    "    df['if_law_applied_4o_mini'] = df['if_law_applied_4o_mini'].apply(convert_to_bool)\n",
    "    \n",
    "    # Check the distribution before filtering\n",
    "    print(\"\\nDistribution before filtering:\")\n",
    "    print(f\"Actual True: {df['if_law_applied_actual'].sum()}\")\n",
    "    print(f\"4o-mini True: {df['if_law_applied_4o_mini'].sum()}\")\n",
    "    print(f\"Both True: {(df['if_law_applied_actual'] & df['if_law_applied_4o_mini']).sum()}\")\n",
    "    print(f\"Both False: {(~df['if_law_applied_actual'] & ~df['if_law_applied_4o_mini']).sum()}\")\n",
    "    \n",
    "    # Filter for disagreement cases (XOR - either one is True but not both)\n",
    "    disagreement_mask = (\n",
    "        (df['if_law_applied_actual'] & ~df['if_law_applied_4o_mini']) |  # ChatGPT True, 4o-mini False\n",
    "        (~df['if_law_applied_actual'] & df['if_law_applied_4o_mini'])    # ChatGPT False, 4o-mini True\n",
    "    )\n",
    "    \n",
    "    disagreement_df = df[disagreement_mask].copy()\n",
    "    \n",
    "    print(f\"\\nDisagreement cases found: {len(disagreement_df)}\")\n",
    "    print(f\"actual=True, 4o-mini=False: {(disagreement_df['if_law_applied_actual'] & ~disagreement_df['if_law_applied_4o_mini']).sum()}\")\n",
    "    print(f\"actual=False, 4o-mini=True: {(~disagreement_df['if_law_applied_actual'] & disagreement_df['if_law_applied_4o_mini']).sum()}\")\n",
    "    \n",
    "    # Add a column to indicate the type of disagreement\n",
    "    disagreement_df['disagreement_type'] = np.where(\n",
    "        disagreement_df['if_law_applied_actual'] & ~disagreement_df['if_law_applied_4o_mini'],\n",
    "        'actual_only',\n",
    "        'GPT4o_mini_only'\n",
    "    )\n",
    "    \n",
    "    # Save to new CSV\n",
    "    disagreement_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"\\nDisagreement cases saved to: {output_file}\")\n",
    "    print(f\"Columns in output: {disagreement_df.columns.tolist()}\")\n",
    "    \n",
    "    return disagreement_df\n",
    "\n",
    "def analyze_disagreements(df):\n",
    "    \"\"\"\n",
    "    Provide additional analysis of the disagreement cases\n",
    "    \"\"\"\n",
    "    print(\"\\n=== DISAGREEMENT ANALYSIS ===\")\n",
    "    \n",
    "    # Length analysis\n",
    "    df['para_length'] = df['paragraphs'].str.len()\n",
    "    \n",
    "    chatgpt_only = df[df['disagreement_type'] == 'Actual_only']\n",
    "    gpt4o_only = df[df['disagreement_type'] == 'GPT4o_mini_only']\n",
    "    \n",
    "    print(f\"\\nParagraph length statistics:\")\n",
    "    print(f\"Actual-only cases - Mean length: {chatgpt_only['para_length'].mean():.1f}\")\n",
    "    print(f\"GPT-4o-mini-only cases - Mean length: {gpt4o_only['para_length'].mean():.1f}\")\n",
    "    \n",
    "    # Show some examples\n",
    "    print(f\"\\n=== SAMPLE CHATGPT-ONLY CASES (first 3) ===\")\n",
    "    for idx, row in chatgpt_only.head(3).iterrows():\n",
    "        print(f\"\\nPara ID: {row['para_id']}\")\n",
    "        print(f\"Text: {row['paragraphs'][:200]}...\")\n",
    "        if 'reason' in row and pd.notna(row['reason']):\n",
    "            print(f\"Reason: {row['reason']}\")\n",
    "    \n",
    "    print(f\"\\n=== SAMPLE GPT-4O-MINI-ONLY CASES (first 3) ===\")\n",
    "    for idx, row in gpt4o_only.head(3).iterrows():\n",
    "        print(f\"\\nPara ID: {row['para_id']}\")\n",
    "        print(f\"Text: {row['paragraphs'][:200]}...\")\n",
    "        if 'reason' in row and pd.notna(row['reason']):\n",
    "            print(f\"Reason: {row['reason']}\")\n",
    "\n",
    "\n",
    "input_file = \"../data/newData/merged_output.csv\"  # Update this path if needed\n",
    "output_file = \"../data/newData/disagreement_cases.csv\"\n",
    "\n",
    "try:\n",
    "    # Filter disagreement cases\n",
    "    disagreement_df = filter_disagreement_cases(input_file, output_file)\n",
    "    \n",
    "    # Analyze the disagreements\n",
    "    analyze_disagreements(disagreement_df)\n",
    "    \n",
    "    print(f\"\\n✅ Successfully created {output_file} with {len(disagreement_df)} disagreement cases\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: Could not find {input_file}\")\n",
    "    print(\"Please make sure the file path is correct\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Odyssey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
