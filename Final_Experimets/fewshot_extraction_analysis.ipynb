{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22a58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_source = pd.read_csv('../data/final_test/final/reexperiment/combined_sourcedf_final_rebuild.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41da6e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "if 'ewca_civ_2018_162#para_13' in df_source.para_id.unique():\n",
    "    print(\"Yes\")\n",
    "else:\n",
    "    print(\"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ae701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_pairs = set(zip(df_source['para_id'], df_source['section_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc0f5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openai_new = pd.read_csv('../data/final_test/final/reexperiment/fewhot/11August/redo-gpt-4o-mini_output-combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf0009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openai_new.para_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3e727fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['eat_2022_192#para_12', 'eat_2022_192#para_18',\n",
       "       'eat_2022_192#para_21', ..., 'ewfc_b_2024_69#para_203',\n",
       "       'uksc_2013_11#para_42', 'ewhc_qb_2017_294#para_29'],\n",
       "      shape=(9002,), dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openai_new.para_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa39430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "if 'ewca_civ_2018_162#para_13' in df_openai_new.para_id.unique():\n",
    "    print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de7a5b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>para_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>phrase_index</th>\n",
       "      <th>case_law_excerpt</th>\n",
       "      <th>legislation_excerpt</th>\n",
       "      <th>confidence</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>para_text</th>\n",
       "      <th>section_text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>request_2477</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-170</td>\n",
       "      <td>0</td>\n",
       "      <td>The benefits that the Appellant obtained throu...</td>\n",
       "      <td>the defendant has a criminal lifestyle but has...</td>\n",
       "      <td>High</td>\n",
       "      <td>The case law reflects upon the irrelevance of ...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>170 No order made: reconsideration of benefit ...</td>\n",
       "      <td>2431</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>request_2477</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-170</td>\n",
       "      <td>0</td>\n",
       "      <td>The benefits that the Appellant obtained throu...</td>\n",
       "      <td>the defendant has a criminal lifestyle but has...</td>\n",
       "      <td>High</td>\n",
       "      <td>The case law reflects upon the irrelevance of ...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>170 No order made: reconsideration of benefit ...</td>\n",
       "      <td>2431</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>request_2478</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-20</td>\n",
       "      <td>0</td>\n",
       "      <td>Moreover, the argument to be made on the stren...</td>\n",
       "      <td>may make a confiscation order under that section</td>\n",
       "      <td>High</td>\n",
       "      <td>The case law discusses the implications of con...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>20 No order made: reconsideration of benefit (...</td>\n",
       "      <td>2432</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>request_2478</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-20</td>\n",
       "      <td>0</td>\n",
       "      <td>Moreover, the argument to be made on the stren...</td>\n",
       "      <td>may make a confiscation order under that section</td>\n",
       "      <td>High</td>\n",
       "      <td>The case law discusses the implications of con...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>20 No order made: reconsideration of benefit (...</td>\n",
       "      <td>2432</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         custom_id                    para_id                    section_id  \\\n",
       "4858  request_2477  ewca_civ_2018_162#para_13  id/ukpga/2002/29_section-170   \n",
       "4859  request_2477  ewca_civ_2018_162#para_13  id/ukpga/2002/29_section-170   \n",
       "4860  request_2478  ewca_civ_2018_162#para_13   id/ukpga/2002/29_section-20   \n",
       "4861  request_2478  ewca_civ_2018_162#para_13   id/ukpga/2002/29_section-20   \n",
       "\n",
       "      phrase_index                                   case_law_excerpt  \\\n",
       "4858             0  The benefits that the Appellant obtained throu...   \n",
       "4859             0  The benefits that the Appellant obtained throu...   \n",
       "4860             0  Moreover, the argument to be made on the stren...   \n",
       "4861             0  Moreover, the argument to be made on the stren...   \n",
       "\n",
       "                                    legislation_excerpt confidence  \\\n",
       "4858  the defendant has a criminal lifestyle but has...       High   \n",
       "4859  the defendant has a criminal lifestyle but has...       High   \n",
       "4860   may make a confiscation order under that section       High   \n",
       "4861   may make a confiscation order under that section       High   \n",
       "\n",
       "                                              reasoning  \\\n",
       "4858  The case law reflects upon the irrelevance of ...   \n",
       "4859  The case law reflects upon the irrelevance of ...   \n",
       "4860  The case law discusses the implications of con...   \n",
       "4861  The case law discusses the implications of con...   \n",
       "\n",
       "                                              para_text  \\\n",
       "4858  13. We refused permission to adduce this evide...   \n",
       "4859  13. We refused permission to adduce this evide...   \n",
       "4860  13. We refused permission to adduce this evide...   \n",
       "4861  13. We refused permission to adduce this evide...   \n",
       "\n",
       "                                           section_text  line_number   status  \n",
       "4858  170 No order made: reconsideration of benefit ...         2431  SUCCESS  \n",
       "4859  170 No order made: reconsideration of benefit ...         2431  SUCCESS  \n",
       "4860  20 No order made: reconsideration of benefit (...         2432  SUCCESS  \n",
       "4861  20 No order made: reconsideration of benefit (...         2432  SUCCESS  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b18ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_openai_new[df_openai_new.para_id == 'ewca_civ_2018_162#para_13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf28514a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The benefits that the Appellant obtained through his criminal tipping on the Land are irrelevant to that claim or its quantification. Moreover, the argument to be made on the strength of this evidence would appear to involve a claim to share in the Appellant’s proceeds of crime, which might well be open to objection in principle.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['case_law_excerpt'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3293e9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'may make a confiscation order under that section'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['legislation_excerpt'].values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4684f5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The case law discusses the implications of considering the benefits gained through unlawful actions, which relates directly to the court's ability to make confiscation orders as outlined in the legislation.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['reasoning'].values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9379c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied',\n",
       "       'application_of_law_phrases', 'reason', 'if_law_applied_llama',\n",
       "       'application_of_law_phrases_llama', 'reason_llama',\n",
       "       'if_law_applied_claude', 'application_of_law_phrases_claude',\n",
       "       'reason_claude', 'confidence', 'agreement_with', 'final_annotation',\n",
       "       'case_name', 'section_id', 'section_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654bf14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['custom_id', 'para_id', 'section_id', 'phrase_index',\n",
       "       'case_law_excerpt', 'legislation_excerpt', 'confidence', 'reasoning',\n",
       "       'para_text', 'section_text', 'line_number', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openai_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b75af3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered df_openai_new: 35640\n",
      "Length after adding missing records: 35824\n",
      "Added 184 missing records\n"
     ]
    }
   ],
   "source": [
    "df_openai_new = df_openai_new[df_openai_new.status == 'SUCCESS']\n",
    "# Filter df_openai_new to only keep rows where (para_id, section_id) exists in source_pairs\n",
    "df_openai_new = df_openai_new[df_openai_new.apply(lambda row: (row['para_id'], row['section_id']) in source_pairs, axis=1)]\n",
    "\n",
    "print(f\"Length of filtered df_openai_new: {len(df_openai_new)}\")\n",
    "\n",
    "# Get existing pairs in df_openai_new\n",
    "existing_pairs = set(zip(df_openai_new['para_id'], df_openai_new['section_id']))\n",
    "\n",
    "# Find missing pairs that are in source_pairs but not in df_openai_new\n",
    "missing_pairs = source_pairs - existing_pairs\n",
    "\n",
    "# Create records for missing pairs\n",
    "missing_records = []\n",
    "for para_id, section_id in missing_pairs:\n",
    "    # Get the corresponding row from df_source\n",
    "    source_row = df_source[(df_source['para_id'] == para_id) & \n",
    "                          (df_source['section_id'] == section_id)].iloc[0]\n",
    "    \n",
    "    missing_record = {\n",
    "        'custom_id': '000',\n",
    "        'para_id': para_id,\n",
    "        'section_id': section_id,\n",
    "        'phrase_index': -1,\n",
    "        'case_law_excerpt': None,\n",
    "        'legislation_excerpt': None,\n",
    "        'confidence': 'Low',\n",
    "        'reasoning': None,\n",
    "        'para_text': source_row['paragraphs'],  # assuming this column exists in df_source\n",
    "        'section_text': source_row['section_text'],  # assuming this column exists in df_source\n",
    "        'line_number': '000',\n",
    "        'status': 'Dummy',\n",
    "        'is_valid': False  # assuming missing records are not valid\n",
    "    }\n",
    "    missing_records.append(missing_record)\n",
    "\n",
    "# Convert to DataFrame and concatenate\n",
    "if missing_records:\n",
    "    df_missing = pd.DataFrame(missing_records)\n",
    "    df_openai_new = pd.concat([df_openai_new, df_missing], ignore_index=True)\n",
    "\n",
    "print(f\"Length after adding missing records: {len(df_openai_new)}\")\n",
    "print(f\"Added {len(missing_records)} missing records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e0567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9002"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openai_new.para_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e2c41c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confidence\n",
       "High    30044\n",
       "Low      5780\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openai_new.confidence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08873ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_special_chars(s):\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    # Remove all non-alphanumeric and non-space characters\n",
    "    return re.sub(r'[^A-Za-z0-9 ]+', '', s)\n",
    "def check_valid(row):\n",
    "    #case_ok = str(row.get('case_law_excerpt', '')) in str(row.get('para_text', ''))\n",
    "    legis_ok = str(row.get('legislation_excerpt', '')) in str(row.get('section_text', ''))\n",
    "    if legis_ok:#if case_ok and legis_ok:\n",
    "        return True\n",
    "    cleaned_caselaw_excerpt = remove_special_chars(row.get('case_law_excerpt', ''))\n",
    "    cleaned_legislation_excerpt = remove_special_chars(row.get('legislation_excerpt', ''))\n",
    "    cleaned_para_text = remove_special_chars(row.get('para_text', ''))\n",
    "    cleaned_section_text = remove_special_chars(row.get('section_text', ''))\n",
    "    case_ok = str(cleaned_caselaw_excerpt) in str(cleaned_para_text)\n",
    "    legis_ok = str(cleaned_legislation_excerpt) in str(cleaned_section_text)    \n",
    "    #return case_ok and legis_ok\n",
    "    return legis_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b07c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openai_new['is_valid'] = df_openai_new.apply(check_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ca536bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence distribution after update:\n",
      "confidence\n",
      "High    23248\n",
      "Low     12576\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set confidence to 'Low' for records where is_valid is False\n",
    "df_openai_new.loc[df_openai_new['is_valid'] == False, 'confidence'] = 'Low'\n",
    "\n",
    "# Check the result\n",
    "print(\"Confidence distribution after update:\")\n",
    "print(df_openai_new['confidence'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc6a4868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 7701\n"
     ]
    }
   ],
   "source": [
    "High_ids_openai = df_openai_new[df_openai_new['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_openai}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6c25aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "Total records: 28382\n",
      "High confidence records: 23248\n",
      "Low confidence records: 5134\n",
      "Unique para_ids: 9002\n",
      "\n",
      "Confidence distribution:\n",
      "confidence\n",
      "High    23248\n",
      "Low      5134\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get para_ids that have at least one High confidence record\n",
    "para_ids_with_high = df_openai_new[df_openai_new['confidence'] == 'High']['para_id'].unique()\n",
    "\n",
    "# Get para_ids that have NO High confidence records (only Low)\n",
    "para_ids_only_low = df_openai_new[~df_openai_new['para_id'].isin(para_ids_with_high)]['para_id'].unique()\n",
    "\n",
    "# Filter the dataframe:\n",
    "# 1. Keep High confidence records for para_ids that have at least one High\n",
    "# 2. Keep Low confidence records only for para_ids that have NO High records\n",
    "df_openai_filtered = df_openai_new[\n",
    "    ((df_openai_new['confidence'] == 'High') & (df_openai_new['para_id'].isin(para_ids_with_high))) |\n",
    "    ((df_openai_new['confidence'] == 'Low') & (df_openai_new['para_id'].isin(para_ids_only_low)))\n",
    "]\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Total records: {len(df_openai_filtered)}\")\n",
    "print(f\"High confidence records: {len(df_openai_filtered[df_openai_filtered['confidence'] == 'High'])}\")\n",
    "print(f\"Low confidence records: {len(df_openai_filtered[df_openai_filtered['confidence'] == 'Low'])}\")\n",
    "print(f\"Unique para_ids: {df_openai_filtered['para_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nConfidence distribution:\")\n",
    "print(df_openai_filtered['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73e541fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 7701\n",
      "Number of para_ids with at least one Low entry: 1301\n"
     ]
    }
   ],
   "source": [
    "High_ids_openai = df_openai_filtered[df_openai_filtered['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_openai}\")\n",
    "\n",
    "Low_ids_openai = df_openai_filtered[df_openai_filtered['confidence'] == 'Low']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one Low entry: {Low_ids_openai}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e791a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_llama = pd.read_csv('../data/final_test/final/reexperiment/fewhot/11August/llama_combined_output_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6663e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llama = df_llama[df_llama.status == 'SUCCESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f66ade0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered df_llama: 21245\n",
      "Length after adding missing records: 22696\n",
      "Added 1451 missing records\n"
     ]
    }
   ],
   "source": [
    "df_llama = df_llama[df_llama.apply(lambda row: (row['para_id'], row['section_id']) in source_pairs, axis=1)]\n",
    "\n",
    "print(f\"Length of filtered df_llama: {len(df_llama)}\")\n",
    "\n",
    "# Get existing pairs in df_llama\n",
    "existing_pairs_llama = set(zip(df_llama['para_id'], df_llama['section_id']))\n",
    "\n",
    "# Find missing pairs that are in source_pairs but not in df_llama\n",
    "missing_pairs_llama = source_pairs - existing_pairs_llama\n",
    "\n",
    "# Create records for missing pairs\n",
    "missing_records = []\n",
    "for para_id, section_id in missing_pairs_llama:\n",
    "    # Get the corresponding row from df_source\n",
    "    source_row = df_source[(df_source['para_id'] == para_id) & \n",
    "                          (df_source['section_id'] == section_id)].iloc[0]\n",
    "    \n",
    "    missing_record = {\n",
    "        'custom_id': '000',\n",
    "        'para_id': para_id,\n",
    "        'section_id': section_id,\n",
    "        'phrase_index': -1,\n",
    "        'case_law_excerpt': None,\n",
    "        'legislation_excerpt': None,\n",
    "        'confidence': 'Low',\n",
    "        'reasoning': None,\n",
    "        'para_text': source_row['paragraphs'],  # assuming this column exists in df_source\n",
    "        'section_text': source_row['section_text'],  # assuming this column exists in df_source\n",
    "        'line_number': '000',\n",
    "        'status': 'Dummy',\n",
    "        'is_valid': False  # assuming missing records are not valid\n",
    "    }\n",
    "    missing_records.append(missing_record)\n",
    "\n",
    "# Convert to DataFrame and concatenate\n",
    "if missing_records:\n",
    "    df_missing = pd.DataFrame(missing_records)\n",
    "    df_llama = pd.concat([df_llama, df_missing], ignore_index=True)\n",
    "\n",
    "print(f\"Length after adding missing records: {len(df_llama)}\")\n",
    "print(f\"Added {len(missing_records)} missing records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "482c3c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>para_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>phrase_index</th>\n",
       "      <th>case_law_excerpt</th>\n",
       "      <th>legislation_excerpt</th>\n",
       "      <th>confidence</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>para_text</th>\n",
       "      <th>section_text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>request_2477</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-170</td>\n",
       "      <td>0</td>\n",
       "      <td>the benefits that the Appellant obtained throu...</td>\n",
       "      <td>evidence which was not available to the prosec...</td>\n",
       "      <td>Low</td>\n",
       "      <td>The court's decision to refuse permission to a...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>170 No order made: reconsideration of benefit ...</td>\n",
       "      <td>2466</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>request_2478</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-20</td>\n",
       "      <td>0</td>\n",
       "      <td>the benefits that the Appellant obtained throu...</td>\n",
       "      <td>the court concludes that it would have decided...</td>\n",
       "      <td>Low</td>\n",
       "      <td>The court's decision to refuse permission to a...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>20 No order made: reconsideration of benefit (...</td>\n",
       "      <td>2483</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         custom_id                    para_id                    section_id  \\\n",
       "2098  request_2477  ewca_civ_2018_162#para_13  id/ukpga/2002/29_section-170   \n",
       "2112  request_2478  ewca_civ_2018_162#para_13   id/ukpga/2002/29_section-20   \n",
       "\n",
       "      phrase_index                                   case_law_excerpt  \\\n",
       "2098             0  the benefits that the Appellant obtained throu...   \n",
       "2112             0  the benefits that the Appellant obtained throu...   \n",
       "\n",
       "                                    legislation_excerpt confidence  \\\n",
       "2098  evidence which was not available to the prosec...        Low   \n",
       "2112  the court concludes that it would have decided...        Low   \n",
       "\n",
       "                                              reasoning  \\\n",
       "2098  The court's decision to refuse permission to a...   \n",
       "2112  The court's decision to refuse permission to a...   \n",
       "\n",
       "                                              para_text  \\\n",
       "2098  13. We refused permission to adduce this evide...   \n",
       "2112  13. We refused permission to adduce this evide...   \n",
       "\n",
       "                                           section_text  line_number   status  \n",
       "2098  170 No order made: reconsideration of benefit ...         2466  SUCCESS  \n",
       "2112  20 No order made: reconsideration of benefit (...         2483  SUCCESS  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llama[df_llama.para_id == 'ewca_civ_2018_162#para_13']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c7576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence distribution after update:\n",
      "confidence\n",
      "Low       14957\n",
      "High       7624\n",
      "Medium      115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_llama['is_valid'] = df_llama.apply(check_valid, axis=1)\n",
    "\n",
    "# Set confidence to 'Low' for records where is_valid is False\n",
    "df_llama.loc[df_llama['is_valid'] == False, 'confidence'] = 'Low'\n",
    "\n",
    "# Check the result\n",
    "print(\"Confidence distribution after update:\")\n",
    "print(df_llama['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c31e8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llama.loc[df_llama['confidence'] == 'Medium', 'confidence'] = 'High'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25dd448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence\n",
      "Low     14957\n",
      "High     7739\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_llama['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e61186fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 5492\n"
     ]
    }
   ],
   "source": [
    "High_ids_llama = df_llama[df_llama['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_llama}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e4e598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "Total records: 16816\n",
      "High confidence records: 7739\n",
      "Low confidence records: 9077\n",
      "Unique para_ids: 9002\n",
      "\n",
      "Confidence distribution:\n",
      "confidence\n",
      "Low     9077\n",
      "High    7739\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get para_ids that have at least one High confidence record\n",
    "para_ids_with_high_llama = df_llama[df_llama['confidence'] == 'High']['para_id'].unique()\n",
    "\n",
    "# Get para_ids that have NO High confidence records (only Low)\n",
    "para_ids_only_low_llama = df_llama[~df_llama['para_id'].isin(para_ids_with_high_llama)]['para_id'].unique()\n",
    "\n",
    "# Filter the dataframe:\n",
    "# 1. Keep High confidence records for para_ids that have at least one High\n",
    "# 2. Keep Low confidence records only for para_ids that have NO High records\n",
    "df_llama_filtered = df_llama[\n",
    "    ((df_llama['confidence'] == 'High') & (df_llama['para_id'].isin(para_ids_with_high_llama))) |\n",
    "    ((df_llama['confidence'] == 'Low') & (df_llama['para_id'].isin(para_ids_only_low_llama)))\n",
    "]\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Total records: {len(df_llama_filtered)}\")\n",
    "print(f\"High confidence records: {len(df_llama_filtered[df_llama_filtered['confidence'] == 'High'])}\")\n",
    "print(f\"Low confidence records: {len(df_llama_filtered[df_llama_filtered['confidence'] == 'Low'])}\")\n",
    "print(f\"Unique para_ids: {df_llama_filtered['para_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nConfidence distribution:\")\n",
    "print(df_llama_filtered['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb0c89de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 5492\n",
      "Number of para_ids with at least one Low entry: 3510\n"
     ]
    }
   ],
   "source": [
    "High_ids_llama = df_llama_filtered[df_llama_filtered['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_llama}\")\n",
    "\n",
    "Low_ids_llama = df_llama_filtered[df_llama_filtered['confidence'] == 'Low']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one Low entry: {Low_ids_llama}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5186b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deepseek = pd.read_csv('../data/final_test/final/reexperiment/fewhot/11August/deepseek_combined_output_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45bf2d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>para_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>phrase_index</th>\n",
       "      <th>case_law_excerpt</th>\n",
       "      <th>legislation_excerpt</th>\n",
       "      <th>confidence</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>para_text</th>\n",
       "      <th>section_text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>request_2478</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-20</td>\n",
       "      <td>0</td>\n",
       "      <td>We refused permission to adduce this evidence....</td>\n",
       "      <td>If this section applies the court— (a) must ma...</td>\n",
       "      <td>High</td>\n",
       "      <td>The case law excerpt discusses the refusal to ...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>20 No order made: reconsideration of benefit (...</td>\n",
       "      <td>2474</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>request_2477</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-170</td>\n",
       "      <td>0</td>\n",
       "      <td>The benefits that the Appellant obtained throu...</td>\n",
       "      <td>the court has decided that— (a) the defendant ...</td>\n",
       "      <td>High</td>\n",
       "      <td>The case law discusses the irrelevance of crim...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>170 No order made: reconsideration of benefit ...</td>\n",
       "      <td>2485</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         custom_id                    para_id                    section_id  \\\n",
       "2198  request_2478  ewca_civ_2018_162#para_13   id/ukpga/2002/29_section-20   \n",
       "2207  request_2477  ewca_civ_2018_162#para_13  id/ukpga/2002/29_section-170   \n",
       "\n",
       "      phrase_index                                   case_law_excerpt  \\\n",
       "2198             0  We refused permission to adduce this evidence....   \n",
       "2207             0  The benefits that the Appellant obtained throu...   \n",
       "\n",
       "                                    legislation_excerpt confidence  \\\n",
       "2198  If this section applies the court— (a) must ma...       High   \n",
       "2207  the court has decided that— (a) the defendant ...       High   \n",
       "\n",
       "                                              reasoning  \\\n",
       "2198  The case law excerpt discusses the refusal to ...   \n",
       "2207  The case law discusses the irrelevance of crim...   \n",
       "\n",
       "                                              para_text  \\\n",
       "2198  13. We refused permission to adduce this evide...   \n",
       "2207  13. We refused permission to adduce this evide...   \n",
       "\n",
       "                                           section_text  line_number   status  \n",
       "2198  20 No order made: reconsideration of benefit (...         2474  SUCCESS  \n",
       "2207  170 No order made: reconsideration of benefit ...         2485  SUCCESS  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ewca_civ_2018_162#para_13' in df_deepseek.para_id.unique()\n",
    "df_deepseek[df_deepseek['para_id'] == 'ewca_civ_2018_162#para_13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1f9bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deepseek = df_deepseek[df_deepseek.status == 'SUCCESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1569a60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered df_deepseek: 21792\n",
      "Length after adding missing records: 22247\n",
      "Added 455 missing records\n"
     ]
    }
   ],
   "source": [
    "# Filter df_deepseek to only keep rows where (para_id, section_id) exists in source_pairs\n",
    "df_deepseek = df_deepseek[df_deepseek.apply(lambda row: (row['para_id'], row['section_id']) in source_pairs, axis=1)]\n",
    "\n",
    "print(f\"Length of filtered df_deepseek: {len(df_deepseek)}\")\n",
    "\n",
    "# Get existing pairs in df_deepseek\n",
    "existing_pairs_deepseek = set(zip(df_deepseek['para_id'], df_deepseek['section_id']))\n",
    "\n",
    "# Find missing pairs that are in source_pairs but not in df_deepseek\n",
    "missing_pairs_deepseek = source_pairs - existing_pairs_deepseek\n",
    "\n",
    "# Create records for missing pairs\n",
    "missing_records_deepseek = []\n",
    "for para_id, section_id in missing_pairs_deepseek:\n",
    "    # Get the corresponding row from df_source\n",
    "    source_row = df_source[(df_source['para_id'] == para_id) & \n",
    "                          (df_source['section_id'] == section_id)].iloc[0]\n",
    "    \n",
    "    missing_record_deepseek = {\n",
    "        'custom_id': '000',\n",
    "        'para_id': para_id,\n",
    "        'section_id': section_id,\n",
    "        'phrase_index': -1,\n",
    "        'case_law_excerpt': None,\n",
    "        'legislation_excerpt': None,\n",
    "        'confidence': 'Low',\n",
    "        'reasoning': None,\n",
    "        'para_text': source_row['paragraphs'],  # assuming this column exists in df_source\n",
    "        'section_text': source_row['section_text'],  # assuming this column exists in df_source\n",
    "        'line_number': '000',\n",
    "        'status': 'Dummy',\n",
    "        'is_valid': False  # assuming missing records are not valid\n",
    "    }\n",
    "    missing_records_deepseek.append(missing_record_deepseek)\n",
    "\n",
    "# Convert to DataFrame and concatenate\n",
    "if missing_records_deepseek:\n",
    "    df_missing_deepseek = pd.DataFrame(missing_records_deepseek)\n",
    "    df_deepseek = pd.concat([df_deepseek, df_missing_deepseek], ignore_index=True)\n",
    "\n",
    "print(f\"Length after adding missing records: {len(df_deepseek)}\")\n",
    "print(f\"Added {len(missing_records_deepseek)} missing records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a1c9db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence distribution after update:\n",
      "confidence\n",
      "Low         11413\n",
      "High        10753\n",
      "Medium         64\n",
      "Moderate       16\n",
      "No match        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_deepseek['is_valid'] = df_deepseek.apply(check_valid, axis=1)\n",
    "\n",
    "# Set confidence to 'Low' for records where is_valid is False\n",
    "df_deepseek.loc[df_deepseek['is_valid'] == False, 'confidence'] = 'Low'\n",
    "\n",
    "# Check the result\n",
    "print(\"Confidence distribution after update:\")\n",
    "print(df_deepseek['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de70dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deepseek.loc[df_deepseek['confidence'] == 'Medium', 'confidence'] = 'High'\n",
    "df_deepseek.loc[df_deepseek['confidence'] == 'Moderate', 'confidence'] = 'High'\n",
    "df_deepseek.loc[df_deepseek['confidence'] == 'No match', 'confidence'] = 'Low'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16ce140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence distribution after update:\n",
      "confidence\n",
      "Low     11414\n",
      "High    10833\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Confidence distribution after update:\")\n",
    "print(df_deepseek['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36b0f6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 7137\n"
     ]
    }
   ],
   "source": [
    "High_ids_deepseek = df_deepseek[df_deepseek['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_deepseek}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0815ddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "Total records: 16065\n",
      "High confidence records: 10833\n",
      "Low confidence records: 5232\n",
      "Unique para_ids: 9002\n",
      "\n",
      "Confidence distribution:\n",
      "confidence\n",
      "High    10833\n",
      "Low      5232\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get para_ids that have at least one High confidence record\n",
    "para_ids_with_high_deepseek = df_deepseek[df_deepseek['confidence'] == 'High']['para_id'].unique()\n",
    "\n",
    "# Get para_ids that have NO High confidence records (only Low)\n",
    "para_ids_only_low_deepseek = df_deepseek[~df_deepseek['para_id'].isin(para_ids_with_high_deepseek)]['para_id'].unique()\n",
    "\n",
    "# Filter the dataframe:\n",
    "# 1. Keep High confidence records for para_ids that have at least one High\n",
    "# 2. Keep Low confidence records only for para_ids that have NO High records\n",
    "df_deepseek_filtered = df_deepseek[\n",
    "    ((df_deepseek['confidence'] == 'High') & (df_deepseek['para_id'].isin(para_ids_with_high_deepseek))) |\n",
    "    ((df_deepseek['confidence'] == 'Low') & (df_deepseek['para_id'].isin(para_ids_only_low_deepseek)))\n",
    "]\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Total records: {len(df_deepseek_filtered)}\")\n",
    "print(f\"High confidence records: {len(df_deepseek_filtered[df_deepseek_filtered['confidence'] == 'High'])}\")\n",
    "print(f\"Low confidence records: {len(df_deepseek_filtered[df_deepseek_filtered['confidence'] == 'Low'])}\")\n",
    "print(f\"Unique para_ids: {df_deepseek_filtered['para_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nConfidence distribution:\")\n",
    "print(df_deepseek_filtered['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66e33f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 7137\n",
      "Number of para_ids with at least one Low entry: 1865\n"
     ]
    }
   ],
   "source": [
    "High_ids_deepseek = df_deepseek_filtered[df_deepseek_filtered['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_deepseek}\")\n",
    "\n",
    "Low_ids_deepseek = df_deepseek_filtered[df_deepseek_filtered['confidence'] == 'Low']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one Low entry: {Low_ids_deepseek}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "470a25a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4631"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_deepseek_filtered[df_deepseek_filtered['confidence'] == 'High']['para_id'].unique())&set(df_llama_filtered[df_llama_filtered['confidence'] == 'High']['para_id'].unique())&set(df_openai_filtered[df_openai_filtered['confidence'] == 'High']['para_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce41be39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records per dataframe after keeping one per para_id:\n",
      "DeepSeek: 9002\n",
      "Llama: 9002\n",
      "OpenAI: 9002\n",
      "\n",
      "Total unique para_ids (X): 9002\n",
      "\n",
      "Distribution of para_ids by confidence pattern:\n",
      "a_all_high: 4631 para_ids (51.4%)\n",
      "b_2high_1low: 2604 para_ids (28.9%)\n",
      "c_1high_2low: 1229 para_ids (13.7%)\n",
      "d_all_low: 538 para_ids (6.0%)\n",
      "\n",
      "Verification: 9002 = 9002 ✓\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First, let's ensure each dataframe has only one record per para_id\n",
    "# For para_ids with multiple Low records, keep only one (this should mainly affect df_deepseek_filtered)\n",
    "\n",
    "def keep_one_record_per_para_id(df):\n",
    "    \"\"\"Keep one record per para_id - prefer High confidence, if all Low then keep first\"\"\"\n",
    "    # Group by para_id and keep the first record (High confidence records should already be filtered appropriately)\n",
    "    return df.groupby('para_id').first().reset_index()\n",
    "\n",
    "df_deepseek_final = keep_one_record_per_para_id(df_deepseek_filtered)\n",
    "df_llama_final = keep_one_record_per_para_id(df_llama_filtered)\n",
    "df_openai_final = keep_one_record_per_para_id(df_openai_filtered)\n",
    "\n",
    "print(\"Records per dataframe after keeping one per para_id:\")\n",
    "print(f\"DeepSeek: {len(df_deepseek_final)}\")\n",
    "print(f\"Llama: {len(df_llama_final)}\")\n",
    "print(f\"OpenAI: {len(df_openai_final)}\")\n",
    "\n",
    "# Get all unique para_ids across all three dataframes\n",
    "all_para_ids = set(df_deepseek_final['para_id'].unique()) | \\\n",
    "               set(df_llama_final['para_id'].unique()) | \\\n",
    "               set(df_openai_final['para_id'].unique())\n",
    "\n",
    "X = len(all_para_ids)\n",
    "print(f\"\\nTotal unique para_ids (X): {X}\")\n",
    "\n",
    "# Create a comprehensive dataframe with confidence for each model\n",
    "results = []\n",
    "\n",
    "for para_id in all_para_ids:\n",
    "    # Get confidence for each model (None if para_id not present)\n",
    "    deepseek_conf = df_deepseek_final[df_deepseek_final['para_id'] == para_id]['confidence'].iloc[0] if para_id in df_deepseek_final['para_id'].values else None\n",
    "    llama_conf = df_llama_final[df_llama_final['para_id'] == para_id]['confidence'].iloc[0] if para_id in df_llama_final['para_id'].values else None\n",
    "    openai_conf = df_openai_final[df_openai_final['para_id'] == para_id]['confidence'].iloc[0] if para_id in df_openai_final['para_id'].values else None\n",
    "    \n",
    "    # Count High and Low confidences\n",
    "    confidences = [deepseek_conf, llama_conf, openai_conf]\n",
    "    high_count = confidences.count('High')\n",
    "    low_count = confidences.count('Low')\n",
    "    \n",
    "    results.append({\n",
    "        'para_id': para_id,\n",
    "        'deepseek_conf': deepseek_conf,\n",
    "        'llama_conf': llama_conf,\n",
    "        'openai_conf': openai_conf,\n",
    "        'high_count': high_count,\n",
    "        'low_count': low_count\n",
    "    })\n",
    "\n",
    "df_analysis = pd.DataFrame(results)\n",
    "\n",
    "# Categorize based on High/Low distribution\n",
    "def categorize_confidence(row):\n",
    "    if row['high_count'] == 3:\n",
    "        return 'a_all_high'\n",
    "    elif row['high_count'] == 2 and row['low_count'] == 1:\n",
    "        return 'b_2high_1low'\n",
    "    elif row['high_count'] == 1 and row['low_count'] == 2:\n",
    "        return 'c_1high_2low'\n",
    "    elif row['low_count'] == 3:\n",
    "        return 'd_all_low'\n",
    "    else:\n",
    "        return 'other'  # This shouldn't happen if all para_ids have 3 entries\n",
    "\n",
    "df_analysis['category'] = df_analysis.apply(categorize_confidence, axis=1)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nDistribution of para_ids by confidence pattern:\")\n",
    "category_counts = df_analysis['category'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / X) * 100\n",
    "    print(f\"{category}: {count} para_ids ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nVerification: {category_counts.sum()} = {X} ✓\" if category_counts.sum() == X else f\"\\nError: {category_counts.sum()} ≠ {X}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7aef24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with all low confidence: 538\n",
      "Number of records in df_source_all_low: 1076\n",
      "Unique para_ids in df_source_all_low: 538\n",
      "Verification: Expected 538 para_ids, got 538\n",
      "\n",
      "DataFrame shape: (1076, 19)\n",
      "Columns: ['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied', 'application_of_law_phrases', 'reason', 'if_law_applied_llama', 'application_of_law_phrases_llama', 'reason_llama', 'if_law_applied_claude', 'application_of_law_phrases_claude', 'reason_claude', 'confidence', 'agreement_with', 'final_annotation', 'case_name', 'section_id', 'section_text']\n",
      "\n",
      "First 5 rows:\n",
      "                                              case_uri               para_id  \\\n",
      "124  https://caselaw.nationalarchives.gov.uk/eat/20...  eat_2024_17#para_100   \n",
      "125  https://caselaw.nationalarchives.gov.uk/eat/20...  eat_2024_17#para_100   \n",
      "128  https://caselaw.nationalarchives.gov.uk/eat/20...  eat_2024_17#para_112   \n",
      "129  https://caselaw.nationalarchives.gov.uk/eat/20...  eat_2024_17#para_112   \n",
      "130  https://caselaw.nationalarchives.gov.uk/eat/20...  eat_2024_17#para_118   \n",
      "\n",
      "                                            paragraphs references  \\\n",
      "124  100. I must say immediately that in the presen...         []   \n",
      "125  100. I must say immediately that in the presen...         []   \n",
      "128  112. I add this: I would not want the conclusi...         []   \n",
      "129  112. I add this: I would not want the conclusi...         []   \n",
      "130  118. At [101], which is the target of this gro...         []   \n",
      "\n",
      "    if_law_applied                         application_of_law_phrases  \\\n",
      "124           True  ['the claimant does not allege, and I do not f...   \n",
      "125           True  ['the claimant does not allege, and I do not f...   \n",
      "128           True  ['my conclusion that the interventions crossed...   \n",
      "129           True  ['my conclusion that the interventions crossed...   \n",
      "130          False                                                 []   \n",
      "\n",
      "                                                reason if_law_applied_llama  \\\n",
      "124  The judge applies legal standards of fairness ...                 True   \n",
      "125  The judge applies legal standards of fairness ...                 True   \n",
      "128  The judge applies legal principles regarding t...                 True   \n",
      "129  The judge applies legal principles regarding t...                 True   \n",
      "130  The paragraph discusses the Tribunal's conside...                 True   \n",
      "\n",
      "                      application_of_law_phrases_llama  \\\n",
      "124                 ['that rendered the trial unfair']   \n",
      "125                 ['that rendered the trial unfair']   \n",
      "128  ['provided it is compatible with proper consid...   \n",
      "129  ['provided it is compatible with proper consid...   \n",
      "130  ['We have considered the consultation document...   \n",
      "\n",
      "                                          reason_llama if_law_applied_claude  \\\n",
      "124  The judge applies the legal principle of fairn...                   NaN   \n",
      "125  The judge applies the legal principle of fairn...                   NaN   \n",
      "128  The judge applies the legal principle of a fai...                   NaN   \n",
      "129  The judge applies the legal principle of a fai...                   NaN   \n",
      "130  The Tribunal applies the principles outlined i...                  True   \n",
      "\n",
      "                     application_of_law_phrases_claude  \\\n",
      "124                                                NaN   \n",
      "125                                                NaN   \n",
      "128                                                NaN   \n",
      "129                                                NaN   \n",
      "130  ['We have considered the consultation document...   \n",
      "\n",
      "                                         reason_claude confidence  \\\n",
      "124                                                NaN        NaN   \n",
      "125                                                NaN        NaN   \n",
      "128                                                NaN        NaN   \n",
      "129                                                NaN        NaN   \n",
      "130  Model B (Llama) is correct. This paragraph cle...       High   \n",
      "\n",
      "    agreement_with  final_annotation    case_name  \\\n",
      "124            NaN              True  eat_2024_17   \n",
      "125            NaN              True  eat_2024_17   \n",
      "128            NaN              True  eat_2024_17   \n",
      "129            NaN              True  eat_2024_17   \n",
      "130          Llama              True  eat_2024_17   \n",
      "\n",
      "                        section_id  \\\n",
      "124   id/ukpga/2010/15_section-122   \n",
      "125   id/ukpga/1996/18_section-43M   \n",
      "128   id/ukpga/2010/15_section-123   \n",
      "129  id/ukpga/2010/15_section-140B   \n",
      "130   id/ukpga/1996/18_section-129   \n",
      "\n",
      "                                          section_text  \n",
      "124  122 References by court to tribunal, etc. (1) ...  \n",
      "125  43M Jury service (1) An employee has the right...  \n",
      "128  123 Time limits (1) Subject to section 140B pr...  \n",
      "129  140B Extension of time limits to facilitate co...  \n",
      "130  129 Procedure on hearing of application and ma...  \n"
     ]
    }
   ],
   "source": [
    "# Get the para_ids that are in the 'd_all_low' category\n",
    "d_all_low_para_ids = df_analysis[df_analysis['category'] == 'd_all_low']['para_id'].tolist()\n",
    "\n",
    "print(f\"Number of para_ids with all low confidence: {len(d_all_low_para_ids)}\")\n",
    "\n",
    "# Filter df_source to keep only rows with para_ids in d_all_low\n",
    "df_source_all_low = df_source[df_source['para_id'].isin(d_all_low_para_ids)].copy()\n",
    "\n",
    "print(f\"Number of records in df_source_all_low: {len(df_source_all_low)}\")\n",
    "print(f\"Unique para_ids in df_source_all_low: {df_source_all_low['para_id'].nunique()}\")\n",
    "\n",
    "# Verify that we got all the d_all_low para_ids\n",
    "unique_para_ids_in_result = df_source_all_low['para_id'].nunique()\n",
    "print(f\"Verification: Expected {len(d_all_low_para_ids)} para_ids, got {unique_para_ids_in_result}\")\n",
    "\n",
    "# Show some basic info about the filtered dataframe\n",
    "print(f\"\\nDataFrame shape: {df_source_all_low.shape}\")\n",
    "print(f\"Columns: {list(df_source_all_low.columns)}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_source_all_low.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "606dcf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of wide analysis dataframe: (14724, 17)\n",
      "Unique para_ids: 9002\n",
      "Unique (para_id, section_id) combinations: 14724\n",
      "\n",
      "Columns in final wide dataframe:\n",
      "  para_id\n",
      "  section_id\n",
      "  category\n",
      "  case_law_excerpt_deepseek\n",
      "  legislation_excerpt_deepseek\n",
      "  confidence_deepseek\n",
      "  reasoning_deepseek\n",
      "  case_law_excerpt_llama\n",
      "  legislation_excerpt_llama\n",
      "  confidence_llama\n",
      "  reasoning_llama\n",
      "  case_law_excerpt_openai\n",
      "  legislation_excerpt_openai\n",
      "  confidence_openai\n",
      "  reasoning_openai\n",
      "  paragraphs\n",
      "  section_text\n",
      "\n",
      "Distribution by category:\n",
      "category\n",
      "a_all_high      7522\n",
      "b_2high_1low    4192\n",
      "c_1high_2low    2086\n",
      "d_all_low        924\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 3 rows (showing key columns):\n",
      "                para_id                          section_id      category  \\\n",
      "0  eat_2022_192#para_12         id/ukpga/2010/15_section-60    a_all_high   \n",
      "1  eat_2022_192#para_18  id/ukpga/2010/15_schedule-8-part-1    a_all_high   \n",
      "2  eat_2022_192#para_21  id/ukpga/2010/15_schedule-1-part-1  b_2high_1low   \n",
      "\n",
      "  confidence_deepseek confidence_llama confidence_openai  \n",
      "0                High             High              High  \n",
      "1                High             High               NaN  \n",
      "2                High              Low              High  \n"
     ]
    }
   ],
   "source": [
    "# Create a wide format dataframe with one row per (para_id, section_id) and columns for each model\n",
    "def create_wide_analysis_df():\n",
    "    # Start with the analysis dataframe to get all para_ids and their categories\n",
    "    df_wide = df_analysis[['para_id', 'category']].copy()\n",
    "    \n",
    "    # We need to get section_ids, so let's merge with one of the model dataframes first\n",
    "    # Get all unique (para_id, section_id) combinations from all models\n",
    "    all_combinations = []\n",
    "    \n",
    "    for df_model in [df_deepseek_final, df_llama_final, df_openai_final]:\n",
    "        combinations = df_model[['para_id', 'section_id']].drop_duplicates()\n",
    "        all_combinations.append(combinations)\n",
    "    \n",
    "    # Combine all combinations and remove duplicates\n",
    "    all_combos = pd.concat(all_combinations).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Merge with category information\n",
    "    df_wide = all_combos.merge(df_analysis[['para_id', 'category']], on='para_id', how='left')\n",
    "    \n",
    "    # Add columns from deepseek\n",
    "    deepseek_cols = df_deepseek_final[['para_id', 'section_id', 'case_law_excerpt', 'legislation_excerpt', 'confidence', 'reasoning']].copy()\n",
    "    deepseek_cols = deepseek_cols.rename(columns={\n",
    "        'case_law_excerpt': 'case_law_excerpt_deepseek',\n",
    "        'legislation_excerpt': 'legislation_excerpt_deepseek',\n",
    "        'confidence': 'confidence_deepseek',\n",
    "        'reasoning': 'reasoning_deepseek'\n",
    "    })\n",
    "    df_wide = df_wide.merge(deepseek_cols, on=['para_id', 'section_id'], how='left')\n",
    "    \n",
    "    # Add columns from llama\n",
    "    llama_cols = df_llama_final[['para_id', 'section_id', 'case_law_excerpt', 'legislation_excerpt', 'confidence', 'reasoning']].copy()\n",
    "    llama_cols = llama_cols.rename(columns={\n",
    "        'case_law_excerpt': 'case_law_excerpt_llama',\n",
    "        'legislation_excerpt': 'legislation_excerpt_llama',\n",
    "        'confidence': 'confidence_llama',\n",
    "        'reasoning': 'reasoning_llama'\n",
    "    })\n",
    "    df_wide = df_wide.merge(llama_cols, on=['para_id', 'section_id'], how='left')\n",
    "    \n",
    "    # Add columns from openai\n",
    "    openai_cols = df_openai_final[['para_id', 'section_id', 'case_law_excerpt', 'legislation_excerpt', 'confidence', 'reasoning']].copy()\n",
    "    openai_cols = openai_cols.rename(columns={\n",
    "        'case_law_excerpt': 'case_law_excerpt_openai',\n",
    "        'legislation_excerpt': 'legislation_excerpt_openai',\n",
    "        'confidence': 'confidence_openai',\n",
    "        'reasoning': 'reasoning_openai'\n",
    "    })\n",
    "    df_wide = df_wide.merge(openai_cols, on=['para_id', 'section_id'], how='left')\n",
    "    \n",
    "    # Add additional columns from df_source instead of model dataframes\n",
    "    base_cols = df_source[['para_id', 'section_id', 'paragraphs', 'section_text']].drop_duplicates()\n",
    "    df_wide = df_wide.merge(base_cols, on=['para_id', 'section_id'], how='left')\n",
    "    \n",
    "    return df_wide\n",
    "\n",
    "# Create the wide format dataframe\n",
    "df_final_wide = create_wide_analysis_df()\n",
    "\n",
    "print(f\"Shape of wide analysis dataframe: {df_final_wide.shape}\")\n",
    "print(f\"Unique para_ids: {df_final_wide['para_id'].nunique()}\")\n",
    "print(f\"Unique (para_id, section_id) combinations: {len(df_final_wide)}\")\n",
    "\n",
    "print(f\"\\nColumns in final wide dataframe:\")\n",
    "for col in df_final_wide.columns:\n",
    "    print(f\"  {col}\")\n",
    "\n",
    "print(f\"\\nDistribution by category:\")\n",
    "print(df_final_wide['category'].value_counts())\n",
    "\n",
    "print(f\"\\nFirst 3 rows (showing key columns):\")\n",
    "key_cols = ['para_id', 'section_id', 'category', 'confidence_deepseek', 'confidence_llama', 'confidence_openai']\n",
    "print(df_final_wide[key_cols].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03b00027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['para_id', 'section_id', 'category', 'case_law_excerpt_deepseek',\n",
       "       'legislation_excerpt_deepseek', 'confidence_deepseek',\n",
       "       'reasoning_deepseek', 'case_law_excerpt_llama',\n",
       "       'legislation_excerpt_llama', 'confidence_llama', 'reasoning_llama',\n",
       "       'case_law_excerpt_openai', 'legislation_excerpt_openai',\n",
       "       'confidence_openai', 'reasoning_openai', 'paragraphs', 'section_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_wide.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e47c7d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a_all_high', 'b_2high_1low', 'c_1high_2low', 'd_all_low'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_wide.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90d6fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4631\n",
      "2604\n",
      "1229\n",
      "538\n"
     ]
    }
   ],
   "source": [
    "print(df_final_wide[df_final_wide['category'] == 'a_all_high']['para_id'].nunique())\n",
    "print(df_final_wide[df_final_wide['category'] == 'b_2high_1low']['para_id'].nunique())\n",
    "\n",
    "print(df_final_wide[df_final_wide['category'] == 'c_1high_2low']['para_id'].nunique())\n",
    "print(df_final_wide[df_final_wide['category'] == 'd_all_low']['para_id'].nunique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8ea28ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_wide.to_csv('../data/final_test/final/reexperiment/fewhot/11August/df_final_wide_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_all_low.to_csv('../data/final_test/final/reexperiment/fewhot/11August/df_source_all_low_for_claude.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc867995",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_regenrated = pd.read_csv('../data/final_test/final/reexperiment/fewhot/11August/df_source_all_low_for_claude_output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f67abbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(claude_regenrated[claude_regenrated['confidence'] == 'High']['para_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13325a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_wide = pd.read_csv('../data/final_test/final/reexperiment/fewhot/11August/df_final_wide_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd536c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(claude_regenrated[claude_regenrated['confidence'] == 'High']['para_id'].unique()) - set(df_final_wide['para_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "169879ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the df_final_wide with category 'd_all_low' to compare with Claude's output\n",
    "df_final_wide_d_all_low = df_final_wide[df_final_wide['category'] == 'd_all_low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1208ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerated_Success = set(claude_regenrated[claude_regenrated['confidence'] == 'High']['para_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11d3f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_review_para_ids = set(df_final_wide_d_all_low.para_id.unique()) - regenerated_Success "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e42ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(for_review_para_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c05445b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_for_review = df_source[df_source['para_id'].isin(for_review_para_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1f80508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_for_review.to_csv('../data/final_test/final/reexperiment/fewhot/11August/df_source_for_review.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
