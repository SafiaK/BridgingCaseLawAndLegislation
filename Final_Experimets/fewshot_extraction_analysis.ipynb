{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22a58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_source = pd.read_csv('../data/final_test/final/reexperiment/combined_sourcedf_final_rebuild.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41da6e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "if 'ewca_civ_2018_162#para_13' in df_source.para_id.unique():\n",
    "    print(\"Yes\")\n",
    "else:\n",
    "    print(\"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ae701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_pairs = set(zip(df_source['para_id'], df_source['section_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0f5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openai_new = pd.read_csv('../data/final_test/final/reexperiment/fewhot/11August/redo-gpt-4o-mini_output-combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e727fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['eat_2022_192#para_12', 'eat_2022_192#para_18',\n",
       "       'eat_2022_192#para_21', ..., 'ewfc_b_2024_69#para_203',\n",
       "       'uksc_2013_11#para_42', 'ewhc_qb_2017_294#para_29'],\n",
       "      shape=(9002,), dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openai_new.para_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa39430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "if 'ewca_civ_2018_162#para_13' in df_openai_new.para_id.unique():\n",
    "    print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b18ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_openai_new[df_openai_new.para_id == 'ewca_civ_2018_162#para_13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf28514a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The benefits that the Appellant obtained through his criminal tipping on the Land are irrelevant to that claim or its quantification. Moreover, the argument to be made on the strength of this evidence would appear to involve a claim to share in the Appellant’s proceeds of crime, which might well be open to objection in principle.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['case_law_excerpt'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3293e9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'may make a confiscation order under that section'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['legislation_excerpt'].values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4684f5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The case law discusses the implications of considering the benefits gained through unlawful actions, which relates directly to the court's ability to make confiscation orders as outlined in the legislation.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['reasoning'].values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9379c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied',\n",
       "       'application_of_law_phrases', 'reason', 'if_law_applied_llama',\n",
       "       'application_of_law_phrases_llama', 'reason_llama',\n",
       "       'if_law_applied_claude', 'application_of_law_phrases_claude',\n",
       "       'reason_claude', 'confidence', 'agreement_with', 'final_annotation',\n",
       "       'case_name', 'section_id', 'section_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654bf14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['custom_id', 'para_id', 'section_id', 'phrase_index',\n",
       "       'case_law_excerpt', 'legislation_excerpt', 'confidence', 'reasoning',\n",
       "       'para_text', 'section_text', 'line_number', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openai_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b75af3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered df_openai_new: 35640\n",
      "Length after adding missing records: 35824\n",
      "Added 184 missing records\n"
     ]
    }
   ],
   "source": [
    "df_openai_new = df_openai_new[df_openai_new.status == 'SUCCESS']\n",
    "# Filter df_openai_new to only keep rows where (para_id, section_id) exists in source_pairs\n",
    "df_openai_new = df_openai_new[df_openai_new.apply(lambda row: (row['para_id'], row['section_id']) in source_pairs, axis=1)]\n",
    "\n",
    "print(f\"Length of filtered df_openai_new: {len(df_openai_new)}\")\n",
    "\n",
    "# Get existing pairs in df_openai_new\n",
    "existing_pairs = set(zip(df_openai_new['para_id'], df_openai_new['section_id']))\n",
    "\n",
    "# Find missing pairs that are in source_pairs but not in df_openai_new\n",
    "missing_pairs = source_pairs - existing_pairs\n",
    "\n",
    "# Create records for missing pairs\n",
    "missing_records = []\n",
    "for para_id, section_id in missing_pairs:\n",
    "    # Get the corresponding row from df_source\n",
    "    source_row = df_source[(df_source['para_id'] == para_id) & \n",
    "                          (df_source['section_id'] == section_id)].iloc[0]\n",
    "    \n",
    "    missing_record = {\n",
    "        'custom_id': '000',\n",
    "        'para_id': para_id,\n",
    "        'section_id': section_id,\n",
    "        'phrase_index': -1,\n",
    "        'case_law_excerpt': None,\n",
    "        'legislation_excerpt': None,\n",
    "        'confidence': 'Low',\n",
    "        'reasoning': None,\n",
    "        'para_text': source_row['paragraphs'],  # assuming this column exists in df_source\n",
    "        'section_text': source_row['section_text'],  # assuming this column exists in df_source\n",
    "        'line_number': '000',\n",
    "        'status': 'Dummy',\n",
    "        'is_valid': False  # assuming missing records are not valid\n",
    "    }\n",
    "    missing_records.append(missing_record)\n",
    "\n",
    "# Convert to DataFrame and concatenate\n",
    "if missing_records:\n",
    "    df_missing = pd.DataFrame(missing_records)\n",
    "    df_openai_new = pd.concat([df_openai_new, df_missing], ignore_index=True)\n",
    "\n",
    "print(f\"Length after adding missing records: {len(df_openai_new)}\")\n",
    "print(f\"Added {len(missing_records)} missing records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e0567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openai_new.para_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e2c41c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confidence\n",
       "High    30044\n",
       "Low      5780\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openai_new.confidence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08873ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_special_chars(s):\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    # Remove all non-alphanumeric and non-space characters\n",
    "    return re.sub(r'[^A-Za-z0-9 ]+', '', s)\n",
    "def check_valid(row):\n",
    "    #case_ok = str(row.get('case_law_excerpt', '')) in str(row.get('para_text', ''))\n",
    "    legis_ok = str(row.get('legislation_excerpt', '')) in str(row.get('section_text', ''))\n",
    "    if legis_ok:#if case_ok and legis_ok:\n",
    "        return True\n",
    "    cleaned_caselaw_excerpt = remove_special_chars(row.get('case_law_excerpt', ''))\n",
    "    cleaned_legislation_excerpt = remove_special_chars(row.get('legislation_excerpt', ''))\n",
    "    cleaned_para_text = remove_special_chars(row.get('para_text', ''))\n",
    "    cleaned_section_text = remove_special_chars(row.get('section_text', ''))\n",
    "    case_ok = str(cleaned_caselaw_excerpt) in str(cleaned_para_text)\n",
    "    legis_ok = str(cleaned_legislation_excerpt) in str(cleaned_section_text)    \n",
    "    #return case_ok and legis_ok\n",
    "    return legis_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b07c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openai_new['is_valid'] = df_openai_new.apply(check_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca536bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence distribution after update:\n",
      "confidence\n",
      "High    23248\n",
      "Low     12576\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set confidence to 'Low' for records where is_valid is False\n",
    "df_openai_new.loc[df_openai_new['is_valid'] == False, 'confidence'] = 'Low'\n",
    "\n",
    "# Check the result\n",
    "print(\"Confidence distribution after update:\")\n",
    "print(df_openai_new['confidence'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc6a4868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 7701\n"
     ]
    }
   ],
   "source": [
    "High_ids_openai = df_openai_new[df_openai_new['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_openai}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c25aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "Total records: 28382\n",
      "High confidence records: 23248\n",
      "Low confidence records: 5134\n",
      "Unique para_ids: 9002\n",
      "\n",
      "Confidence distribution:\n",
      "confidence\n",
      "High    23248\n",
      "Low      5134\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get para_ids that have at least one High confidence record\n",
    "para_ids_with_high = df_openai_new[df_openai_new['confidence'] == 'High']['para_id'].unique()\n",
    "\n",
    "# Get para_ids that have NO High confidence records (only Low)\n",
    "para_ids_only_low = df_openai_new[~df_openai_new['para_id'].isin(para_ids_with_high)]['para_id'].unique()\n",
    "\n",
    "# Filter the dataframe:\n",
    "# 1. Keep High confidence records for para_ids that have at least one High\n",
    "# 2. Keep Low confidence records only for para_ids that have NO High records\n",
    "df_openai_filtered = df_openai_new[\n",
    "    ((df_openai_new['confidence'] == 'High') & (df_openai_new['para_id'].isin(para_ids_with_high))) |\n",
    "    ((df_openai_new['confidence'] == 'Low') & (df_openai_new['para_id'].isin(para_ids_only_low)))\n",
    "]\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Total records: {len(df_openai_filtered)}\")\n",
    "print(f\"High confidence records: {len(df_openai_filtered[df_openai_filtered['confidence'] == 'High'])}\")\n",
    "print(f\"Low confidence records: {len(df_openai_filtered[df_openai_filtered['confidence'] == 'Low'])}\")\n",
    "print(f\"Unique para_ids: {df_openai_filtered['para_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nConfidence distribution:\")\n",
    "print(df_openai_filtered['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d21abd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the high confidence records with [para_id, section_id] unique pairs\n",
    "df_openai_new_high = df_openai_new[df_openai_new['confidence'] == 'Low']\n",
    "\n",
    "\n",
    "#get the unique pairs\n",
    "unique_pairs_openai = df_openai_new_high[['para_id', 'section_id']].drop_duplicates()\n",
    "\n",
    "\n",
    "#get the unique pairs that are in df_openai_new_high but not in df_llama_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23cbd7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para_id</th>\n",
       "      <th>section_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eat_2022_192#para_12</td>\n",
       "      <td>id/ukpga/2010/15_schedule-8-part-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eat_2022_192#para_18</td>\n",
       "      <td>id/ukpga/2010/15_schedule-8-part-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eat_2022_192#para_21</td>\n",
       "      <td>id/ukpga/2010/15_section-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eat_2022_192#para_28</td>\n",
       "      <td>id/ukpga/2010/15_schedule-8-part-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>eat_2022_192#para_28</td>\n",
       "      <td>id/ukpga/2010/15_section-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35819</th>\n",
       "      <td>ewhc_comm_2005_2115#para_57</td>\n",
       "      <td>id/ukpga/1982/27_schedule-4-part-TITLE-II-chap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35820</th>\n",
       "      <td>ewhc_comm_2023_2866#para_55</td>\n",
       "      <td>id/ukpga/2018/13_section-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35821</th>\n",
       "      <td>ewhc_admin_2003_1578#para_73</td>\n",
       "      <td>id/ukpga/1965/64_section-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35822</th>\n",
       "      <td>ukftt_tc_2022_201#para_49</td>\n",
       "      <td>id/ukpga/1994/23_schedule-8-part-II_chunk_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35823</th>\n",
       "      <td>ewhc_admin_2003_1837#para_34</td>\n",
       "      <td>id/ukpga/1988/50_schedule-10-part-II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            para_id  \\\n",
       "2              eat_2022_192#para_12   \n",
       "6              eat_2022_192#para_18   \n",
       "8              eat_2022_192#para_21   \n",
       "16             eat_2022_192#para_28   \n",
       "18             eat_2022_192#para_28   \n",
       "...                             ...   \n",
       "35819   ewhc_comm_2005_2115#para_57   \n",
       "35820   ewhc_comm_2023_2866#para_55   \n",
       "35821  ewhc_admin_2003_1578#para_73   \n",
       "35822     ukftt_tc_2022_201#para_49   \n",
       "35823  ewhc_admin_2003_1837#para_34   \n",
       "\n",
       "                                              section_id  \n",
       "2                     id/ukpga/2010/15_schedule-8-part-3  \n",
       "6                     id/ukpga/2010/15_schedule-8-part-1  \n",
       "8                            id/ukpga/2010/15_section-16  \n",
       "16                    id/ukpga/2010/15_schedule-8-part-3  \n",
       "18                           id/ukpga/2010/15_section-60  \n",
       "...                                                  ...  \n",
       "35819  id/ukpga/1982/27_schedule-4-part-TITLE-II-chap...  \n",
       "35820                        id/ukpga/2018/13_section-39  \n",
       "35821                        id/ukpga/1965/64_section-16  \n",
       "35822        id/ukpga/1994/23_schedule-8-part-II_chunk_4  \n",
       "35823               id/ukpga/1988/50_schedule-10-part-II  \n",
       "\n",
       "[6380 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_pairs_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d2b80c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6380"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18004-11624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e208a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter df_llama based on source_pairs\n",
    "df_openai_pair = df_openai_new[df_openai_new.apply(lambda row: (row['para_id'], row['section_id']) in source_pairs, axis=1)]\n",
    "\n",
    "# Get high confidence pairs\n",
    "df_openai_high_pairs = df_openai_pair[df_openai_pair['confidence'] == 'High']\n",
    "df_openai_high_pairs = df_openai_high_pairs[['para_id', 'section_id']].drop_duplicates()\n",
    "\n",
    "# Convert high pairs to a set of tuples for efficient lookup\n",
    "high_pairs_set_openai = set(df_openai_high_pairs.apply(lambda row: (row['para_id'], row['section_id']), axis=1))\n",
    "\n",
    "# Get low confidence pairs that are not in high confidence pairs\n",
    "df_openai_low_pairs = df_openai_new[\n",
    "    (df_openai_new['confidence'] == 'Low') & \n",
    "    (~df_openai_new.apply(lambda row: (row['para_id'], row['section_id']) in high_pairs_set_openai, axis=1))\n",
    "]\n",
    "df_openai_low_pairs = df_openai_low_pairs[['para_id', 'section_id']].drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "64b5d020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para_id</th>\n",
       "      <th>section_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eat_2022_192#para_12</td>\n",
       "      <td>id/ukpga/2010/15_section-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eat_2022_192#para_18</td>\n",
       "      <td>id/ukpga/2010/15_section-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>eat_2022_192#para_21</td>\n",
       "      <td>id/ukpga/2010/15_schedule-1-part-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eat_2022_192#para_22</td>\n",
       "      <td>id/ukpga/2010/15_section-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>eat_2022_192#para_22</td>\n",
       "      <td>id/ukpga/2010/15_section-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35624</th>\n",
       "      <td>ewca_civ_2023_239#para_99</td>\n",
       "      <td>http://www.legislation.gov.uk/id/ukpga/1996/40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35628</th>\n",
       "      <td>ewfc_b_2024_69#para_203</td>\n",
       "      <td>id/ukpga/1989/41_section-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35630</th>\n",
       "      <td>ewfc_b_2024_69#para_203</td>\n",
       "      <td>id/ukpga/2021/17_section-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>uksc_2013_11#para_42</td>\n",
       "      <td>id/ukpga/1986/60_section-61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35636</th>\n",
       "      <td>ewhc_qb_2017_294#para_29</td>\n",
       "      <td>http://www.legislation.gov.uk/id/ukpga/1990/8/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11624 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         para_id  \\\n",
       "0           eat_2022_192#para_12   \n",
       "4           eat_2022_192#para_18   \n",
       "10          eat_2022_192#para_21   \n",
       "12          eat_2022_192#para_22   \n",
       "14          eat_2022_192#para_22   \n",
       "...                          ...   \n",
       "35624  ewca_civ_2023_239#para_99   \n",
       "35628    ewfc_b_2024_69#para_203   \n",
       "35630    ewfc_b_2024_69#para_203   \n",
       "35632       uksc_2013_11#para_42   \n",
       "35636   ewhc_qb_2017_294#para_29   \n",
       "\n",
       "                                              section_id  \n",
       "0                            id/ukpga/2010/15_section-60  \n",
       "4                            id/ukpga/2010/15_section-60  \n",
       "10                    id/ukpga/2010/15_schedule-1-part-1  \n",
       "12                           id/ukpga/2010/15_section-60  \n",
       "14                           id/ukpga/2010/15_section-16  \n",
       "...                                                  ...  \n",
       "35624  http://www.legislation.gov.uk/id/ukpga/1996/40...  \n",
       "35628                         id/ukpga/1989/41_section-1  \n",
       "35630                        id/ukpga/2021/17_section-57  \n",
       "35632                        id/ukpga/1986/60_section-61  \n",
       "35636  http://www.legislation.gov.uk/id/ukpga/1990/8/...  \n",
       "\n",
       "[11624 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openai_high_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73e541fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 7701\n",
      "Number of para_ids with at least one Low entry: 1301\n"
     ]
    }
   ],
   "source": [
    "High_ids_openai = df_openai_filtered[df_openai_filtered['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_openai}\")\n",
    "\n",
    "Low_ids_openai = df_openai_filtered[df_openai_filtered['confidence'] == 'Low']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one Low entry: {Low_ids_openai}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e791a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_llama = pd.read_csv('../data/final_test/final/reexperiment/fewhot/11August/llama_combined_output_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6663e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llama = df_llama[df_llama.status == 'SUCCESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f66ade0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered df_llama: 22696\n",
      "Length after adding missing records: 22696\n",
      "Added 0 missing records\n"
     ]
    }
   ],
   "source": [
    "df_llama = df_llama[df_llama.apply(lambda row: (row['para_id'], row['section_id']) in source_pairs, axis=1)]\n",
    "\n",
    "print(f\"Length of filtered df_llama: {len(df_llama)}\")\n",
    "\n",
    "# Get existing pairs in df_llama\n",
    "existing_pairs_llama = set(zip(df_llama['para_id'], df_llama['section_id']))\n",
    "\n",
    "# Find missing pairs that are in source_pairs but not in df_llama\n",
    "missing_pairs_llama = source_pairs - existing_pairs_llama\n",
    "\n",
    "# Create records for missing pairs\n",
    "missing_records = []\n",
    "for para_id, section_id in missing_pairs_llama:\n",
    "    # Get the corresponding row from df_source\n",
    "    source_row = df_source[(df_source['para_id'] == para_id) & \n",
    "                          (df_source['section_id'] == section_id)].iloc[0]\n",
    "    \n",
    "    missing_record = {\n",
    "        'custom_id': '000',\n",
    "        'para_id': para_id,\n",
    "        'section_id': section_id,\n",
    "        'phrase_index': -1,\n",
    "        'case_law_excerpt': None,\n",
    "        'legislation_excerpt': None,\n",
    "        'confidence': 'Low',\n",
    "        'reasoning': None,\n",
    "        'para_text': source_row['paragraphs'],  # assuming this column exists in df_source\n",
    "        'section_text': source_row['section_text'],  # assuming this column exists in df_source\n",
    "        'line_number': '000',\n",
    "        'status': 'Dummy',\n",
    "        'is_valid': False  # assuming missing records are not valid\n",
    "    }\n",
    "    missing_records.append(missing_record)\n",
    "\n",
    "# Convert to DataFrame and concatenate\n",
    "if missing_records:\n",
    "    df_missing = pd.DataFrame(missing_records)\n",
    "    df_llama = pd.concat([df_llama, df_missing], ignore_index=True)\n",
    "\n",
    "print(f\"Length after adding missing records: {len(df_llama)}\")\n",
    "print(f\"Added {len(missing_records)} missing records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "482c3c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>para_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>phrase_index</th>\n",
       "      <th>case_law_excerpt</th>\n",
       "      <th>legislation_excerpt</th>\n",
       "      <th>confidence</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>para_text</th>\n",
       "      <th>section_text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>status</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>request_2477</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-170</td>\n",
       "      <td>0</td>\n",
       "      <td>the benefits that the Appellant obtained throu...</td>\n",
       "      <td>evidence which was not available to the prosec...</td>\n",
       "      <td>Low</td>\n",
       "      <td>The court's decision to refuse permission to a...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>170 No order made: reconsideration of benefit ...</td>\n",
       "      <td>2466</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>request_2478</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-20</td>\n",
       "      <td>0</td>\n",
       "      <td>the benefits that the Appellant obtained throu...</td>\n",
       "      <td>the court concludes that it would have decided...</td>\n",
       "      <td>Low</td>\n",
       "      <td>The court's decision to refuse permission to a...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>20 No order made: reconsideration of benefit (...</td>\n",
       "      <td>2483</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         custom_id                    para_id                    section_id  \\\n",
       "2052  request_2477  ewca_civ_2018_162#para_13  id/ukpga/2002/29_section-170   \n",
       "2066  request_2478  ewca_civ_2018_162#para_13   id/ukpga/2002/29_section-20   \n",
       "\n",
       "      phrase_index                                   case_law_excerpt  \\\n",
       "2052             0  the benefits that the Appellant obtained throu...   \n",
       "2066             0  the benefits that the Appellant obtained throu...   \n",
       "\n",
       "                                    legislation_excerpt confidence  \\\n",
       "2052  evidence which was not available to the prosec...        Low   \n",
       "2066  the court concludes that it would have decided...        Low   \n",
       "\n",
       "                                              reasoning  \\\n",
       "2052  The court's decision to refuse permission to a...   \n",
       "2066  The court's decision to refuse permission to a...   \n",
       "\n",
       "                                              para_text  \\\n",
       "2052  13. We refused permission to adduce this evide...   \n",
       "2066  13. We refused permission to adduce this evide...   \n",
       "\n",
       "                                           section_text line_number   status  \\\n",
       "2052  170 No order made: reconsideration of benefit ...        2466  SUCCESS   \n",
       "2066  20 No order made: reconsideration of benefit (...        2483  SUCCESS   \n",
       "\n",
       "      is_valid  \n",
       "2052      True  \n",
       "2066      True  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llama[df_llama.para_id == 'ewca_civ_2018_162#para_13']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6c7576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence distribution after update:\n",
      "confidence\n",
      "Low     14957\n",
      "High     7739\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_llama['is_valid'] = df_llama.apply(check_valid, axis=1)\n",
    "\n",
    "# Set confidence to 'Low' for records where is_valid is False\n",
    "df_llama.loc[df_llama['is_valid'] == False, 'confidence'] = 'Low'\n",
    "\n",
    "# Check the result\n",
    "print(\"Confidence distribution after update:\")\n",
    "print(df_llama['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c31e8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llama.loc[df_llama['confidence'] == 'Medium', 'confidence'] = 'High'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25dd448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence\n",
      "Low     14957\n",
      "High     7739\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_llama['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e61186fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 5492\n"
     ]
    }
   ],
   "source": [
    "High_ids_llama = df_llama[df_llama['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_llama}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e4e598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "Total records: 16816\n",
      "High confidence records: 7739\n",
      "Low confidence records: 9077\n",
      "Unique para_ids: 9002\n",
      "\n",
      "Confidence distribution:\n",
      "confidence\n",
      "Low     9077\n",
      "High    7739\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get para_ids that have at least one High confidence record\n",
    "para_ids_with_high_llama = df_llama[df_llama['confidence'] == 'High']['para_id'].unique()\n",
    "\n",
    "# Get para_ids that have NO High confidence records (only Low)\n",
    "para_ids_only_low_llama = df_llama[~df_llama['para_id'].isin(para_ids_with_high_llama)]['para_id'].unique()\n",
    "\n",
    "# Filter the dataframe:\n",
    "# 1. Keep High confidence records for para_ids that have at least one High\n",
    "# 2. Keep Low confidence records only for para_ids that have NO High records\n",
    "df_llama_filtered = df_llama[\n",
    "    ((df_llama['confidence'] == 'High') & (df_llama['para_id'].isin(para_ids_with_high_llama))) |\n",
    "    ((df_llama['confidence'] == 'Low') & (df_llama['para_id'].isin(para_ids_only_low_llama)))\n",
    "]\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Total records: {len(df_llama_filtered)}\")\n",
    "print(f\"High confidence records: {len(df_llama_filtered[df_llama_filtered['confidence'] == 'High'])}\")\n",
    "print(f\"Low confidence records: {len(df_llama_filtered[df_llama_filtered['confidence'] == 'Low'])}\")\n",
    "print(f\"Unique para_ids: {df_llama_filtered['para_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nConfidence distribution:\")\n",
    "print(df_llama_filtered['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb0c89de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 5492\n",
      "Number of para_ids with at least one Low entry: 3510\n"
     ]
    }
   ],
   "source": [
    "High_ids_llama = df_llama_filtered[df_llama_filtered['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_llama}\")\n",
    "\n",
    "Low_ids_llama = df_llama_filtered[df_llama_filtered['confidence'] == 'Low']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one Low entry: {Low_ids_llama}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c409e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter df_llama based on source_pairs\n",
    "df_llama = df_llama[df_llama.apply(lambda row: (row['para_id'], row['section_id']) in source_pairs, axis=1)]\n",
    "\n",
    "# Get high confidence pairs\n",
    "df_llama_high_pairs = df_llama[df_llama['confidence'] == 'High']\n",
    "df_llama_high_pairs = df_llama_high_pairs[['para_id', 'section_id']].drop_duplicates()\n",
    "\n",
    "# Convert high pairs to a set of tuples for efficient lookup\n",
    "high_pairs_set = set(df_llama_high_pairs.apply(lambda row: (row['para_id'], row['section_id']), axis=1))\n",
    "\n",
    "# Get low confidence pairs that are not in high confidence pairs\n",
    "df_llama_low_pairs = df_llama[\n",
    "    (df_llama['confidence'] == 'Low') & \n",
    "    (~df_llama.apply(lambda row: (row['para_id'], row['section_id']) in high_pairs_set, axis=1))\n",
    "]\n",
    "df_llama_low_pairs = df_llama_low_pairs[['para_id', 'section_id']].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf49e71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para_id</th>\n",
       "      <th>section_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eat_2022_192#para_34</td>\n",
       "      <td>id/ukpga/2010/15_section-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>eat_2022_192#para_18</td>\n",
       "      <td>id/ukpga/2010/15_schedule-8-part-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eat_2022_192#para_66</td>\n",
       "      <td>id/ukpga/2010/15_schedule-8-part-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>eat_2022_192#para_70</td>\n",
       "      <td>id/ukpga/2010/15_schedule-8-part-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>eat_2022_192#para_64</td>\n",
       "      <td>id/ukpga/2010/15_schedule-8-part-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21120</th>\n",
       "      <td>ukftt_tc_2024_744#para_136</td>\n",
       "      <td>id/ukpga/1992/4_schedule-4B-part-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21126</th>\n",
       "      <td>ukftt_tc_2024_462#para_132</td>\n",
       "      <td>id/ukpga/2007/3_section-225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21200</th>\n",
       "      <td>uksc_2013_37#para_20</td>\n",
       "      <td>id/ukpga/1988/36_section-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21204</th>\n",
       "      <td>uksc_2022_30#para_35</td>\n",
       "      <td>id/ukpga/1990/8_section-75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21221</th>\n",
       "      <td>ukut_aac_2016_355#para_32</td>\n",
       "      <td>id/ukpga/1998/14_section-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7548 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          para_id                          section_id\n",
       "4            eat_2022_192#para_34         id/ukpga/2010/15_section-60\n",
       "10           eat_2022_192#para_18  id/ukpga/2010/15_schedule-8-part-1\n",
       "12           eat_2022_192#para_66  id/ukpga/2010/15_schedule-8-part-3\n",
       "14           eat_2022_192#para_70  id/ukpga/2010/15_schedule-8-part-1\n",
       "15           eat_2022_192#para_64  id/ukpga/2010/15_schedule-8-part-3\n",
       "...                           ...                                 ...\n",
       "21120  ukftt_tc_2024_744#para_136  id/ukpga/1992/4_schedule-4B-part-2\n",
       "21126  ukftt_tc_2024_462#para_132         id/ukpga/2007/3_section-225\n",
       "21200        uksc_2013_37#para_20         id/ukpga/1988/36_section-41\n",
       "21204        uksc_2022_30#para_35          id/ukpga/1990/8_section-75\n",
       "21221   ukut_aac_2016_355#para_32         id/ukpga/1998/14_section-14\n",
       "\n",
       "[7548 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llama_high_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ecfefb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18004"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10456 +7548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5186b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deepseek = pd.read_csv('../data/final_test/final/reexperiment/fewhot/11August/deepseek_combined_output_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "45bf2d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>para_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>phrase_index</th>\n",
       "      <th>case_law_excerpt</th>\n",
       "      <th>legislation_excerpt</th>\n",
       "      <th>confidence</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>para_text</th>\n",
       "      <th>section_text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>request_2478</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-20</td>\n",
       "      <td>0</td>\n",
       "      <td>We refused permission to adduce this evidence....</td>\n",
       "      <td>If this section applies the court— (a) must ma...</td>\n",
       "      <td>High</td>\n",
       "      <td>The case law excerpt discusses the refusal to ...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>20 No order made: reconsideration of benefit (...</td>\n",
       "      <td>2474</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>request_2477</td>\n",
       "      <td>ewca_civ_2018_162#para_13</td>\n",
       "      <td>id/ukpga/2002/29_section-170</td>\n",
       "      <td>0</td>\n",
       "      <td>The benefits that the Appellant obtained throu...</td>\n",
       "      <td>the court has decided that— (a) the defendant ...</td>\n",
       "      <td>High</td>\n",
       "      <td>The case law discusses the irrelevance of crim...</td>\n",
       "      <td>13. We refused permission to adduce this evide...</td>\n",
       "      <td>170 No order made: reconsideration of benefit ...</td>\n",
       "      <td>2485</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         custom_id                    para_id                    section_id  \\\n",
       "2198  request_2478  ewca_civ_2018_162#para_13   id/ukpga/2002/29_section-20   \n",
       "2207  request_2477  ewca_civ_2018_162#para_13  id/ukpga/2002/29_section-170   \n",
       "\n",
       "      phrase_index                                   case_law_excerpt  \\\n",
       "2198             0  We refused permission to adduce this evidence....   \n",
       "2207             0  The benefits that the Appellant obtained throu...   \n",
       "\n",
       "                                    legislation_excerpt confidence  \\\n",
       "2198  If this section applies the court— (a) must ma...       High   \n",
       "2207  the court has decided that— (a) the defendant ...       High   \n",
       "\n",
       "                                              reasoning  \\\n",
       "2198  The case law excerpt discusses the refusal to ...   \n",
       "2207  The case law discusses the irrelevance of crim...   \n",
       "\n",
       "                                              para_text  \\\n",
       "2198  13. We refused permission to adduce this evide...   \n",
       "2207  13. We refused permission to adduce this evide...   \n",
       "\n",
       "                                           section_text  line_number   status  \n",
       "2198  20 No order made: reconsideration of benefit (...         2474  SUCCESS  \n",
       "2207  170 No order made: reconsideration of benefit ...         2485  SUCCESS  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ewca_civ_2018_162#para_13' in df_deepseek.para_id.unique()\n",
    "df_deepseek[df_deepseek['para_id'] == 'ewca_civ_2018_162#para_13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b1f9bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deepseek = df_deepseek[df_deepseek.status == 'SUCCESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1569a60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered df_deepseek: 21792\n",
      "Length after adding missing records: 22247\n",
      "Added 455 missing records\n"
     ]
    }
   ],
   "source": [
    "# Filter df_deepseek to only keep rows where (para_id, section_id) exists in source_pairs\n",
    "df_deepseek = df_deepseek[df_deepseek.apply(lambda row: (row['para_id'], row['section_id']) in source_pairs, axis=1)]\n",
    "\n",
    "print(f\"Length of filtered df_deepseek: {len(df_deepseek)}\")\n",
    "\n",
    "# Get existing pairs in df_deepseek\n",
    "existing_pairs_deepseek = set(zip(df_deepseek['para_id'], df_deepseek['section_id']))\n",
    "\n",
    "# Find missing pairs that are in source_pairs but not in df_deepseek\n",
    "missing_pairs_deepseek = source_pairs - existing_pairs_deepseek\n",
    "\n",
    "# Create records for missing pairs\n",
    "missing_records_deepseek = []\n",
    "for para_id, section_id in missing_pairs_deepseek:\n",
    "    # Get the corresponding row from df_source\n",
    "    source_row = df_source[(df_source['para_id'] == para_id) & \n",
    "                          (df_source['section_id'] == section_id)].iloc[0]\n",
    "    \n",
    "    missing_record_deepseek = {\n",
    "        'custom_id': '000',\n",
    "        'para_id': para_id,\n",
    "        'section_id': section_id,\n",
    "        'phrase_index': -1,\n",
    "        'case_law_excerpt': None,\n",
    "        'legislation_excerpt': None,\n",
    "        'confidence': 'Low',\n",
    "        'reasoning': None,\n",
    "        'para_text': source_row['paragraphs'],  # assuming this column exists in df_source\n",
    "        'section_text': source_row['section_text'],  # assuming this column exists in df_source\n",
    "        'line_number': '000',\n",
    "        'status': 'Dummy',\n",
    "        'is_valid': False  # assuming missing records are not valid\n",
    "    }\n",
    "    missing_records_deepseek.append(missing_record_deepseek)\n",
    "\n",
    "# Convert to DataFrame and concatenate\n",
    "if missing_records_deepseek:\n",
    "    df_missing_deepseek = pd.DataFrame(missing_records_deepseek)\n",
    "    df_deepseek = pd.concat([df_deepseek, df_missing_deepseek], ignore_index=True)\n",
    "\n",
    "print(f\"Length after adding missing records: {len(df_deepseek)}\")\n",
    "print(f\"Added {len(missing_records_deepseek)} missing records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a1c9db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence distribution after update:\n",
      "confidence\n",
      "Low         11413\n",
      "High        10753\n",
      "Medium         64\n",
      "Moderate       16\n",
      "No match        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_deepseek['is_valid'] = df_deepseek.apply(check_valid, axis=1)\n",
    "\n",
    "# Set confidence to 'Low' for records where is_valid is False\n",
    "df_deepseek.loc[df_deepseek['is_valid'] == False, 'confidence'] = 'Low'\n",
    "\n",
    "# Check the result\n",
    "print(\"Confidence distribution after update:\")\n",
    "print(df_deepseek['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de70dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deepseek.loc[df_deepseek['confidence'] == 'Medium', 'confidence'] = 'High'\n",
    "df_deepseek.loc[df_deepseek['confidence'] == 'Moderate', 'confidence'] = 'High'\n",
    "df_deepseek.loc[df_deepseek['confidence'] == 'No match', 'confidence'] = 'Low'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "16ce140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence distribution after update:\n",
      "confidence\n",
      "Low     11414\n",
      "High    10833\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Confidence distribution after update:\")\n",
    "print(df_deepseek['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "36b0f6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 7137\n"
     ]
    }
   ],
   "source": [
    "High_ids_deepseek = df_deepseek[df_deepseek['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_deepseek}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0815ddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "Total records: 16065\n",
      "High confidence records: 10833\n",
      "Low confidence records: 5232\n",
      "Unique para_ids: 9002\n",
      "\n",
      "Confidence distribution:\n",
      "confidence\n",
      "High    10833\n",
      "Low      5232\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get para_ids that have at least one High confidence record\n",
    "para_ids_with_high_deepseek = df_deepseek[df_deepseek['confidence'] == 'High']['para_id'].unique()\n",
    "\n",
    "# Get para_ids that have NO High confidence records (only Low)\n",
    "para_ids_only_low_deepseek = df_deepseek[~df_deepseek['para_id'].isin(para_ids_with_high_deepseek)]['para_id'].unique()\n",
    "\n",
    "# Filter the dataframe:\n",
    "# 1. Keep High confidence records for para_ids that have at least one High\n",
    "# 2. Keep Low confidence records only for para_ids that have NO High records\n",
    "df_deepseek_filtered = df_deepseek[\n",
    "    ((df_deepseek['confidence'] == 'High') & (df_deepseek['para_id'].isin(para_ids_with_high_deepseek))) |\n",
    "    ((df_deepseek['confidence'] == 'Low') & (df_deepseek['para_id'].isin(para_ids_only_low_deepseek)))\n",
    "]\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Total records: {len(df_deepseek_filtered)}\")\n",
    "print(f\"High confidence records: {len(df_deepseek_filtered[df_deepseek_filtered['confidence'] == 'High'])}\")\n",
    "print(f\"Low confidence records: {len(df_deepseek_filtered[df_deepseek_filtered['confidence'] == 'Low'])}\")\n",
    "print(f\"Unique para_ids: {df_deepseek_filtered['para_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nConfidence distribution:\")\n",
    "print(df_deepseek_filtered['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "66e33f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with at least one High entry: 7137\n",
      "Number of para_ids with at least one Low entry: 1865\n"
     ]
    }
   ],
   "source": [
    "High_ids_deepseek = df_deepseek_filtered[df_deepseek_filtered['confidence'] == 'High']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one High entry: {High_ids_deepseek}\")\n",
    "\n",
    "Low_ids_deepseek = df_deepseek_filtered[df_deepseek_filtered['confidence'] == 'Low']['para_id'].nunique()\n",
    "print(f\"Number of para_ids with at least one Low entry: {Low_ids_deepseek}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "470a25a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4631"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_deepseek_filtered[df_deepseek_filtered['confidence'] == 'High']['para_id'].unique())&set(df_llama_filtered[df_llama_filtered['confidence'] == 'High']['para_id'].unique())&set(df_openai_filtered[df_openai_filtered['confidence'] == 'High']['para_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87f87af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter df_llama based on source_pairs\n",
    "df_deepseek = df_deepseek[df_deepseek.apply(lambda row: (row['para_id'], row['section_id']) in source_pairs, axis=1)]\n",
    "\n",
    "# Get high confidence pairs\n",
    "df_deepseek_high_pairs = df_deepseek[df_deepseek['confidence'] == 'High']\n",
    "df_deepseek_high_pairs = df_deepseek_high_pairs[['para_id', 'section_id']].drop_duplicates()\n",
    "\n",
    "# Convert high pairs to a set of tuples for efficient lookup\n",
    "high_pairs_set_deepseek = set(df_deepseek_high_pairs.apply(lambda row: (row['para_id'], row['section_id']), axis=1))\n",
    "\n",
    "# Get low confidence pairs that are not in high confidence pairs\n",
    "df_deepseek_low_pairs = df_deepseek[\n",
    "    (df_deepseek['confidence'] == 'Low') & \n",
    "    (~df_deepseek.apply(lambda row: (row['para_id'], row['section_id']) in high_pairs_set_deepseek, axis=1))\n",
    "]\n",
    "df_deepseek_low_pairs = df_deepseek_low_pairs[['para_id', 'section_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "679d9ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18004"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10717 + 7287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ce41be39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records per dataframe after keeping one per para_id:\n",
      "DeepSeek: 9002\n",
      "Llama: 9002\n",
      "OpenAI: 9002\n",
      "\n",
      "Total unique para_ids (X): 9002\n",
      "\n",
      "Distribution of para_ids by confidence pattern:\n",
      "a_all_high: 4631 para_ids (51.4%)\n",
      "b_2high_1low: 2604 para_ids (28.9%)\n",
      "c_1high_2low: 1229 para_ids (13.7%)\n",
      "d_all_low: 538 para_ids (6.0%)\n",
      "\n",
      "Verification: 9002 = 9002 ✓\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First, let's ensure each dataframe has only one record per para_id\n",
    "# For para_ids with multiple Low records, keep only one (this should mainly affect df_deepseek_filtered)\n",
    "\n",
    "def keep_one_record_per_para_id(df):\n",
    "    \"\"\"Keep one record per para_id - prefer High confidence, if all Low then keep first\"\"\"\n",
    "    # Group by para_id and keep the first record (High confidence records should already be filtered appropriately)\n",
    "    return df.groupby('para_id').first().reset_index()\n",
    "\n",
    "df_deepseek_final = keep_one_record_per_para_id(df_deepseek_filtered)\n",
    "df_llama_final = keep_one_record_per_para_id(df_llama_filtered)\n",
    "df_openai_final = keep_one_record_per_para_id(df_openai_filtered)\n",
    "\n",
    "print(\"Records per dataframe after keeping one per para_id:\")\n",
    "print(f\"DeepSeek: {len(df_deepseek_final)}\")\n",
    "print(f\"Llama: {len(df_llama_final)}\")\n",
    "print(f\"OpenAI: {len(df_openai_final)}\")\n",
    "\n",
    "# Get all unique para_ids across all three dataframes\n",
    "all_para_ids = set(df_deepseek_final['para_id'].unique()) | \\\n",
    "               set(df_llama_final['para_id'].unique()) | \\\n",
    "               set(df_openai_final['para_id'].unique())\n",
    "\n",
    "X = len(all_para_ids)\n",
    "print(f\"\\nTotal unique para_ids (X): {X}\")\n",
    "\n",
    "# Create a comprehensive dataframe with confidence for each model\n",
    "results = []\n",
    "\n",
    "for para_id in all_para_ids:\n",
    "    # Get confidence for each model (None if para_id not present)\n",
    "    deepseek_conf = df_deepseek_final[df_deepseek_final['para_id'] == para_id]['confidence'].iloc[0] if para_id in df_deepseek_final['para_id'].values else None\n",
    "    llama_conf = df_llama_final[df_llama_final['para_id'] == para_id]['confidence'].iloc[0] if para_id in df_llama_final['para_id'].values else None\n",
    "    openai_conf = df_openai_final[df_openai_final['para_id'] == para_id]['confidence'].iloc[0] if para_id in df_openai_final['para_id'].values else None\n",
    "    \n",
    "    # Count High and Low confidences\n",
    "    confidences = [deepseek_conf, llama_conf, openai_conf]\n",
    "    high_count = confidences.count('High')\n",
    "    low_count = confidences.count('Low')\n",
    "    \n",
    "    results.append({\n",
    "        'para_id': para_id,\n",
    "        'deepseek_conf': deepseek_conf,\n",
    "        'llama_conf': llama_conf,\n",
    "        'openai_conf': openai_conf,\n",
    "        'high_count': high_count,\n",
    "        'low_count': low_count\n",
    "    })\n",
    "\n",
    "df_analysis = pd.DataFrame(results)\n",
    "\n",
    "# Categorize based on High/Low distribution\n",
    "def categorize_confidence(row):\n",
    "    if row['high_count'] == 3:\n",
    "        return 'a_all_high'\n",
    "    elif row['high_count'] == 2 and row['low_count'] == 1:\n",
    "        return 'b_2high_1low'\n",
    "    elif row['high_count'] == 1 and row['low_count'] == 2:\n",
    "        return 'c_1high_2low'\n",
    "    elif row['low_count'] == 3:\n",
    "        return 'd_all_low'\n",
    "    else:\n",
    "        return 'other'  # This shouldn't happen if all para_ids have 3 entries\n",
    "\n",
    "df_analysis['category'] = df_analysis.apply(categorize_confidence, axis=1)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nDistribution of para_ids by confidence pattern:\")\n",
    "category_counts = df_analysis['category'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / X) * 100\n",
    "    print(f\"{category}: {count} para_ids ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nVerification: {category_counts.sum()} = {X} ✓\" if category_counts.sum() == X else f\"\\nError: {category_counts.sum()} ≠ {X}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1814da62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records per dataframe after keeping one per (para_id, section_id) pair:\n",
      "DeepSeek: 18004\n",
      "Llama: 18004\n",
      "OpenAI: 18004\n",
      "\n",
      "Total unique (para_id, section_id) pairs (X): 18004\n",
      "\n",
      "Distribution of (para_id, section_id) pairs by confidence pattern:\n",
      "a_all_high: 4936 pairs (27.4%)\n",
      "b_2high_1low: 5346 pairs (29.7%)\n",
      "c_1high_2low: 4389 pairs (24.4%)\n",
      "d_all_low: 3333 pairs (18.5%)\n",
      "\n",
      "Verification: 18004 = 18004 ✓\n",
      "\n",
      "Sample of analysis results:\n",
      "                        para_id  \\\n",
      "0    ewca_crim_2003_190#para_19   \n",
      "1           ukait_2008_1#para_5   \n",
      "2       ewhc_ch_2012_28#para_70   \n",
      "3      ewca_civ_2019_53#para_29   \n",
      "4   ewhc_comm_2017_1430#para_13   \n",
      "5     ewca_crim_2023_630#para_5   \n",
      "6       ewfc_b_2024_69#para_187   \n",
      "7     ewhc_kb_2023_1256#para_29   \n",
      "8  ewhc_costs_2003_9050#para_23   \n",
      "9   ewhc_admin_2020_801#para_29   \n",
      "\n",
      "                                          section_id deepseek_conf llama_conf  \\\n",
      "0                        id/ukpga/1999/23_section-41          High       High   \n",
      "1                       id/ukpga/2002/41_section-101          High        Low   \n",
      "2                        id/ukpga/1998/42_section-21           Low        Low   \n",
      "3  http://www.legislation.gov.uk/id/ukpga/2002/41...           Low        Low   \n",
      "4                        id/ukpga/1996/23_section-56          High        Low   \n",
      "5               id/ukpga/1988/33_schedule-10-part-IV           Low        Low   \n",
      "6                         id/ukpga/2021/17_section-3          High       High   \n",
      "7                         id/ukpga/2013/26_section-3          High       High   \n",
      "8                         id/ukpga/1990/41_section-4          High       High   \n",
      "9  http://www.legislation.gov.uk/id/ukpga/1980/66...          High       High   \n",
      "\n",
      "  openai_conf  high_count  low_count  none_count      category  \n",
      "0        High           3          0           0    a_all_high  \n",
      "1        High           2          1           0  b_2high_1low  \n",
      "2         Low           0          3           0     d_all_low  \n",
      "3         Low           0          3           0     d_all_low  \n",
      "4         Low           1          2           0  c_1high_2low  \n",
      "5        High           1          2           0  c_1high_2low  \n",
      "6        High           3          0           0    a_all_high  \n",
      "7        High           3          0           0    a_all_high  \n",
      "8        High           3          0           0    a_all_high  \n",
      "9         Low           2          1           0  b_2high_1low  \n"
     ]
    }
   ],
   "source": [
    "# Combine high and low pairs for each model into filtered dataframes\n",
    "def combine_high_low_pairs(high_pairs_df, low_pairs_df, model_name):\n",
    "    \"\"\"Combine high and low confidence pairs into a single dataframe\"\"\"\n",
    "    # Add confidence column to each dataframe\n",
    "    high_pairs_df = high_pairs_df.copy()\n",
    "    high_pairs_df['confidence'] = 'High'\n",
    "    high_pairs_df['model'] = model_name\n",
    "    \n",
    "    low_pairs_df = low_pairs_df.copy() \n",
    "    low_pairs_df['confidence'] = 'Low'\n",
    "    low_pairs_df['model'] = model_name\n",
    "    \n",
    "    # Combine them\n",
    "    combined_df = pd.concat([high_pairs_df, low_pairs_df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Create filtered dataframes for each model\n",
    "df_deepseek_filtered = combine_high_low_pairs(df_deepseek_high_pairs, df_deepseek_low_pairs, 'deepseek')\n",
    "df_llama_filtered = combine_high_low_pairs(df_llama_high_pairs, df_llama_low_pairs, 'llama')\n",
    "df_openai_filtered = combine_high_low_pairs(df_openai_high_pairs, df_openai_low_pairs, 'openai')\n",
    "\n",
    "def keep_one_record_per_pair(df):\n",
    "    \"\"\"Keep one record per (para_id, section_id) pair - prefer High confidence, if all Low then keep first\"\"\"\n",
    "    # Sort by confidence (High comes before Low alphabetically) and keep first record per pair\n",
    "    df_sorted = df.sort_values(['para_id', 'section_id', 'confidence'], ascending=[True, True, False])\n",
    "    return df_sorted.groupby(['para_id', 'section_id']).first().reset_index()\n",
    "\n",
    "# Apply the function to each model's dataframe\n",
    "df_deepseek_final = keep_one_record_per_pair(df_deepseek_filtered)\n",
    "df_llama_final = keep_one_record_per_pair(df_llama_filtered)\n",
    "df_openai_final = keep_one_record_per_pair(df_openai_filtered)\n",
    "\n",
    "print(\"Records per dataframe after keeping one per (para_id, section_id) pair:\")\n",
    "print(f\"DeepSeek: {len(df_deepseek_final)}\")\n",
    "print(f\"Llama: {len(df_llama_final)}\")\n",
    "print(f\"OpenAI: {len(df_openai_final)}\")\n",
    "\n",
    "# Get all unique (para_id, section_id) pairs across all three dataframes\n",
    "all_pairs = set(zip(df_deepseek_final['para_id'], df_deepseek_final['section_id'])) | \\\n",
    "            set(zip(df_llama_final['para_id'], df_llama_final['section_id'])) | \\\n",
    "            set(zip(df_openai_final['para_id'], df_openai_final['section_id']))\n",
    "\n",
    "X = len(all_pairs)\n",
    "print(f\"\\nTotal unique (para_id, section_id) pairs (X): {X}\")\n",
    "\n",
    "# Create a comprehensive dataframe with confidence for each model\n",
    "results = []\n",
    "\n",
    "for para_id, section_id in all_pairs:\n",
    "    # Helper function to get confidence for a specific pair\n",
    "    def get_confidence(df, pid, sid):\n",
    "        mask = (df['para_id'] == pid) & (df['section_id'] == sid)\n",
    "        if mask.any():\n",
    "            confidences = df[mask]['confidence'].values\n",
    "            # If any confidence is High, return High; otherwise return the first one\n",
    "            if 'High' in confidences:\n",
    "                return 'High'\n",
    "            return confidences[0]\n",
    "        return None\n",
    "    \n",
    "    # Get confidence for each model (None if pair not present)\n",
    "    deepseek_conf = get_confidence(df_deepseek_final, para_id, section_id)\n",
    "    llama_conf = get_confidence(df_llama_final, para_id, section_id)\n",
    "    openai_conf = get_confidence(df_openai_final, para_id, section_id)\n",
    "    \n",
    "    # Count High and Low confidences\n",
    "    confidences = [deepseek_conf, llama_conf, openai_conf]\n",
    "    high_count = confidences.count('High')\n",
    "    low_count = confidences.count('Low')\n",
    "    none_count = confidences.count(None)  # Track missing predictions\n",
    "    \n",
    "    results.append({\n",
    "        'para_id': para_id,\n",
    "        'section_id': section_id,\n",
    "        'deepseek_conf': deepseek_conf,\n",
    "        'llama_conf': llama_conf,\n",
    "        'openai_conf': openai_conf,\n",
    "        'high_count': high_count,\n",
    "        'low_count': low_count,\n",
    "        'none_count': none_count\n",
    "    })\n",
    "\n",
    "df_analysis = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "df_analysis['category'] = df_analysis.apply(categorize_confidence, axis=1)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nDistribution of (para_id, section_id) pairs by confidence pattern:\")\n",
    "category_counts = df_analysis['category'].value_counts().sort_index()\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / X) * 100\n",
    "    print(f\"{category}: {count} pairs ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nVerification: {category_counts.sum()} = {X} ✓\" if category_counts.sum() == X else f\"\\nError: {category_counts.sum()} ≠ {X}\")\n",
    "\n",
    "# Show sample of the analysis dataframe\n",
    "print(\"\\nSample of analysis results:\")\n",
    "print(df_analysis.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c3f24e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9735"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5346 + 4389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7411e746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>deepseek_conf</th>\n",
       "      <th>llama_conf</th>\n",
       "      <th>openai_conf</th>\n",
       "      <th>high_count</th>\n",
       "      <th>low_count</th>\n",
       "      <th>none_count</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewca_crim_2003_190#para_19</td>\n",
       "      <td>id/ukpga/1999/23_section-41</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a_all_high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ukait_2008_1#para_5</td>\n",
       "      <td>id/ukpga/2002/41_section-101</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>b_2high_1low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewhc_ch_2012_28#para_70</td>\n",
       "      <td>id/ukpga/1998/42_section-21</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>d_all_low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewca_civ_2019_53#para_29</td>\n",
       "      <td>http://www.legislation.gov.uk/id/ukpga/2002/41...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>d_all_low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ewhc_comm_2017_1430#para_13</td>\n",
       "      <td>id/ukpga/1996/23_section-56</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>c_1high_2low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>ewhc_comm_2023_1889#para_32</td>\n",
       "      <td>id/ukpga/2003/44_section-258</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a_all_high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>ewhc_qb_2022_1917#para_21</td>\n",
       "      <td>id/ukpga/1981/49_schedule-2-part-II</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>d_all_low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18001</th>\n",
       "      <td>uksc_2013_37#para_13</td>\n",
       "      <td>id/ukpga/1988/36_section-27</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>b_2high_1low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18002</th>\n",
       "      <td>ewhc_ch_2010_180#para_9</td>\n",
       "      <td>id/ukpga/1981/54_section-129</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>b_2high_1low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18003</th>\n",
       "      <td>ewhc_admin_2012_1033#para_18</td>\n",
       "      <td>id/ukpga/Geo5/15-16/20_section-8</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>b_2high_1low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18004 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            para_id  \\\n",
       "0        ewca_crim_2003_190#para_19   \n",
       "1               ukait_2008_1#para_5   \n",
       "2           ewhc_ch_2012_28#para_70   \n",
       "3          ewca_civ_2019_53#para_29   \n",
       "4       ewhc_comm_2017_1430#para_13   \n",
       "...                             ...   \n",
       "17999   ewhc_comm_2023_1889#para_32   \n",
       "18000     ewhc_qb_2022_1917#para_21   \n",
       "18001          uksc_2013_37#para_13   \n",
       "18002       ewhc_ch_2010_180#para_9   \n",
       "18003  ewhc_admin_2012_1033#para_18   \n",
       "\n",
       "                                              section_id deepseek_conf  \\\n",
       "0                            id/ukpga/1999/23_section-41          High   \n",
       "1                           id/ukpga/2002/41_section-101          High   \n",
       "2                            id/ukpga/1998/42_section-21           Low   \n",
       "3      http://www.legislation.gov.uk/id/ukpga/2002/41...           Low   \n",
       "4                            id/ukpga/1996/23_section-56          High   \n",
       "...                                                  ...           ...   \n",
       "17999                       id/ukpga/2003/44_section-258          High   \n",
       "18000                id/ukpga/1981/49_schedule-2-part-II           Low   \n",
       "18001                        id/ukpga/1988/36_section-27          High   \n",
       "18002                       id/ukpga/1981/54_section-129          High   \n",
       "18003                   id/ukpga/Geo5/15-16/20_section-8          High   \n",
       "\n",
       "      llama_conf openai_conf  high_count  low_count  none_count      category  \n",
       "0           High        High           3          0           0    a_all_high  \n",
       "1            Low        High           2          1           0  b_2high_1low  \n",
       "2            Low         Low           0          3           0     d_all_low  \n",
       "3            Low         Low           0          3           0     d_all_low  \n",
       "4            Low         Low           1          2           0  c_1high_2low  \n",
       "...          ...         ...         ...        ...         ...           ...  \n",
       "17999       High        High           3          0           0    a_all_high  \n",
       "18000        Low         Low           0          3           0     d_all_low  \n",
       "18001        Low        High           2          1           0  b_2high_1low  \n",
       "18002        Low        High           2          1           0  b_2high_1low  \n",
       "18003        Low        High           2          1           0  b_2high_1low  \n",
       "\n",
       "[18004 rows x 9 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accepted = []\n",
    "df_decision = []\n",
    "df_regenation =[]\n",
    "for para_id,section_id.unique in df_analysis:\n",
    "    if df_analysis['category'] =='a_all_high':\n",
    "         #pick up the rown from df_deepseek given para_id,section_id and confidence == 'High' and put it in df_decision\n",
    "         #pick up the rown from df_openai_new given para_id,section_id and confidence == 'High' and put it in df_decision\n",
    "         #pick up the rown from df_llama given para_id,section_id and confidence == 'High' and put it in df_decision\n",
    "    elif df_analysis['category'] =='b_2high_1low':\n",
    "        if df_analysis['deepseek_conf'] == 'High':\n",
    "            #pick up the rown from df_deepseek given para_id,section_id and confidence == 'High' and put it in df_decision\n",
    "        if df_analysis['openai_conf'] == 'High':\n",
    "            #pick up the rown from df_openai_new given para_id,section_id and confidence == 'High' and put it in df_decision\n",
    "        if df_analysis['llama_conf'] == 'High':\n",
    "            #pick up the rown from df_llama given para_id,section_id and confidence == 'High' and put it in df_decision\n",
    "    elif df_analysis['category'] =='c_1high_2low':\n",
    "        if df_analysis['deepseek_conf'] == 'High':\n",
    "            #pick up the rown from df_deepseek given para_id,section_id and confidence == 'High' and put it in df_accepted\n",
    "        if df_analysis['openai_conf'] == 'High':\n",
    "            #pick up the rown from df_openai_new given para_id,section_id and confidence == 'High' and put it in df_accepted\n",
    "        if df_analysis['llama_conf'] == 'High':\n",
    "            #pick up the rown from df_llama given para_id,section_id and confidence == 'High' and put it in df_accepted\n",
    "    elif df_analysis['category'] =='d_all_low':\n",
    "        if df_analysis['deepseek_conf'] == 'Low':\n",
    "            #pick up the rown from df_deepseek given para_id,section_id and confidence == 'Low' and put it in df_regenation\n",
    "        if df_analysis['openai_conf'] == 'Low':\n",
    "            #pick up the rown from df_openai_new given para_id,section_id and confidence == 'Low' and put it in df_regenation\n",
    "        if df_analysis['llama_conf'] == 'Low':\n",
    "            #pick up the rown from df_llama given para_id,section_id and confidence == 'Low' and put it in df_regenation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9312193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorization Results:\n",
      "df_accepted: 4389 records\n",
      "df_decision: 25500 records\n",
      "df_regeneration: 9999 records\n",
      "Total records: 39888\n",
      "\n",
      "Sample of df_accepted:\n",
      "Columns available: ['para_id', 'section_id', 'confidence', 'reasoning', 'model', 'para_text', 'section_text', 'category', 'case_law_excerpt', 'legislation_excerpt']\n",
      "                        para_id                            section_id  \\\n",
      "0   ewhc_comm_2017_1430#para_13           id/ukpga/1996/23_section-56   \n",
      "1     ewca_crim_2023_630#para_5  id/ukpga/1988/33_schedule-10-part-IV   \n",
      "2    ewhc_admin_2019_84#para_24           id/ukpga/2014/12_section-13   \n",
      "3  ewhc_admin_2006_3048#para_10          id/ukpga/1999/33_section-116   \n",
      "4  ewhc_admin_2015_3084#para_34            id/ukpga/2004/5_section-49   \n",
      "\n",
      "  confidence                                          reasoning     model  \\\n",
      "0       High  The case discusses the delay in meeting the aw...  deepseek   \n",
      "1       High  The case law discusses the appellant's underst...    openai   \n",
      "2       High  The case law discusses the implicit requiremen...    openai   \n",
      "3       High  The paragraph illustrates the responsibilities...    openai   \n",
      "4       High  The case law discusses the limits on building ...    openai   \n",
      "\n",
      "                                           para_text  \\\n",
      "0  13. In response, Romania denies delaying tacti...   \n",
      "1  5. The appellant places considerable reliance ...   \n",
      "2  24. On behalf of the Appellant, it was submitt...   \n",
      "3  10. NASS is not responsible for granting or re...   \n",
      "4  34. The Officers’ Report’s analysis of sub-par...   \n",
      "\n",
      "                                        section_text      category  \\\n",
      "0  56 Power to withhold award in case of non-paym...  c_1high_2low   \n",
      "1  Part IV Section Inserted After Section 16 16A ...  c_1high_2low   \n",
      "2  13 Power to exclude person from home in cases ...  c_1high_2low   \n",
      "3  116 Amendment of section 21 of the National As...  c_1high_2low   \n",
      "4  49 Development to include certain internal ope...  c_1high_2low   \n",
      "\n",
      "                                    case_law_excerpt  \\\n",
      "0  In response, Romania denies delaying tactics, ...   \n",
      "1  the appellant was said to be deliberately evas...   \n",
      "2  it is implicit in the 2014 Act that only reaso...   \n",
      "3  NASS is not responsible for granting or refusi...   \n",
      "4  It does not provide general support for tall b...   \n",
      "\n",
      "                                 legislation_excerpt  \n",
      "0  The tribunal may refuse to deliver an award to...  \n",
      "1  considers it appropriate to make an attendance...  \n",
      "2  the court thinks that— (i) the anti-social beh...  \n",
      "3  A person to whom section 115 of the Immigratio...  \n",
      "4  The Secretary of State may in a development or...  \n",
      "\n",
      "Sample of df_decision:\n",
      "Columns available: ['para_id', 'section_id', 'confidence', 'reasoning', 'model', 'para_text', 'section_text', 'category', 'case_law_excerpt', 'legislation_excerpt']\n",
      "                      para_id                    section_id confidence  \\\n",
      "0  ewca_crim_2003_190#para_19   id/ukpga/1999/23_section-41       High   \n",
      "1  ewca_crim_2003_190#para_19   id/ukpga/1999/23_section-41       High   \n",
      "2  ewca_crim_2003_190#para_19   id/ukpga/1999/23_section-41       High   \n",
      "3         ukait_2008_1#para_5  id/ukpga/2002/41_section-101       High   \n",
      "4         ukait_2008_1#para_5  id/ukpga/2002/41_section-101       High   \n",
      "\n",
      "                                           reasoning     model  \\\n",
      "0  The case discusses the admissibility of eviden...  deepseek   \n",
      "1  The case law discusses how the distinction bet...    openai   \n",
      "2  The court references the reduction of distinct...     llama   \n",
      "3  The case law discusses the Senior Immigration ...  deepseek   \n",
      "4  The case law refers to the process of reconsid...    openai   \n",
      "\n",
      "                                           para_text  \\\n",
      "0  19. Giving the judgment of the Court, Henry J ...   \n",
      "1  19. Giving the judgment of the Court, Henry J ...   \n",
      "2  19. Giving the judgment of the Court, Henry J ...   \n",
      "3  5. In pursuance of rule 23(5)(b), at the end o...   \n",
      "4  5. In pursuance of rule 23(5)(b), at the end o...   \n",
      "\n",
      "                                        section_text      category  \\\n",
      "0  41 Restriction on evidence or questions about ...    a_all_high   \n",
      "1  41 Restriction on evidence or questions about ...    a_all_high   \n",
      "2  41 Restriction on evidence or questions about ...    a_all_high   \n",
      "3  101 Appeal to Tribunal (1) A party to an appea...  b_2high_1low   \n",
      "4  101 Appeal to Tribunal (1) A party to an appea...  b_2high_1low   \n",
      "\n",
      "                                    case_law_excerpt  \\\n",
      "0  Giving the judgment of the Court, Henry J refe...   \n",
      "1  the difference between questions going to cred...   \n",
      "2  the difference between questions going to cred...   \n",
      "3  The Senior Immigration Judge decided to order ...   \n",
      "4  the determination of the Immigration Judge “wa...   \n",
      "\n",
      "                                 legislation_excerpt  \n",
      "0  If at a trial a person is charged with a sexua...  \n",
      "1  no evidence may be adduced, and (b) no questio...  \n",
      "2  For the purposes of subsection (3) no evidence...  \n",
      "3  A party to an appeal to an adjudicator under s...  \n",
      "4  A party to an appeal to an adjudicator under s...  \n",
      "\n",
      "Sample of df_regeneration:\n",
      "Columns available: ['para_id', 'section_id', 'confidence', 'reasoning', 'model', 'para_text', 'section_text', 'category', 'case_law_excerpt', 'legislation_excerpt']\n",
      "                    para_id  \\\n",
      "0   ewhc_ch_2012_28#para_70   \n",
      "1   ewhc_ch_2012_28#para_70   \n",
      "2   ewhc_ch_2012_28#para_70   \n",
      "3  ewca_civ_2019_53#para_29   \n",
      "4  ewca_civ_2019_53#para_29   \n",
      "\n",
      "                                          section_id confidence  \\\n",
      "0                        id/ukpga/1998/42_section-21        Low   \n",
      "1                        id/ukpga/1998/42_section-21        Low   \n",
      "2                        id/ukpga/1998/42_section-21        Low   \n",
      "3  http://www.legislation.gov.uk/id/ukpga/2002/41...        Low   \n",
      "4  http://www.legislation.gov.uk/id/ukpga/2002/41...        Low   \n",
      "\n",
      "                                           reasoning     model  \\\n",
      "0  The case law paragraph discusses the interpret...  deepseek   \n",
      "1  The paragraph evaluates the fulfillment of the...    openai   \n",
      "2  The case law discusses the interpretation of t...     llama   \n",
      "3  There is no direct textual overlap or clear in...  deepseek   \n",
      "4  The case law discusses the impact of provision...    openai   \n",
      "\n",
      "                                           para_text  \\\n",
      "0  70. Accordingly, I conclude that although the ...   \n",
      "1  70. Accordingly, I conclude that although the ...   \n",
      "2  70. Accordingly, I conclude that although the ...   \n",
      "3  29. The second issue related to the effect of ...   \n",
      "4  29. The second issue related to the effect of ...   \n",
      "\n",
      "                                        section_text   category  \\\n",
      "0  21 Interpretation, etc. (1) In this Act— “ ame...  d_all_low   \n",
      "1  21 Interpretation, etc. (1) In this Act— “ ame...  d_all_low   \n",
      "2  21 Interpretation, etc. (1) In this Act— “ ame...  d_all_low   \n",
      "3  117 Northern Ireland appeals: legal aid (1) In...  d_all_low   \n",
      "4  117 Northern Ireland appeals: legal aid (1) In...  d_all_low   \n",
      "\n",
      "                                    case_law_excerpt  \\\n",
      "0  I conclude that although the definition of net...   \n",
      "1  the requirement to operate a network is not sa...   \n",
      "2  Accordingly, I conclude that although the defi...   \n",
      "3  The criticism was made that the expression had...   \n",
      "4  the effect of section 117 A(2)(a) is clear. It...   \n",
      "\n",
      "                                 legislation_excerpt  \n",
      "0  In this Act— \" amend \" includes repeal and app...  \n",
      "1  the definition of network in the UCR is to be ...  \n",
      "2  In this Act— “ amend ” includes repeal and app...  \n",
      "3  In Part 1 of Schedule 1 to the Legal Aid, Advi...  \n",
      "4  Proceedings before an adjudicator appointed fo...  \n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the categorized records\n",
    "df_accepted = []\n",
    "df_decision = []\n",
    "df_regeneration = []\n",
    "\n",
    "# Helper function to find and extract row from original dataframes\n",
    "def get_row_from_original_df(df, para_id, section_id, confidence,model,category):\n",
    "    \"\"\"Extract row from original dataframe based on para_id, section_id, and confidence\"\"\"\n",
    "    mask = (df['para_id'] == para_id) & (df['section_id'] == section_id) & (df['confidence'] == confidence)\n",
    "    if mask.any():\n",
    "        df_row = df[mask].iloc[0]\n",
    "        df_row['category'] = category\n",
    "        df_row['model'] = model\n",
    "        df_row = df_row[['para_id', 'section_id', 'confidence', 'reasoning','model','para_text','section_text','category','case_law_excerpt','legislation_excerpt']]\n",
    "        return df_row.to_dict()  # Return first matching row as dictionary\n",
    "    return None\n",
    "\n",
    "# Iterate through each row in df_analysis\n",
    "for index, row in df_analysis.iterrows():\n",
    "    para_id = row['para_id']\n",
    "    section_id = row['section_id']\n",
    "    category = row['category']\n",
    "    \n",
    "    if category == 'a_all_high':\n",
    "        # All models have high confidence - add all to df_decision\n",
    "        deepseek_row = get_row_from_original_df(df_deepseek, para_id, section_id, 'High','deepseek',category)\n",
    "        if deepseek_row:\n",
    "            df_decision.append(deepseek_row)\n",
    "            \n",
    "        openai_row = get_row_from_original_df(df_openai_new, para_id, section_id, 'High','openai',category)\n",
    "        if openai_row:\n",
    "            df_decision.append(openai_row)\n",
    "            \n",
    "        llama_row = get_row_from_original_df(df_llama, para_id, section_id, 'High','llama',category)\n",
    "        if llama_row:\n",
    "            df_decision.append(llama_row)\n",
    "    \n",
    "    elif category == 'b_2high_1low':\n",
    "        # 2 models have high confidence - add high confidence ones to df_decision\n",
    "        if row['deepseek_conf'] == 'High':\n",
    "            deepseek_row = get_row_from_original_df(df_deepseek, para_id, section_id, 'High','deepseek',category)\n",
    "            if deepseek_row:\n",
    "                df_decision.append(deepseek_row)\n",
    "                \n",
    "        if row['openai_conf'] == 'High':\n",
    "            openai_row = get_row_from_original_df(df_openai_new, para_id, section_id, 'High','openai',category)\n",
    "            if openai_row:\n",
    "                df_decision.append(openai_row)\n",
    "                \n",
    "        if row['llama_conf'] == 'High':\n",
    "            llama_row = get_row_from_original_df(df_llama, para_id, section_id, 'High','llama',category)\n",
    "            if llama_row:\n",
    "                df_decision.append(llama_row)\n",
    "    \n",
    "    elif category == 'c_1high_2low':\n",
    "        # 1 model has high confidence - add high confidence one to df_accepted\n",
    "        if row['deepseek_conf'] == 'High':\n",
    "            deepseek_row = get_row_from_original_df(df_deepseek, para_id, section_id, 'High','deepseek',category)\n",
    "            if deepseek_row:\n",
    "                df_accepted.append(deepseek_row)\n",
    "                \n",
    "        if row['openai_conf'] == 'High':\n",
    "            openai_row = get_row_from_original_df(df_openai_new, para_id, section_id, 'High','openai',category)\n",
    "            if openai_row:\n",
    "                df_accepted.append(openai_row)\n",
    "                \n",
    "        if row['llama_conf'] == 'High':\n",
    "            llama_row = get_row_from_original_df(df_llama, para_id, section_id, 'High','llama',category)\n",
    "            if llama_row:\n",
    "                df_accepted.append(llama_row)\n",
    "    \n",
    "    elif category == 'd_all_low':\n",
    "        # All models have low confidence - add all to df_regeneration\n",
    "        if row['deepseek_conf'] == 'Low':\n",
    "            deepseek_row = get_row_from_original_df(df_deepseek, para_id, section_id, 'Low','deepseek',category)\n",
    "            if deepseek_row:\n",
    "                df_regeneration.append(deepseek_row)\n",
    "                \n",
    "        if row['openai_conf'] == 'Low':\n",
    "            openai_row = get_row_from_original_df(df_openai_new, para_id, section_id, 'Low' ,'openai',category)\n",
    "            if openai_row:\n",
    "                df_regeneration.append(openai_row)\n",
    "                \n",
    "        if row['llama_conf'] == 'Low':\n",
    "            llama_row = get_row_from_original_df(df_llama, para_id, section_id, 'Low','llama',category)\n",
    "            if llama_row:\n",
    "                df_regeneration.append(llama_row)\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "df_accepted = pd.DataFrame(df_accepted)\n",
    "df_decision = pd.DataFrame(df_decision)\n",
    "df_regeneration = pd.DataFrame(df_regeneration)\n",
    "\n",
    "# Display results\n",
    "print(\"Categorization Results:\")\n",
    "print(f\"df_accepted: {len(df_accepted)} records\")\n",
    "print(f\"df_decision: {len(df_decision)} records\") \n",
    "print(f\"df_regeneration: {len(df_regeneration)} records\")\n",
    "print(f\"Total records: {len(df_accepted) + len(df_decision) + len(df_regeneration)}\")\n",
    "\n",
    "# Show sample of each category\n",
    "print(\"\\nSample of df_accepted:\")\n",
    "if len(df_accepted) > 0:\n",
    "    print(f\"Columns available: {df_accepted.columns.tolist()}\")\n",
    "    print(df_accepted.head())\n",
    "else:\n",
    "    print(\"No records in df_accepted\")\n",
    "\n",
    "print(\"\\nSample of df_decision:\")\n",
    "if len(df_decision) > 0:\n",
    "    print(f\"Columns available: {df_decision.columns.tolist()}\")\n",
    "    print(df_decision.head())\n",
    "else:\n",
    "    print(\"No records in df_decision\")\n",
    "\n",
    "print(\"\\nSample of df_regeneration:\")\n",
    "if len(df_regeneration) > 0:\n",
    "    print(f\"Columns available: {df_regeneration.columns.tolist()}\")\n",
    "    print(df_regeneration.head())\n",
    "else:\n",
    "    print(\"No records in df_regeneration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "38a53c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the number of unique (para_id, section_id) pairs in df_decision_pairwise\n",
    "num_unique_pairs = df_decision[['para_id', 'section_id','category']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "530e1f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "b_2high_1low    5346\n",
       "a_all_high      4936\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unique_pairs.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d5b00bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10282"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5346 + 4936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f782bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I have to make a dataframe where I have to get c_1high_2low from the model where it was High\n",
    "df_accepted.to_csv('../data/extraction_results/df_accepted.csv', index=False)\n",
    "df_decision.to_csv('../data/extraction_results/df_decision.csv', index=False)\n",
    "df_regeneration.to_csv('../data/extraction_results/df_regeneration.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7aef24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_ids with all low confidence: 538\n",
      "Number of records in df_source_all_low: 1076\n",
      "Unique para_ids in df_source_all_low: 538\n",
      "Verification: Expected 538 para_ids, got 538\n",
      "\n",
      "DataFrame shape: (1076, 19)\n",
      "Columns: ['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied', 'application_of_law_phrases', 'reason', 'if_law_applied_llama', 'application_of_law_phrases_llama', 'reason_llama', 'if_law_applied_claude', 'application_of_law_phrases_claude', 'reason_claude', 'confidence', 'agreement_with', 'final_annotation', 'case_name', 'section_id', 'section_text']\n",
      "\n",
      "First 5 rows:\n",
      "                                              case_uri               para_id  \\\n",
      "124  https://caselaw.nationalarchives.gov.uk/eat/20...  eat_2024_17#para_100   \n",
      "125  https://caselaw.nationalarchives.gov.uk/eat/20...  eat_2024_17#para_100   \n",
      "128  https://caselaw.nationalarchives.gov.uk/eat/20...  eat_2024_17#para_112   \n",
      "129  https://caselaw.nationalarchives.gov.uk/eat/20...  eat_2024_17#para_112   \n",
      "130  https://caselaw.nationalarchives.gov.uk/eat/20...  eat_2024_17#para_118   \n",
      "\n",
      "                                            paragraphs references  \\\n",
      "124  100. I must say immediately that in the presen...         []   \n",
      "125  100. I must say immediately that in the presen...         []   \n",
      "128  112. I add this: I would not want the conclusi...         []   \n",
      "129  112. I add this: I would not want the conclusi...         []   \n",
      "130  118. At [101], which is the target of this gro...         []   \n",
      "\n",
      "    if_law_applied                         application_of_law_phrases  \\\n",
      "124           True  ['the claimant does not allege, and I do not f...   \n",
      "125           True  ['the claimant does not allege, and I do not f...   \n",
      "128           True  ['my conclusion that the interventions crossed...   \n",
      "129           True  ['my conclusion that the interventions crossed...   \n",
      "130          False                                                 []   \n",
      "\n",
      "                                                reason if_law_applied_llama  \\\n",
      "124  The judge applies legal standards of fairness ...                 True   \n",
      "125  The judge applies legal standards of fairness ...                 True   \n",
      "128  The judge applies legal principles regarding t...                 True   \n",
      "129  The judge applies legal principles regarding t...                 True   \n",
      "130  The paragraph discusses the Tribunal's conside...                 True   \n",
      "\n",
      "                      application_of_law_phrases_llama  \\\n",
      "124                 ['that rendered the trial unfair']   \n",
      "125                 ['that rendered the trial unfair']   \n",
      "128  ['provided it is compatible with proper consid...   \n",
      "129  ['provided it is compatible with proper consid...   \n",
      "130  ['We have considered the consultation document...   \n",
      "\n",
      "                                          reason_llama if_law_applied_claude  \\\n",
      "124  The judge applies the legal principle of fairn...                   NaN   \n",
      "125  The judge applies the legal principle of fairn...                   NaN   \n",
      "128  The judge applies the legal principle of a fai...                   NaN   \n",
      "129  The judge applies the legal principle of a fai...                   NaN   \n",
      "130  The Tribunal applies the principles outlined i...                  True   \n",
      "\n",
      "                     application_of_law_phrases_claude  \\\n",
      "124                                                NaN   \n",
      "125                                                NaN   \n",
      "128                                                NaN   \n",
      "129                                                NaN   \n",
      "130  ['We have considered the consultation document...   \n",
      "\n",
      "                                         reason_claude confidence  \\\n",
      "124                                                NaN        NaN   \n",
      "125                                                NaN        NaN   \n",
      "128                                                NaN        NaN   \n",
      "129                                                NaN        NaN   \n",
      "130  Model B (Llama) is correct. This paragraph cle...       High   \n",
      "\n",
      "    agreement_with  final_annotation    case_name  \\\n",
      "124            NaN              True  eat_2024_17   \n",
      "125            NaN              True  eat_2024_17   \n",
      "128            NaN              True  eat_2024_17   \n",
      "129            NaN              True  eat_2024_17   \n",
      "130          Llama              True  eat_2024_17   \n",
      "\n",
      "                        section_id  \\\n",
      "124   id/ukpga/2010/15_section-122   \n",
      "125   id/ukpga/1996/18_section-43M   \n",
      "128   id/ukpga/2010/15_section-123   \n",
      "129  id/ukpga/2010/15_section-140B   \n",
      "130   id/ukpga/1996/18_section-129   \n",
      "\n",
      "                                          section_text  \n",
      "124  122 References by court to tribunal, etc. (1) ...  \n",
      "125  43M Jury service (1) An employee has the right...  \n",
      "128  123 Time limits (1) Subject to section 140B pr...  \n",
      "129  140B Extension of time limits to facilitate co...  \n",
      "130  129 Procedure on hearing of application and ma...  \n"
     ]
    }
   ],
   "source": [
    "# Get the para_ids that are in the 'd_all_low' category\n",
    "d_all_low_para_ids = df_analysis[df_analysis['category'] == 'd_all_low']['para_id'].tolist()\n",
    "\n",
    "print(f\"Number of para_ids with all low confidence: {len(d_all_low_para_ids)}\")\n",
    "\n",
    "# Filter df_source to keep only rows with para_ids in d_all_low\n",
    "df_source_all_low = df_source[df_source['para_id'].isin(d_all_low_para_ids)].copy()\n",
    "\n",
    "print(f\"Number of records in df_source_all_low: {len(df_source_all_low)}\")\n",
    "print(f\"Unique para_ids in df_source_all_low: {df_source_all_low['para_id'].nunique()}\")\n",
    "\n",
    "# Verify that we got all the d_all_low para_ids\n",
    "unique_para_ids_in_result = df_source_all_low['para_id'].nunique()\n",
    "print(f\"Verification: Expected {len(d_all_low_para_ids)} para_ids, got {unique_para_ids_in_result}\")\n",
    "\n",
    "# Show some basic info about the filtered dataframe\n",
    "print(f\"\\nDataFrame shape: {df_source_all_low.shape}\")\n",
    "print(f\"Columns: {list(df_source_all_low.columns)}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_source_all_low.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "606dcf14",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['case_law_excerpt', 'legislation_excerpt', 'reasoning'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_wide\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Create the wide format dataframe\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m df_final_wide = \u001b[43mcreate_wide_analysis_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of wide analysis dataframe: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_final_wide.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnique para_ids: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_final_wide[\u001b[33m'\u001b[39m\u001b[33mpara_id\u001b[39m\u001b[33m'\u001b[39m].nunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mcreate_wide_analysis_df\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     18\u001b[39m df_wide = all_combos.merge(df_analysis[[\u001b[33m'\u001b[39m\u001b[33mpara_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m]], on=\u001b[33m'\u001b[39m\u001b[33mpara_id\u001b[39m\u001b[33m'\u001b[39m, how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Add columns from deepseek\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m deepseek_cols = \u001b[43mdf_deepseek_final\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpara_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msection_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcase_law_excerpt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlegislation_excerpt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconfidence\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n\u001b[32m     22\u001b[39m deepseek_cols = deepseek_cols.rename(columns={\n\u001b[32m     23\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcase_law_excerpt\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcase_law_excerpt_deepseek\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     24\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlegislation_excerpt\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mlegislation_excerpt_deepseek\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mconfidence_deepseek\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     26\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mreasoning_deepseek\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     27\u001b[39m })\n\u001b[32m     28\u001b[39m df_wide = df_wide.merge(deepseek_cols, on=[\u001b[33m'\u001b[39m\u001b[33mpara_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msection_id\u001b[39m\u001b[33m'\u001b[39m], how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Swansea/Projects/BridgingCaseLawAndLegislation/BridgingCaseLawAndLegislation/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Swansea/Projects/BridgingCaseLawAndLegislation/BridgingCaseLawAndLegislation/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Swansea/Projects/BridgingCaseLawAndLegislation/BridgingCaseLawAndLegislation/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['case_law_excerpt', 'legislation_excerpt', 'reasoning'] not in index\""
     ]
    }
   ],
   "source": [
    "# Create a wide format dataframe with one row per (para_id, section_id) and columns for each model\n",
    "def create_wide_analysis_df():\n",
    "    # Start with the analysis dataframe to get all para_ids and their categories\n",
    "    df_wide = df_analysis[['para_id', 'category']].copy()\n",
    "    \n",
    "    # We need to get section_ids, so let's merge with one of the model dataframes first\n",
    "    # Get all unique (para_id, section_id) combinations from all models\n",
    "    all_combinations = []\n",
    "    \n",
    "    for df_model in [df_deepseek_final, df_llama_final, df_openai_final]:\n",
    "        combinations = df_model[['para_id', 'section_id']].drop_duplicates()\n",
    "        all_combinations.append(combinations)\n",
    "    \n",
    "    # Combine all combinations and remove duplicates\n",
    "    all_combos = pd.concat(all_combinations).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Merge with category information\n",
    "    df_wide = all_combos.merge(df_analysis[['para_id', 'category']], on='para_id', how='left')\n",
    "    \n",
    "    # Add columns from deepseek\n",
    "    deepseek_cols = df_deepseek_final[['para_id', 'section_id', 'case_law_excerpt', 'legislation_excerpt', 'confidence', 'reasoning']].copy()\n",
    "    deepseek_cols = deepseek_cols.rename(columns={\n",
    "        'case_law_excerpt': 'case_law_excerpt_deepseek',\n",
    "        'legislation_excerpt': 'legislation_excerpt_deepseek',\n",
    "        'confidence': 'confidence_deepseek',\n",
    "        'reasoning': 'reasoning_deepseek'\n",
    "    })\n",
    "    df_wide = df_wide.merge(deepseek_cols, on=['para_id', 'section_id'], how='left')\n",
    "    \n",
    "    # Add columns from llama\n",
    "    llama_cols = df_llama_final[['para_id', 'section_id', 'case_law_excerpt', 'legislation_excerpt', 'confidence', 'reasoning']].copy()\n",
    "    llama_cols = llama_cols.rename(columns={\n",
    "        'case_law_excerpt': 'case_law_excerpt_llama',\n",
    "        'legislation_excerpt': 'legislation_excerpt_llama',\n",
    "        'confidence': 'confidence_llama',\n",
    "        'reasoning': 'reasoning_llama'\n",
    "    })\n",
    "    df_wide = df_wide.merge(llama_cols, on=['para_id', 'section_id'], how='left')\n",
    "    \n",
    "    # Add columns from openai\n",
    "    openai_cols = df_openai_final[['para_id', 'section_id', 'case_law_excerpt', 'legislation_excerpt', 'confidence', 'reasoning']].copy()\n",
    "    openai_cols = openai_cols.rename(columns={\n",
    "        'case_law_excerpt': 'case_law_excerpt_openai',\n",
    "        'legislation_excerpt': 'legislation_excerpt_openai',\n",
    "        'confidence': 'confidence_openai',\n",
    "        'reasoning': 'reasoning_openai'\n",
    "    })\n",
    "    df_wide = df_wide.merge(openai_cols, on=['para_id', 'section_id'], how='left')\n",
    "    \n",
    "    # Add additional columns from df_source instead of model dataframes\n",
    "    base_cols = df_source[['para_id', 'section_id', 'paragraphs', 'section_text']].drop_duplicates()\n",
    "    df_wide = df_wide.merge(base_cols, on=['para_id', 'section_id'], how='left')\n",
    "    \n",
    "    return df_wide\n",
    "\n",
    "# Create the wide format dataframe\n",
    "df_final_wide = create_wide_analysis_df()\n",
    "\n",
    "print(f\"Shape of wide analysis dataframe: {df_final_wide.shape}\")\n",
    "print(f\"Unique para_ids: {df_final_wide['para_id'].nunique()}\")\n",
    "print(f\"Unique (para_id, section_id) combinations: {len(df_final_wide)}\")\n",
    "\n",
    "print(f\"\\nColumns in final wide dataframe:\")\n",
    "for col in df_final_wide.columns:\n",
    "    print(f\"  {col}\")\n",
    "\n",
    "print(f\"\\nDistribution by category:\")\n",
    "print(df_final_wide['category'].value_counts())\n",
    "\n",
    "print(f\"\\nFirst 3 rows (showing key columns):\")\n",
    "key_cols = ['para_id', 'section_id', 'category', 'confidence_deepseek', 'confidence_llama', 'confidence_openai']\n",
    "print(df_final_wide[key_cols].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03b00027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['para_id', 'section_id', 'category', 'case_law_excerpt_deepseek',\n",
       "       'legislation_excerpt_deepseek', 'confidence_deepseek',\n",
       "       'reasoning_deepseek', 'case_law_excerpt_llama',\n",
       "       'legislation_excerpt_llama', 'confidence_llama', 'reasoning_llama',\n",
       "       'case_law_excerpt_openai', 'legislation_excerpt_openai',\n",
       "       'confidence_openai', 'reasoning_openai', 'paragraphs', 'section_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_wide.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e47c7d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a_all_high', 'b_2high_1low', 'c_1high_2low', 'd_all_low'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_wide.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90d6fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4631\n",
      "2604\n",
      "1229\n",
      "538\n"
     ]
    }
   ],
   "source": [
    "print(df_final_wide[df_final_wide['category'] == 'a_all_high']['para_id'].nunique())\n",
    "print(df_final_wide[df_final_wide['category'] == 'b_2high_1low']['para_id'].nunique())\n",
    "\n",
    "print(df_final_wide[df_final_wide['category'] == 'c_1high_2low']['para_id'].nunique())\n",
    "print(df_final_wide[df_final_wide['category'] == 'd_all_low']['para_id'].nunique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8ea28ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_wide.to_csv('../data/final_test/final/reexperiment/fewhot/11August/df_final_wide_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_all_low.to_csv('../data/final_test/final/reexperiment/fewhot/11August/df_source_all_low_for_claude.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cc867995",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_regenrated = pd.read_csv('../data/final_test/final/reexperiment/fewhot/11August/df_source_all_low_for_claude_output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6f67abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_regenrated_high = claude_regenrated[claude_regenrated['confidence'] == 'High']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cb707a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique (para_id, section_id) pairs with high confidence: 32\n"
     ]
    }
   ],
   "source": [
    "# Get unique (para_id, section_id) pairs where confidence is high\n",
    "unique_pairs = claude_regenrated_high[['para_id', 'section_id']].drop_duplicates()\n",
    "print(f\"Number of unique (para_id, section_id) pairs with high confidence: {len(unique_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "661779c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = unique_pairs[unique_pairs['para_id'] == 'ewhc_admin_2016_2186#para_33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ee5bda5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.legislation.gov.uk/id/ukpga/1978/30/section/10_'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['section_id'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "65d5abd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>para_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>phrase_index</th>\n",
       "      <th>case_law_excerpt</th>\n",
       "      <th>legislation_excerpt</th>\n",
       "      <th>confidence</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>para_text</th>\n",
       "      <th>section_text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>request_430</td>\n",
       "      <td>ewhc_admin_2016_2186#para_33</td>\n",
       "      <td>http://www.legislation.gov.uk/id/ukpga/1978/30...</td>\n",
       "      <td>0</td>\n",
       "      <td>This is because the language of this part of t...</td>\n",
       "      <td>unless the contrary intention appears</td>\n",
       "      <td>High</td>\n",
       "      <td>The case law applies the interpretative princi...</td>\n",
       "      <td>33. As to the definition in section 37 of the ...</td>\n",
       "      <td>10 References to the Sovereign. In any Act a r...</td>\n",
       "      <td>430</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>request_430</td>\n",
       "      <td>ewhc_admin_2016_2186#para_33</td>\n",
       "      <td>http://www.legislation.gov.uk/id/ukpga/1978/30...</td>\n",
       "      <td>0</td>\n",
       "      <td>This is because the language of this part of t...</td>\n",
       "      <td>unless the contrary intention appears</td>\n",
       "      <td>High</td>\n",
       "      <td>The case law applies the interpretative princi...</td>\n",
       "      <td>33. As to the definition in section 37 of the ...</td>\n",
       "      <td>10 References to the Sovereign. In any Act a r...</td>\n",
       "      <td>430</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       custom_id                       para_id  \\\n",
       "859  request_430  ewhc_admin_2016_2186#para_33   \n",
       "860  request_430  ewhc_admin_2016_2186#para_33   \n",
       "\n",
       "                                            section_id  phrase_index  \\\n",
       "859  http://www.legislation.gov.uk/id/ukpga/1978/30...             0   \n",
       "860  http://www.legislation.gov.uk/id/ukpga/1978/30...             0   \n",
       "\n",
       "                                      case_law_excerpt  \\\n",
       "859  This is because the language of this part of t...   \n",
       "860  This is because the language of this part of t...   \n",
       "\n",
       "                       legislation_excerpt confidence  \\\n",
       "859  unless the contrary intention appears       High   \n",
       "860  unless the contrary intention appears       High   \n",
       "\n",
       "                                             reasoning  \\\n",
       "859  The case law applies the interpretative princi...   \n",
       "860  The case law applies the interpretative princi...   \n",
       "\n",
       "                                             para_text  \\\n",
       "859  33. As to the definition in section 37 of the ...   \n",
       "860  33. As to the definition in section 37 of the ...   \n",
       "\n",
       "                                          section_text  line_number   status  \n",
       "859  10 References to the Sovereign. In any Act a r...          430  SUCCESS  \n",
       "860  10 References to the Sovereign. In any Act a r...          430  SUCCESS  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_regenrated_high[(claude_regenrated_high['para_id'] == 'ewhc_admin_2016_2186#para_33') & (claude_regenrated_high['section_id'] == 'http://www.legislation.gov.uk/id/ukpga/1978/30/section/10_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8b9f3fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of para_id with count=2: 5\n",
      "Number of para_id with count=1: 22\n"
     ]
    }
   ],
   "source": [
    "vc = unique_pairs.para_id.value_counts()\n",
    "print(f\"Number of para_id with count=2: {(vc==2).sum()}\")\n",
    "print(f\"Number of para_id with count=1: {(vc==1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6ce9f46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "para_id\n",
       "ewca_crim_2009_651#para_15       5\n",
       "ewhc_admin_2016_2186#para_33     4\n",
       "ewca_crim_2020_597#para_69       4\n",
       "ewhc_ch_2018_2169#para_89        4\n",
       "ewca_crim_2009_651#para_13       4\n",
       "ewhc_admin_2009_590#para_21      4\n",
       "ewca_civ_2008_1097#para_25       3\n",
       "ewhc_ch_2018_2169#para_97        3\n",
       "ewca_crim_2013_1026#para_23      2\n",
       "ewhc_ch_2022_2033#para_22        2\n",
       "ewca_crim_2004_621#para_6        2\n",
       "ewhc_admin_2005_2363#para_20     2\n",
       "ewca_civ_2015_515#para_119       2\n",
       "ewhc_admin_2009_3412#para_1      2\n",
       "ukftt_grc_2025_284#para_39       2\n",
       "ewhc_tcc_2009_1664#para_23       2\n",
       "ewhc_qb_2015_1760#para_79        2\n",
       "ewhc_ch_2018_2169#para_82        2\n",
       "ewfc_2025_41#para_45             2\n",
       "ewhc_ch_2017_769#para_221        2\n",
       "ewhc_ch_2010_938#para_47         2\n",
       "ewhc_ch_2003_2845#para_46        2\n",
       "ewca_crim_2005_3377#para_39      2\n",
       "ewca_crim_2012_1939#para_20      2\n",
       "ewhc_admin_2009_2348#para_77     2\n",
       "ewhc_admin_2003_1578#para_115    2\n",
       "ewca_civ_2003_167#para_55        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_regenrated_high.para_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13325a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_wide = pd.read_csv('../data/final_test/final/reexperiment/fewhot/11August/df_final_wide_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd536c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(claude_regenrated[claude_regenrated['confidence'] == 'High']['para_id'].unique()) - set(df_final_wide['para_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "169879ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the df_final_wide with category 'd_all_low' to compare with Claude's output\n",
    "df_final_wide_d_all_low = df_final_wide[df_final_wide['category'] == 'd_all_low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1208ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerated_Success = set(claude_regenrated[claude_regenrated['confidence'] == 'High']['para_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11d3f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_review_para_ids = set(df_final_wide_d_all_low.para_id.unique()) - regenerated_Success "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e42ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(for_review_para_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c05445b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_for_review = df_source[df_source['para_id'].isin(for_review_para_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1f80508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source_for_review.to_csv('../data/final_test/final/reexperiment/fewhot/11August/df_source_for_review.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
