{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/miniconda3/envs/Odyssey/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src folder to Python path\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "# Load environment variables from src/.env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join(os.path.dirname(os.getcwd()), 'src', '.env'))\n",
    "\n",
    "import openAIHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import make_batch_jsonl_law_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected provider: OpenAI\n",
      "Limits: 50,000 requests, 100MB per file\n",
      "Building JSONL requests...\n",
      "\n",
      "Analysis:\n",
      "  Total requests: 24,578\n",
      "  Estimated size: 250.7 MB\n",
      "  Splits needed: 3 (due to file size (250.7MB > 100MB))\n",
      "\n",
      "ðŸ“‚ Creating 3 files...\n",
      "   âœ… ../data/final_test/combined_openai_part_01.jsonl\n",
      "      Size: 82.2 MB (limit: 100 MB)\n",
      "      Requests: 8,193 (limit: 50,000)\n",
      "   âœ… ../data/final_test/combined_openai_part_02.jsonl\n",
      "      Size: 81.9 MB (limit: 100 MB)\n",
      "      Requests: 8,193 (limit: 50,000)\n",
      "   âœ… ../data/final_test/combined_openai_part_03.jsonl\n",
      "      Size: 82.1 MB (limit: 100 MB)\n",
      "      Requests: 8,192 (limit: 50,000)\n",
      "\n",
      "ðŸ“‹ Summary:\n",
      "   Provider: OpenAI\n",
      "   Model: gpt-4o-mini\n",
      "   Files created: 3\n",
      "   Total requests: 24,578\n",
      "   Total size: 246.2 MB\n",
      "\n",
      "ðŸ“ Output files:\n",
      "   1. ../data/final_test/combined_openai_part_01.jsonl\n",
      "   2. ../data/final_test/combined_openai_part_02.jsonl\n",
      "   3. ../data/final_test/combined_openai_part_03.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_total = pd.read_csv('../data/final_test/combined_sampled_caselaws.csv')\n",
    "df_sample = df_total.sample(10)\n",
    "\n",
    "prompt_file = '../data/final_test/prompt.txt'\n",
    "\n",
    "output_path = '../data/final_test/combined_openai.jsonl'\n",
    "\n",
    "examples_file = '../data/final_test/examples.json'\n",
    "\n",
    "jsonl_files =make_batch_jsonl_law_application.create_batch_jsonl(\n",
    "    model_name='gpt-4o-mini',\n",
    "    prompt_file=prompt_file,\n",
    "    examples_file=examples_file,\n",
    "    df=df_total,\n",
    "    output_path=output_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../data/final_test/combined_openai_part_01.jsonl'\n",
    "batch_job = openAIHandler.get_batch_job(input_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batch_6848998a60188190bc4d3e22f2b39d8e'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_job.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[Batch](data=[Batch(id='batch_6848998a60188190bc4d3e22f2b39d8e', completion_window='24h', created_at=1749588362, endpoint='/v1/chat/completions', input_file_id='file-U9nTUkDJrWuqt374EBhxMD', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749674762, failed_at=None, finalizing_at=None, in_progress_at=1749588367, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=8193)), Batch(id='batch_68485f5930a08190b4b235c15f5500f3', completion_window='24h', created_at=1749573465, endpoint='/v1/chat/completions', input_file_id='file-D5e7dbwsfEqZjHeN8pKqdw', object='batch', status='cancelled', cancelled_at=1749585863, cancelling_at=1749585039, completed_at=None, error_file_id='file-FzwzyJGWKTU7VoJG1zHZ8M', errors=None, expired_at=None, expires_at=1749659865, failed_at=None, finalizing_at=None, in_progress_at=1749573471, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=8192)), Batch(id='batch_68485eecd3348190811410b70308cb00', completion_window='24h', created_at=1749573356, endpoint='/v1/chat/completions', input_file_id='file-QYWz74WQ3jyh8TQVAcPwdG', object='batch', status='cancelled', cancelled_at=1749586020, cancelling_at=1749585045, completed_at=None, error_file_id='file-2FsdUTfRQ33BrchpmaUCpU', errors=None, expired_at=None, expires_at=1749659756, failed_at=None, finalizing_at=None, in_progress_at=1749573363, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=8193)), Batch(id='batch_68485acc6a848190814661bdb5e019e1', completion_window='24h', created_at=1749572300, endpoint='/v1/chat/completions', input_file_id='file-KvH4JYJxSPxq3e4QyDZe5P', object='batch', status='cancelled', cancelled_at=1749585874, cancelling_at=1749585052, completed_at=None, error_file_id='file-Q4vK161rSWzaadN3jyJi7K', errors=None, expired_at=None, expires_at=1749658700, failed_at=None, finalizing_at=None, in_progress_at=1749572307, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=8193)), Batch(id='batch_6848352feea081908a698fa5cedb0afc', completion_window='24h', created_at=1749562671, endpoint='/v1/chat/completions', input_file_id='file-BFRVA2LkZW4mHVEtEVSXWd', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='maximum_input_file_size_exceeded', line=None, message='The batch input file is larger than the 209715200 maximum for the gpt-4o-mini model. Please try again with a smaller batch.', param=None)], object='list'), expired_at=None, expires_at=1749649071, failed_at=1749562675, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_683c119c16dc8190b2d67e5bfa31ab14', completion_window='24h', created_at=1748767132, endpoint='/v1/chat/completions', input_file_id='file-UDfjQys6RgyqTeohgtvVPq', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748767505, error_file_id=None, errors=None, expired_at=None, expires_at=1748853532, failed_at=None, finalizing_at=1748767446, in_progress_at=1748767134, metadata=None, output_file_id='file-9CKMdbCqDAaJ2sd64MJLJL', request_counts=BatchRequestCounts(completed=1108, failed=0, total=1108)), Batch(id='batch_683a26e3f7348190b06d2e3c890da271', completion_window='24h', created_at=1748641507, endpoint='/v1/chat/completions', input_file_id='file-MopbzxrafAsPKVWboreWiq', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748643783, error_file_id=None, errors=None, expired_at=None, expires_at=1748727907, failed_at=None, finalizing_at=1748643623, in_progress_at=1748641510, metadata=None, output_file_id='file-5cUc4rTC35g1FxAmw8SQ5p', request_counts=BatchRequestCounts(completed=1858, failed=0, total=1858)), Batch(id='batch_6835f8fc705c8190b9d09dee7b122788', completion_window='24h', created_at=1748367612, endpoint='/v1/chat/completions', input_file_id='file-MpXcBTCoYiCXohBW9d6tMk', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748368713, error_file_id=None, errors=None, expired_at=None, expires_at=1748454012, failed_at=None, finalizing_at=1748368627, in_progress_at=1748367613, metadata=None, output_file_id='file-9KVE4C7wK1kWXJqrEDek54', request_counts=BatchRequestCounts(completed=1108, failed=0, total=1108)), Batch(id='batch_6830b939b04c81908695504aa9423f7b', completion_window='24h', created_at=1748023609, endpoint='/v1/chat/completions', input_file_id='file-NSAJTF2ra8hedzVba8QXZh', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748024834, error_file_id=None, errors=None, expired_at=None, expires_at=1748110009, failed_at=None, finalizing_at=1748024742, in_progress_at=1748023612, metadata=None, output_file_id='file-4CwqRuC4Pt8kfTaNbw3MNb', request_counts=BatchRequestCounts(completed=938, failed=0, total=938)), Batch(id='batch_682ef3c4b2348190a077a2faadacbc28', completion_window='24h', created_at=1747907524, endpoint='/v1/chat/completions', input_file_id='file-DZWFu7W4c9BrgNWzXYsi7P', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747907759, error_file_id=None, errors=None, expired_at=None, expires_at=1747993924, failed_at=None, finalizing_at=1747907697, in_progress_at=1747907526, metadata=None, output_file_id='file-UPsWKGcBEsiaMFZp7Yoj4m', request_counts=BatchRequestCounts(completed=938, failed=0, total=938)), Batch(id='batch_682dd555c8908190856ecdac4fa784a5', completion_window='24h', created_at=1747834197, endpoint='/v1/chat/completions', input_file_id='file-FqQ4ryRRUMzd4Egvor2jVo', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747834277, error_file_id=None, errors=None, expired_at=None, expires_at=1747920597, failed_at=None, finalizing_at=1747834266, in_progress_at=1747834199, metadata=None, output_file_id='file-RRg4A9Naez6mekbEiDA9at', request_counts=BatchRequestCounts(completed=177, failed=0, total=177)), Batch(id='batch_68266d92253c8190aeb7376380bd0fd0', completion_window='24h', created_at=1747348882, endpoint='/v1/chat/completions', input_file_id='file-VftBYNSVsnv8KQTcJ26SDc', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747352130, error_file_id=None, errors=None, expired_at=None, expires_at=1747435282, failed_at=None, finalizing_at=1747352123, in_progress_at=1747348883, metadata=None, output_file_id='file-BPT7ypSADWNkAZvEKAqvYL', request_counts=BatchRequestCounts(completed=57, failed=0, total=57)), Batch(id='batch_68266aed0c688190aa94530e77958a55', completion_window='24h', created_at=1747348205, endpoint='/v1/chat/completions', input_file_id='file-VLwcgvbukHp4iBViPb9U7q', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='unknown_parameter', line=1, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=2, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=3, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=4, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=5, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=6, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=7, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=8, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=9, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=10, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=11, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=12, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=13, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=14, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=15, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=16, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=17, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=18, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=19, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=20, message=\"Unknown parameter: 'metadata'.\", param='metadata')], object='list'), expired_at=None, expires_at=1747434605, failed_at=1747348206, finalizing_at=None, in_progress_at=None, metadata={'description': 'test extraction job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_68266acf9bcc8190961f3d88f45f5e62', completion_window='24h', created_at=1747348175, endpoint='/v1/chat/completions', input_file_id='file-XdJqiew38Y5LyYfjeMRM26', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='unknown_parameter', line=1, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=2, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=3, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=4, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=5, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=6, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=7, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=8, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=9, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=10, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=11, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=12, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=13, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=14, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=15, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=16, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=17, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=18, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=19, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=20, message=\"Unknown parameter: 'metadata'.\", param='metadata')], object='list'), expired_at=None, expires_at=1747434575, failed_at=1747348176, finalizing_at=None, in_progress_at=None, metadata={'description': 'test extraction job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_67ee51b58ab08190ae274a77e1ade182', completion_window='24h', created_at=1743671733, endpoint='/v1/chat/completions', input_file_id='file-YFgWFryRgXLoZhYH8SJQJA', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1743671801, error_file_id=None, errors=None, expired_at=None, expires_at=1743758133, failed_at=None, finalizing_at=1743671796, in_progress_at=1743671734, metadata=None, output_file_id='file-JEnmAkPEp2TYfUezvyMiit', request_counts=BatchRequestCounts(completed=93, failed=0, total=93)), Batch(id='batch_67bc62da9aa48190a4d93ec4adf842f5', completion_window='24h', created_at=1740399322, endpoint='/v1/chat/completions', input_file_id='file-L3E35zP8bkiJk6Xz89VsQp', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740399407, error_file_id=None, errors=None, expired_at=None, expires_at=1740485722, failed_at=None, finalizing_at=1740399406, in_progress_at=1740399323, metadata=None, output_file_id='file-9nbt441wVrvG9PFVxo4w56', request_counts=BatchRequestCounts(completed=10, failed=0, total=10)), Batch(id='batch_67bc6010ef048190bbecc2a2e77df890', completion_window='24h', created_at=1740398608, endpoint='/v1/chat/completions', input_file_id='file-YDzdjyrZbkYQGSbWrK5YG8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740398636, error_file_id='file-Qk1vjL3mZSXvESCxLk6KVt', errors=None, expired_at=None, expires_at=1740485008, failed_at=None, finalizing_at=1740398635, in_progress_at=1740398610, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=10, total=10)), Batch(id='batch_anewRG8OxTExjD4VUZV0wweY', completion_window='24h', created_at=1726660563, endpoint='/v1/chat/completions', input_file_id='file-rIBLKbZWNaNDCjSFNJIMx1AS', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726660831, error_file_id=None, errors=None, expired_at=None, expires_at=1726746963, failed_at=None, finalizing_at=1726660799, in_progress_at=1726660564, metadata=None, output_file_id='file-ClMe1o26UdQkBDCvTTOjTcaq', request_counts=BatchRequestCounts(completed=463, failed=0, total=463)), Batch(id='batch_ch2WCKqPhN4V44K9hgyVK8ry', completion_window='24h', created_at=1726141576, endpoint='/v1/chat/completions', input_file_id='file-XE8dejaINS2aJDflZh0Czz6H', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726142629, error_file_id=None, errors=None, expired_at=None, expires_at=1726227976, failed_at=None, finalizing_at=1726142586, in_progress_at=1726141578, metadata=None, output_file_id='file-erZQ4MaPSyd5MvkBemwP6nbS', request_counts=BatchRequestCounts(completed=512, failed=0, total=512)), Batch(id='batch_9ZQNztkTB89OYVr2ljqvBLcb', completion_window='24h', created_at=1725218550, endpoint='/v1/chat/completions', input_file_id='file-iiLHhBALE8TPrDA4G84NX2kn', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1725218926, error_file_id=None, errors=None, expired_at=None, expires_at=1725304950, failed_at=None, finalizing_at=1725218909, in_progress_at=1725218552, metadata=None, output_file_id='file-YThU64m6UnOyX2dZ8tUYyUvA', request_counts=BatchRequestCounts(completed=410, failed=0, total=410))], object='list', first_id='batch_6848998a60188190bc4d3e22f2b39d8e', last_id='batch_9ZQNztkTB89OYVr2ljqvBLcb', has_more=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI()\n",
    "client.batches.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = client.batches.list().data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-KvH4JYJxSPxq3e4QyDZe5P'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1.input_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../data/final_test/combined_openai_part_02.jsonl'\n",
    "batch_job2 = openAIHandler.get_batch_job(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_2 = client.batches.list().data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-QYWz74WQ3jyh8TQVAcPwdG'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_2.input_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-WCrHrpxUEwHjTKjfpoozv4\n"
     ]
    }
   ],
   "source": [
    "input_file = '../data/final_test/combined_openai_part_03.jsonl'\n",
    "batch_job3 = openAIHandler.get_batch_job(input_file)\n",
    "batch_3 = client.batches.list().data[0]\n",
    "print(batch_3.input_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-D5e7dbwsfEqZjHeN8pKqdw\n"
     ]
    }
   ],
   "source": [
    "batch_3 = client.batches.list().data[0]\n",
    "print(batch_3.input_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[Batch](data=[Batch(id='batch_68485f5930a08190b4b235c15f5500f3', completion_window='24h', created_at=1749573465, endpoint='/v1/chat/completions', input_file_id='file-D5e7dbwsfEqZjHeN8pKqdw', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749659865, failed_at=None, finalizing_at=None, in_progress_at=1749573471, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=8192)), Batch(id='batch_68485eecd3348190811410b70308cb00', completion_window='24h', created_at=1749573356, endpoint='/v1/chat/completions', input_file_id='file-QYWz74WQ3jyh8TQVAcPwdG', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749659756, failed_at=None, finalizing_at=None, in_progress_at=1749573363, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=8193)), Batch(id='batch_68485acc6a848190814661bdb5e019e1', completion_window='24h', created_at=1749572300, endpoint='/v1/chat/completions', input_file_id='file-KvH4JYJxSPxq3e4QyDZe5P', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749658700, failed_at=None, finalizing_at=None, in_progress_at=1749572307, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=8193)), Batch(id='batch_6848352feea081908a698fa5cedb0afc', completion_window='24h', created_at=1749562671, endpoint='/v1/chat/completions', input_file_id='file-BFRVA2LkZW4mHVEtEVSXWd', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='maximum_input_file_size_exceeded', line=None, message='The batch input file is larger than the 209715200 maximum for the gpt-4o-mini model. Please try again with a smaller batch.', param=None)], object='list'), expired_at=None, expires_at=1749649071, failed_at=1749562675, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_683c119c16dc8190b2d67e5bfa31ab14', completion_window='24h', created_at=1748767132, endpoint='/v1/chat/completions', input_file_id='file-UDfjQys6RgyqTeohgtvVPq', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748767505, error_file_id=None, errors=None, expired_at=None, expires_at=1748853532, failed_at=None, finalizing_at=1748767446, in_progress_at=1748767134, metadata=None, output_file_id='file-9CKMdbCqDAaJ2sd64MJLJL', request_counts=BatchRequestCounts(completed=1108, failed=0, total=1108)), Batch(id='batch_683a26e3f7348190b06d2e3c890da271', completion_window='24h', created_at=1748641507, endpoint='/v1/chat/completions', input_file_id='file-MopbzxrafAsPKVWboreWiq', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748643783, error_file_id=None, errors=None, expired_at=None, expires_at=1748727907, failed_at=None, finalizing_at=1748643623, in_progress_at=1748641510, metadata=None, output_file_id='file-5cUc4rTC35g1FxAmw8SQ5p', request_counts=BatchRequestCounts(completed=1858, failed=0, total=1858)), Batch(id='batch_6835f8fc705c8190b9d09dee7b122788', completion_window='24h', created_at=1748367612, endpoint='/v1/chat/completions', input_file_id='file-MpXcBTCoYiCXohBW9d6tMk', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748368713, error_file_id=None, errors=None, expired_at=None, expires_at=1748454012, failed_at=None, finalizing_at=1748368627, in_progress_at=1748367613, metadata=None, output_file_id='file-9KVE4C7wK1kWXJqrEDek54', request_counts=BatchRequestCounts(completed=1108, failed=0, total=1108)), Batch(id='batch_6830b939b04c81908695504aa9423f7b', completion_window='24h', created_at=1748023609, endpoint='/v1/chat/completions', input_file_id='file-NSAJTF2ra8hedzVba8QXZh', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1748024834, error_file_id=None, errors=None, expired_at=None, expires_at=1748110009, failed_at=None, finalizing_at=1748024742, in_progress_at=1748023612, metadata=None, output_file_id='file-4CwqRuC4Pt8kfTaNbw3MNb', request_counts=BatchRequestCounts(completed=938, failed=0, total=938)), Batch(id='batch_682ef3c4b2348190a077a2faadacbc28', completion_window='24h', created_at=1747907524, endpoint='/v1/chat/completions', input_file_id='file-DZWFu7W4c9BrgNWzXYsi7P', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747907759, error_file_id=None, errors=None, expired_at=None, expires_at=1747993924, failed_at=None, finalizing_at=1747907697, in_progress_at=1747907526, metadata=None, output_file_id='file-UPsWKGcBEsiaMFZp7Yoj4m', request_counts=BatchRequestCounts(completed=938, failed=0, total=938)), Batch(id='batch_682dd555c8908190856ecdac4fa784a5', completion_window='24h', created_at=1747834197, endpoint='/v1/chat/completions', input_file_id='file-FqQ4ryRRUMzd4Egvor2jVo', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747834277, error_file_id=None, errors=None, expired_at=None, expires_at=1747920597, failed_at=None, finalizing_at=1747834266, in_progress_at=1747834199, metadata=None, output_file_id='file-RRg4A9Naez6mekbEiDA9at', request_counts=BatchRequestCounts(completed=177, failed=0, total=177)), Batch(id='batch_68266d92253c8190aeb7376380bd0fd0', completion_window='24h', created_at=1747348882, endpoint='/v1/chat/completions', input_file_id='file-VftBYNSVsnv8KQTcJ26SDc', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1747352130, error_file_id=None, errors=None, expired_at=None, expires_at=1747435282, failed_at=None, finalizing_at=1747352123, in_progress_at=1747348883, metadata=None, output_file_id='file-BPT7ypSADWNkAZvEKAqvYL', request_counts=BatchRequestCounts(completed=57, failed=0, total=57)), Batch(id='batch_68266aed0c688190aa94530e77958a55', completion_window='24h', created_at=1747348205, endpoint='/v1/chat/completions', input_file_id='file-VLwcgvbukHp4iBViPb9U7q', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='unknown_parameter', line=1, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=2, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=3, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=4, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=5, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=6, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=7, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=8, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=9, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=10, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=11, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=12, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=13, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=14, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=15, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=16, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=17, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=18, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=19, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=20, message=\"Unknown parameter: 'metadata'.\", param='metadata')], object='list'), expired_at=None, expires_at=1747434605, failed_at=1747348206, finalizing_at=None, in_progress_at=None, metadata={'description': 'test extraction job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_68266acf9bcc8190961f3d88f45f5e62', completion_window='24h', created_at=1747348175, endpoint='/v1/chat/completions', input_file_id='file-XdJqiew38Y5LyYfjeMRM26', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='unknown_parameter', line=1, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=2, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=3, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=4, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=5, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=6, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=7, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=8, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=9, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=10, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=11, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=12, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=13, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=14, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=15, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=16, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=17, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=18, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=19, message=\"Unknown parameter: 'metadata'.\", param='metadata'), BatchError(code='unknown_parameter', line=20, message=\"Unknown parameter: 'metadata'.\", param='metadata')], object='list'), expired_at=None, expires_at=1747434575, failed_at=1747348176, finalizing_at=None, in_progress_at=None, metadata={'description': 'test extraction job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_67ee51b58ab08190ae274a77e1ade182', completion_window='24h', created_at=1743671733, endpoint='/v1/chat/completions', input_file_id='file-YFgWFryRgXLoZhYH8SJQJA', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1743671801, error_file_id=None, errors=None, expired_at=None, expires_at=1743758133, failed_at=None, finalizing_at=1743671796, in_progress_at=1743671734, metadata=None, output_file_id='file-JEnmAkPEp2TYfUezvyMiit', request_counts=BatchRequestCounts(completed=93, failed=0, total=93)), Batch(id='batch_67bc62da9aa48190a4d93ec4adf842f5', completion_window='24h', created_at=1740399322, endpoint='/v1/chat/completions', input_file_id='file-L3E35zP8bkiJk6Xz89VsQp', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740399407, error_file_id=None, errors=None, expired_at=None, expires_at=1740485722, failed_at=None, finalizing_at=1740399406, in_progress_at=1740399323, metadata=None, output_file_id='file-9nbt441wVrvG9PFVxo4w56', request_counts=BatchRequestCounts(completed=10, failed=0, total=10)), Batch(id='batch_67bc6010ef048190bbecc2a2e77df890', completion_window='24h', created_at=1740398608, endpoint='/v1/chat/completions', input_file_id='file-YDzdjyrZbkYQGSbWrK5YG8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1740398636, error_file_id='file-Qk1vjL3mZSXvESCxLk6KVt', errors=None, expired_at=None, expires_at=1740485008, failed_at=None, finalizing_at=1740398635, in_progress_at=1740398610, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=10, total=10)), Batch(id='batch_anewRG8OxTExjD4VUZV0wweY', completion_window='24h', created_at=1726660563, endpoint='/v1/chat/completions', input_file_id='file-rIBLKbZWNaNDCjSFNJIMx1AS', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726660831, error_file_id=None, errors=None, expired_at=None, expires_at=1726746963, failed_at=None, finalizing_at=1726660799, in_progress_at=1726660564, metadata=None, output_file_id='file-ClMe1o26UdQkBDCvTTOjTcaq', request_counts=BatchRequestCounts(completed=463, failed=0, total=463)), Batch(id='batch_ch2WCKqPhN4V44K9hgyVK8ry', completion_window='24h', created_at=1726141576, endpoint='/v1/chat/completions', input_file_id='file-XE8dejaINS2aJDflZh0Czz6H', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1726142629, error_file_id=None, errors=None, expired_at=None, expires_at=1726227976, failed_at=None, finalizing_at=1726142586, in_progress_at=1726141578, metadata=None, output_file_id='file-erZQ4MaPSyd5MvkBemwP6nbS', request_counts=BatchRequestCounts(completed=512, failed=0, total=512)), Batch(id='batch_9ZQNztkTB89OYVr2ljqvBLcb', completion_window='24h', created_at=1725218550, endpoint='/v1/chat/completions', input_file_id='file-iiLHhBALE8TPrDA4G84NX2kn', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1725218926, error_file_id=None, errors=None, expired_at=None, expires_at=1725304950, failed_at=None, finalizing_at=1725218909, in_progress_at=1725218552, metadata=None, output_file_id='file-YThU64m6UnOyX2dZ8tUYyUvA', request_counts=BatchRequestCounts(completed=410, failed=0, total=410)), Batch(id='batch_7FgiISEC41hZRPipIIVFeTYi', completion_window='24h', created_at=1724966952, endpoint='/v1/chat/completions', input_file_id='file-Z1ZpAz3tTNtlreZLOq1NtHVf', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1724967136, error_file_id=None, errors=None, expired_at=None, expires_at=1725053352, failed_at=None, finalizing_at=1724967133, in_progress_at=1724966953, metadata=None, output_file_id='file-3YoaidQZFdVtN3xXHZdVwRra', request_counts=BatchRequestCounts(completed=60, failed=0, total=60))], object='list', first_id='batch_68485f5930a08190b4b235c15f5500f3', last_id='batch_7FgiISEC41hZRPipIIVFeTYi', has_more=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = client.batches.list().data[2]\n",
    "batch_2 = client.batches.list().data[1]\n",
    "batch_3 = client.batches.list().data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "completed\n",
      "expired\n"
     ]
    }
   ],
   "source": [
    "print(batch_1.status)\n",
    "print(batch_2.status)\n",
    "print(batch_3.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-8RwUiAaYffQYLt1xmAzRkT'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_3.output_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = batch_1.output_file_id\n",
    "file_response = client.files.content(file_id)\n",
    "with open(\"../data/final_test/combined_openai_part_01_output.jsonl\", \"wb\") as f:\n",
    "    f.write(file_response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file saved to: ../data/final_test/combined_openai_output.jsonl\n",
      "Number of lines in first file: 8193\n",
      "Number of lines in second file: 8193\n",
      "Number of lines in third file: 8192\n",
      "Total lines in combined file: 24578\n"
     ]
    }
   ],
   "source": [
    "# Combine three JSONL files into one\n",
    "input_file1 = \"../data/final_test/combined_openai_part_01_output.jsonl\"\n",
    "input_file2 = \"../data/final_test/combined_openai_part_02_output.jsonl\"\n",
    "input_file3 = \"../data/final_test/combined_openai_part_03_output.jsonl\"\n",
    "\n",
    "output_file = \"../data/final_test/combined_openai_output.jsonl\"\n",
    "\n",
    "# Read and combine the files\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    # Process first file\n",
    "    with open(input_file1, 'r', encoding='utf-8') as infile1:\n",
    "        for line in infile1:\n",
    "            outfile.write(line)\n",
    "    \n",
    "    # Process second file\n",
    "    with open(input_file2, 'r', encoding='utf-8') as infile2:\n",
    "        for line in infile2:\n",
    "            outfile.write(line)\n",
    "            \n",
    "    # Process third file\n",
    "    with open(input_file3, 'r', encoding='utf-8') as infile3:\n",
    "        for line in infile3:\n",
    "            outfile.write(line)\n",
    "\n",
    "print(f\"Combined file saved to: {output_file}\")\n",
    "\n",
    "# Verify the number of lines in each file\n",
    "with open(input_file1, 'r', encoding='utf-8') as f1:\n",
    "    lines1 = sum(1 for _ in f1)\n",
    "with open(input_file2, 'r', encoding='utf-8') as f2:\n",
    "    lines2 = sum(1 for _ in f2)\n",
    "with open(input_file3, 'r', encoding='utf-8') as f3:\n",
    "    lines3 = sum(1 for _ in f3)\n",
    "with open(output_file, 'r', encoding='utf-8') as f4:\n",
    "    lines4 = sum(1 for _ in f4)\n",
    "\n",
    "print(f\"Number of lines in first file: {lines1}\")\n",
    "print(f\"Number of lines in second file: {lines2}\")\n",
    "print(f\"Number of lines in third file: {lines3}\")\n",
    "print(f\"Total lines in combined file: {lines4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV saved to: ../data/final_test/combined_openai_output.csv\n",
      "                                            case_uri  \\\n",
      "0  https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
      "1  https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
      "2  https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
      "3  https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
      "4  https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
      "\n",
      "                    para_id  \\\n",
      "0  ewhc_ch_2009_1229#para_1   \n",
      "1  ewhc_ch_2009_1229#para_2   \n",
      "2  ewhc_ch_2009_1229#para_3   \n",
      "3  ewhc_ch_2009_1229#para_4   \n",
      "4  ewhc_ch_2009_1229#para_5   \n",
      "\n",
      "                                          paragraphs references  \\\n",
      "0  1. The Revenueâ€™s appeal to the High Court was ...         []   \n",
      "1  2. I circulated my judgment to the parties in ...         []   \n",
      "2  3. On 16 January BLP forwarded to my clerk a w...         []   \n",
      "3  4. The reasons given by Dr Banerjee for reques...         []   \n",
      "4  5. Dr Banerjee went on to say that she oversee...         []   \n",
      "\n",
      "  if_law_applied application_of_law_phrases  \\\n",
      "0          False                         []   \n",
      "1          False                         []   \n",
      "2          False                         []   \n",
      "3          False                         []   \n",
      "4          False                         []   \n",
      "\n",
      "                                              reason  \n",
      "0  The paragraph provides procedural details abou...  \n",
      "1  This paragraph provides procedural information...  \n",
      "2  This paragraph provides procedural information...  \n",
      "3  This paragraph discusses the reasons for reque...  \n",
      "4  This paragraph describes concerns about public...  \n",
      "Index(['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied',\n",
      "       'application_of_law_phrases', 'reason'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import extract_data_from_jsonl\n",
    "combined_csv_path = '../data/final_test/combined_sampled_caselaws.csv'\n",
    "output_jsonl_path = '../data/final_test/combined_openai_output.jsonl'\n",
    "output_csv_path = '../data/final_test/combined_openai_output.csv'\n",
    "extract_data_from_jsonl.merge_combined_csv_and_output_jsonl(combined_csv_path, output_jsonl_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if_law_applied\n",
       "False    14206\n",
       "True     10724\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('../data/final_test/combined_openai_output.csv')\n",
    "\n",
    "# Count how many rows have True in if_law_applied column\n",
    "df['if_law_applied'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied',\n",
       "       'application_of_law_phrases', 'reason'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../data/final_test/combined_llama_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df rows: 24538\n",
      "Original df2 rows: 24538\n",
      "Combined df rows: 24538\n",
      "\n",
      "Checking for duplicates in merge keys:\n",
      "Duplicates in df: 0\n",
      "Duplicates in df2: 0\n",
      "\n",
      "Percentage agreement between models: 81.95%\n",
      "\n",
      "Detailed agreement counts:\n",
      "if_law_applied_llama  False  True    All\n",
      "if_law_applied                          \n",
      "False                 12445  1454  13899\n",
      "True                   2900  7665  10565\n",
      "All                   15345  9119  24464\n"
     ]
    }
   ],
   "source": [
    "df2.columns\n",
    "# Rename columns in df2 by adding _llama suffix\n",
    "df2 = df2.rename(columns={\n",
    "    'if_law_applied': 'if_law_applied_llama',\n",
    "    'application_of_law_phrases': 'application_of_law_phrases_llama',\n",
    "    'reason': 'reason_llama'\n",
    "})\n",
    "df = df.drop_duplicates(subset=['case_uri', 'para_id'])\n",
    "df2 = df2.drop_duplicates(subset=['case_uri', 'para_id'])\n",
    "# Combine dataframes on common columns\n",
    "combined_df = pd.merge(\n",
    "    df, \n",
    "    df2,\n",
    "    on=['case_uri', 'para_id', 'paragraphs', 'references'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Verify row counts match\n",
    "print(f\"Original df rows: {len(df)}\")\n",
    "print(f\"Original df2 rows: {len(df2)}\")\n",
    "print(f\"Combined df rows: {len(combined_df)}\")\n",
    "\n",
    "# Check for duplicate rows in the merge keys\n",
    "print(\"\\nChecking for duplicates in merge keys:\")\n",
    "print(f\"Duplicates in df: {df.duplicated(['case_uri', 'para_id']).sum()}\")\n",
    "print(f\"Duplicates in df2: {df2.duplicated(['case_uri', 'para_id']).sum()}\")\n",
    "\n",
    "# Show example of duplicate rows if they exist\n",
    "if df.duplicated(['case_uri', 'para_id']).sum() > 0:\n",
    "    print(\"\\nExample duplicate rows in df:\")\n",
    "    print(df[df.duplicated(['case_uri', 'para_id'], keep=False)].head())\n",
    "if df2.duplicated(['case_uri', 'para_id']).sum() > 0:\n",
    "    print(\"\\nExample duplicate rows in df2:\")\n",
    "    print(df2[df2.duplicated(['case_uri', 'para_id'], keep=False)].head())\n",
    "\n",
    "# Calculate agreement percentage\n",
    "agreement = (combined_df['if_law_applied'] == combined_df['if_law_applied_llama']).mean() * 100\n",
    "print(f\"\\nPercentage agreement between models: {agreement:.2f}%\")\n",
    "\n",
    "# Show detailed agreement counts\n",
    "agreement_counts = pd.crosstab(\n",
    "    combined_df['if_law_applied'], \n",
    "    combined_df['if_law_applied_llama'],\n",
    "    margins=True\n",
    ")\n",
    "print(\"\\nDetailed agreement counts:\")\n",
    "print(agreement_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement = combined_df[combined_df['if_law_applied'] == combined_df['if_law_applied_llama']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement.to_csv('../data/final_test/agreement.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreement = combined_df[combined_df['if_law_applied'] != combined_df['if_law_applied_llama']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreement.to_csv('../data/final_test/disagreement.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "disagreement = pd.read_csv('../data/final_test/disagreement.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied',\n",
       "       'application_of_law_phrases', 'reason', 'if_law_applied_llama',\n",
       "       'application_of_law_phrases_llama', 'reason_llama'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreement.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 'para_id', 'paragraphs', 'if_law_applied',\n",
    "       'application_of_law_phrases', 'reason', 'if_law_applied_llama',\n",
    "       'application_of_law_phrases_llama', 'reason_llama'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provider: Anthropic (Claude)\n",
      "Limits: 50,000 requests, 100MB per file\n",
      "Found 4428 disagreement cases out of 4428 total cases (100.0%)\n",
      "Building disagreement resolution JSONL requests...\n",
      "\n",
      "Analysis:\n",
      "  Disagreement cases: 4,428\n",
      "  Estimated size: 19.4 MB\n",
      "  Splits needed: 1 (file within limits)\n",
      "\n",
      "âœ… Creating single disagreement resolution file: ../data/final_test/disagreement_jsonl.jsonl\n",
      "   Actual size: 18.9 MB\n",
      "   Disagreement cases: 4,428\n",
      "\n",
      "ðŸ“‹ Disagreement Resolution Summary:\n",
      "   Provider: Anthropic (Claude)\n",
      "   Model: claude-sonnet-4-20250514\n",
      "   Files created: 1\n",
      "   Disagreement cases processed: 4,428\n",
      "   Agreement rate: 0.0%\n",
      "   Total size: 18.9 MB\n",
      "\n",
      "ðŸ“ Output files:\n",
      "   1. ../data/final_test/disagreement_jsonl.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/final_test/disagreement_jsonl.jsonl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import make_batch_jsonl_law_application\n",
    "make_batch_jsonl_law_application.create_batch_jsonl_for_disagreement(\"claude-sonnet-4-20250514\",disagreement,'../data/final_test/disagreement_jsonl.jsonl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "{\n",
      "    \"para_id\": \"ewhc_ch_2009_1229#para_13\",\n",
      "    \"if_law_applied\": false,\n",
      "    \"application_of_law_phrases\": [],\n",
      "    \"reason\": \"After careful analysis, Model B (Llama) provides the more accurate interpretation. This paragraph is primarily setting out the general legal framework regarding confidentiality of financial and tax affairs, rather than applying it to specific case facts. The paragraph: 1) States the general principle about privacy of financial affairs, 2) Cites case law establishing the duty of confidence, and 3) Explains how the Human Rights Act and Article 8 relate to this principle. While it mentions 'public authorities' and 'the Revenue,' these are referenced as general categories rather than being applied to specific circumstances of the case. The phrase 'Turning to the relevant law' at the start signals this is a legal background section. There is no analysis of specific facts or circumstances of the current case, which would be necessary for an application of law.\",\n",
      "    \"confidence\": \"High\",\n",
      "    \"agreement_with\": \"Llama\"\n",
      "}\n",
      "\n",
      "Parsed JSON:\n",
      "{\n",
      "  \"para_id\": \"ewhc_ch_2009_1229#para_13\",\n",
      "  \"if_law_applied\": false,\n",
      "  \"application_of_law_phrases\": [],\n",
      "  \"reason\": \"After careful analysis, Model B (Llama) provides the more accurate interpretation. This paragraph is primarily setting out the general legal framework regarding confidentiality of financial and tax affairs, rather than applying it to specific case facts. The paragraph: 1) States the general principle about privacy of financial affairs, 2) Cites case law establishing the duty of confidence, and 3) Explains how the Human Rights Act and Article 8 relate to this principle. While it mentions 'public authorities' and 'the Revenue,' these are referenced as general categories rather than being applied to specific circumstances of the case. The phrase 'Turning to the relevant law' at the start signals this is a legal background section. There is no analysis of specific facts or circumstances of the current case, which would be necessary for an application of law.\",\n",
      "  \"confidence\": \"High\",\n",
      "  \"agreement_with\": \"Llama\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# Read first line from JSONL\n",
    "with open(\"../data/final_test/disagreement_jsonl.jsonl\", 'r', encoding='utf-8') as f:\n",
    "   first_line = f.readline().strip()\n",
    "\n",
    "request_data = json.loads(first_line)\n",
    "\n",
    "# Initialize ChatAnthropic with Sonnet 4\n",
    "llm = ChatAnthropic(\n",
    "   model=\"claude-3-5-sonnet-20241022\",  # or whatever Sonnet 4 model name you have\n",
    "\n",
    ")\n",
    "\n",
    "# Convert messages to LangChain format\n",
    "messages = []\n",
    "for msg in request_data[\"body\"][\"messages\"]:\n",
    "   if msg[\"role\"] == \"system\":\n",
    "       messages.append(SystemMessage(content=msg[\"content\"]))\n",
    "   elif msg[\"role\"] == \"user\":\n",
    "       messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "\n",
    "# Send to ChatAnthropic\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Print response\n",
    "print(\"Response:\")\n",
    "print(response.content)\n",
    "\n",
    "# Try to parse as JSON\n",
    "try:\n",
    "   parsed = json.loads(response.content)\n",
    "   print(\"\\nParsed JSON:\")\n",
    "   print(json.dumps(parsed, indent=2))\n",
    "except:\n",
    "   print(\"Could not parse as JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 4428 requests for batch processing\n",
      "Batch created: msgbatch_01GqaiCJzRs6jvEyP3e4fVAc\n",
      "Status: in_progress\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from anthropic import Anthropic\n",
    "\n",
    "# Initialize client\n",
    "client = Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# Read and convert first 5 requests from JSONL file\n",
    "requests = []\n",
    "with open(\"../data/final_test/disagreement_jsonl.jsonl\", 'r') as f:\n",
    "   for i, line in enumerate(f):\n",
    "    #    if i >= 5:  # Only process first 5 requests\n",
    "    #        break\n",
    "           \n",
    "       data = json.loads(line.strip())\n",
    "       \n",
    "       request = {\n",
    "           \"custom_id\": data[\"custom_id\"],\n",
    "           \"params\": {\n",
    "               \"model\": data[\"body\"][\"model\"],\n",
    "               \"max_tokens\": 1000,\n",
    "\n",
    "               \"messages\": [\n",
    "                   msg for msg in data[\"body\"][\"messages\"] \n",
    "                   if msg[\"role\"] != \"system\"\n",
    "               ],\n",
    "               \"system\": next(\n",
    "                   (msg[\"content\"] for msg in data[\"body\"][\"messages\"] \n",
    "                    if msg[\"role\"] == \"system\"), None\n",
    "               )\n",
    "           }\n",
    "       }\n",
    "       requests.append(request)\n",
    "\n",
    "print(f\"Prepared {len(requests)} requests for batch processing\")\n",
    "\n",
    "# Create the batch\n",
    "message_batch = client.messages.batches.create(requests=requests)\n",
    "print(f\"Batch created: {message_batch.id}\")\n",
    "print(f\"Status: {message_batch.processing_status}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch msgbatch_01P7Tye2UXAGLm5k91td4geE processing status is ended\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "message_batch = client.messages.batches.retrieve(\n",
    "    \"msgbatch_01P7Tye2UXAGLm5k91td4geE\",\n",
    ")\n",
    "print(f\"Batch {message_batch.id} processing status is {message_batch.processing_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing content JSON: Expecting ',' delimiter: line 4 column 218 (char 291)\n",
      "Original content: Looking at this paragraph, I need to analyze whether the judge is applying legal principles to specific facts or merely discussing legal requirements in general terms.\n",
      "\n",
      "The paragraph states: \"First, i...\n",
      "Cleaned content: {\n",
      "    \"para_id\": \"ewhc_ch_2006_2612#para_85\",\n",
      "    \"if_law_applied\": true,\n",
      "    \"application_of_law_phrases\": [\"First, it seems to me that there must be a tri-partite agreement between the trustees, the...\n",
      "Error parsing content JSON: Expecting ',' delimiter: line 4 column 60 (char 136)\n",
      "Original content: {\n",
      "    \"para_id\": \"ewhc_admin_2014_3627#para_63\",\n",
      "    \"if_law_applied\": true,\n",
      "    \"application_of_law_phrases\": [\"That something may be \"useful information\" is hardly a basis for making it a mandatory ...\n",
      "Cleaned content: {\n",
      "    \"para_id\": \"ewhc_admin_2014_3627#para_63\",\n",
      "    \"if_law_applied\": true,\n",
      "    \"application_of_law_phrases\": [\"That something may be \"useful information\" is hardly a basis for making it a mandatory ...\n",
      "Error parsing content JSON: Expecting ',' delimiter: line 4 column 123 (char 196)\n",
      "Original content: \n",
      "{\n",
      "    \"para_id\": \"ewhc_ch_2016_2759#para_15\",\n",
      "    \"if_law_applied\": true,\n",
      "    \"application_of_law_phrases\": [\"although it may have been conventional at one time to state that other documents are \"by ...\n",
      "Cleaned content: {\n",
      "    \"para_id\": \"ewhc_ch_2016_2759#para_15\",\n",
      "    \"if_law_applied\": true,\n",
      "    \"application_of_law_phrases\": [\"although it may have been conventional at one time to state that other documents are \"by t...\n",
      "Error parsing content JSON: Expecting ',' delimiter: line 4 column 77 (char 151)\n",
      "Original content: {\n",
      "    \"para_id\": \"ewca_civ_2023_1000#para_56\",\n",
      "    \"if_law_applied\": true,\n",
      "    \"application_of_law_phrases\": [\"was the judge wrong not to define what \"racist\" meant in this context?\", \"My answer is th...\n",
      "Cleaned content: {\n",
      "    \"para_id\": \"ewca_civ_2023_1000#para_56\",\n",
      "    \"if_law_applied\": true,\n",
      "    \"application_of_law_phrases\": [\"was the judge wrong not to define what \"racist\" meant in this context?\", \"My answer is th...\n",
      "Found 4424 records in JSONL file\n",
      "Combined CSV has 4428 records\n",
      "Merged CSV saved to: ../data/final_test/disagreement_output.csv\n",
      "Merged DataFrame shape: (4428, 15)\n",
      "Sample of merged data:\n",
      "                     para_id if_law_applied confidence agreement_with\n",
      "0  ewhc_ch_2009_1229#para_13           True       High          Llama\n",
      "1  ewhc_ch_2009_1229#para_18           True       High          Llama\n",
      "2  ewhc_ch_2009_1229#para_21           True       High          Llama\n",
      "3  ewhc_ch_2009_1229#para_30          False       High         OpenAI\n",
      "4  ewhc_ch_2009_1229#para_35          False       High          Llama\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_uri</th>\n",
       "      <th>para_id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>references</th>\n",
       "      <th>if_law_applied</th>\n",
       "      <th>application_of_law_phrases</th>\n",
       "      <th>reason</th>\n",
       "      <th>if_law_applied_llama</th>\n",
       "      <th>application_of_law_phrases_llama</th>\n",
       "      <th>reason_llama</th>\n",
       "      <th>if_law_applied_claude</th>\n",
       "      <th>application_of_law_phrases_claude</th>\n",
       "      <th>reason_claude</th>\n",
       "      <th>confidence</th>\n",
       "      <th>agreement_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2009_1229#para_13</td>\n",
       "      <td>13. Turning to the relevant law, the starting ...</td>\n",
       "      <td>[{'text': 'section 6(1)', 'href': 'http://www....</td>\n",
       "      <td>True</td>\n",
       "      <td>['public authorities, such as the Revenue, whi...</td>\n",
       "      <td>The judge connects the statutory framework of ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph provides a general overview of ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>After careful analysis, I agree with Model B (...</td>\n",
       "      <td>High</td>\n",
       "      <td>Llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2009_1229#para_18</td>\n",
       "      <td>18. There is no hard and fast rule, submits Mr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>['the case law establishes that: (a) confident...</td>\n",
       "      <td>The paragraph applies principles from case law...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph discusses general legal princip...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>After careful analysis, Model B's classificati...</td>\n",
       "      <td>High</td>\n",
       "      <td>Llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2009_1229#para_21</td>\n",
       "      <td>21. The starting point is the long-established...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>['the burden lies on anybody who seeks to disp...</td>\n",
       "      <td>The paragraph discusses legal principles surro...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph discusses general principles an...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Model B's analysis is more accurate. This para...</td>\n",
       "      <td>High</td>\n",
       "      <td>Llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2009_1229#para_30</td>\n",
       "      <td>30. The footnotes to the above passage cite th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph discusses legal principles and ...</td>\n",
       "      <td>True</td>\n",
       "      <td>['Once a document has been read or referred to...</td>\n",
       "      <td>The paragraph applies legal principles regardi...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph primarily serves as a scholarly...</td>\n",
       "      <td>High</td>\n",
       "      <td>OpenAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2009_1229#para_35</td>\n",
       "      <td>35. It is relevant to bear in mind, I think, t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph discusses the public interest a...</td>\n",
       "      <td>True</td>\n",
       "      <td>['the public interest generally requires the p...</td>\n",
       "      <td>The judge applies the principle of open justic...</td>\n",
       "      <td>True</td>\n",
       "      <td>[the public interest generally requires the pr...</td>\n",
       "      <td>Model B's analysis is more accurate. While thi...</td>\n",
       "      <td>High</td>\n",
       "      <td>Llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewfc/2...</td>\n",
       "      <td>ewfc_2025_41#para_29</td>\n",
       "      <td>\\t    \\t 29.  \\t    \\t      \\t Mrs Odze comme...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>['as their legal father, it was his duty to do...</td>\n",
       "      <td>The judge applies the legal principle of paren...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph presents factual information ab...</td>\n",
       "      <td>True</td>\n",
       "      <td>[as their legal father, it was his duty to do ...</td>\n",
       "      <td>Model A's analysis is more accurate. The parag...</td>\n",
       "      <td>High</td>\n",
       "      <td>OpenAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewfc/2...</td>\n",
       "      <td>ewfc_2025_41#para_30</td>\n",
       "      <td>\\t    \\t 30.  \\t    \\t      \\t On the central...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>['it might have an emotional effect on [A] and...</td>\n",
       "      <td>The judge evaluates the potential impact of Mr...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph presents the expert opinion of ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Model B's analysis is correct. This paragraph ...</td>\n",
       "      <td>High</td>\n",
       "      <td>Llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewfc/2...</td>\n",
       "      <td>ewfc_2025_41#para_36</td>\n",
       "      <td>\\t    \\t 36.  \\t    \\t      \\t Mr Niven-Phill...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>['if I accede to Mr Jâ€™s application his liabil...</td>\n",
       "      <td>The paragraph discusses the potential financia...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph is a summary of arguments made ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph is primarily a summary of argum...</td>\n",
       "      <td>High</td>\n",
       "      <td>Llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewfc/2...</td>\n",
       "      <td>ewfc_2025_41#para_45</td>\n",
       "      <td>\\t    \\t 45.  \\t    \\t      \\t Therefore I am...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This statement reflects the judge's assessment...</td>\n",
       "      <td>True</td>\n",
       "      <td>['I am satisfied that if this application were...</td>\n",
       "      <td>The judge applies the legal principle of consi...</td>\n",
       "      <td>True</td>\n",
       "      <td>[I am satisfied that if this application were ...</td>\n",
       "      <td>Model B's analysis is more accurate. This para...</td>\n",
       "      <td>High</td>\n",
       "      <td>Llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewfc/2...</td>\n",
       "      <td>ewfc_2025_41#para_49</td>\n",
       "      <td>\\t    \\t 49.  \\t    \\t      \\t For completene...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph states the absence of public po...</td>\n",
       "      <td>True</td>\n",
       "      <td>['there is no public policy reason for not gra...</td>\n",
       "      <td>The judge applies the legal principle of publi...</td>\n",
       "      <td>True</td>\n",
       "      <td>[there is no public policy reason for not gran...</td>\n",
       "      <td>Model B's analysis is more accurate. While thi...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Llama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4428 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               case_uri  \\\n",
       "0     https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "1     https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "2     https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "3     https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "4     https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "...                                                 ...   \n",
       "4423  https://caselaw.nationalarchives.gov.uk/ewfc/2...   \n",
       "4424  https://caselaw.nationalarchives.gov.uk/ewfc/2...   \n",
       "4425  https://caselaw.nationalarchives.gov.uk/ewfc/2...   \n",
       "4426  https://caselaw.nationalarchives.gov.uk/ewfc/2...   \n",
       "4427  https://caselaw.nationalarchives.gov.uk/ewfc/2...   \n",
       "\n",
       "                        para_id  \\\n",
       "0     ewhc_ch_2009_1229#para_13   \n",
       "1     ewhc_ch_2009_1229#para_18   \n",
       "2     ewhc_ch_2009_1229#para_21   \n",
       "3     ewhc_ch_2009_1229#para_30   \n",
       "4     ewhc_ch_2009_1229#para_35   \n",
       "...                         ...   \n",
       "4423       ewfc_2025_41#para_29   \n",
       "4424       ewfc_2025_41#para_30   \n",
       "4425       ewfc_2025_41#para_36   \n",
       "4426       ewfc_2025_41#para_45   \n",
       "4427       ewfc_2025_41#para_49   \n",
       "\n",
       "                                             paragraphs  \\\n",
       "0     13. Turning to the relevant law, the starting ...   \n",
       "1     18. There is no hard and fast rule, submits Mr...   \n",
       "2     21. The starting point is the long-established...   \n",
       "3     30. The footnotes to the above passage cite th...   \n",
       "4     35. It is relevant to bear in mind, I think, t...   \n",
       "...                                                 ...   \n",
       "4423   \\t    \\t 29.  \\t    \\t      \\t Mrs Odze comme...   \n",
       "4424   \\t    \\t 30.  \\t    \\t      \\t On the central...   \n",
       "4425   \\t    \\t 36.  \\t    \\t      \\t Mr Niven-Phill...   \n",
       "4426   \\t    \\t 45.  \\t    \\t      \\t Therefore I am...   \n",
       "4427   \\t    \\t 49.  \\t    \\t      \\t For completene...   \n",
       "\n",
       "                                             references if_law_applied  \\\n",
       "0     [{'text': 'section 6(1)', 'href': 'http://www....           True   \n",
       "1                                                    []           True   \n",
       "2                                                    []           True   \n",
       "3                                                    []          False   \n",
       "4                                                    []          False   \n",
       "...                                                 ...            ...   \n",
       "4423                                                 []           True   \n",
       "4424                                                 []           True   \n",
       "4425                                                 []           True   \n",
       "4426                                                 []          False   \n",
       "4427                                                 []          False   \n",
       "\n",
       "                             application_of_law_phrases  \\\n",
       "0     ['public authorities, such as the Revenue, whi...   \n",
       "1     ['the case law establishes that: (a) confident...   \n",
       "2     ['the burden lies on anybody who seeks to disp...   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "4423  ['as their legal father, it was his duty to do...   \n",
       "4424  ['it might have an emotional effect on [A] and...   \n",
       "4425  ['if I accede to Mr Jâ€™s application his liabil...   \n",
       "4426                                                 []   \n",
       "4427                                                 []   \n",
       "\n",
       "                                                 reason if_law_applied_llama  \\\n",
       "0     The judge connects the statutory framework of ...                False   \n",
       "1     The paragraph applies principles from case law...                False   \n",
       "2     The paragraph discusses legal principles surro...                False   \n",
       "3     This paragraph discusses legal principles and ...                 True   \n",
       "4     This paragraph discusses the public interest a...                 True   \n",
       "...                                                 ...                  ...   \n",
       "4423  The judge applies the legal principle of paren...                False   \n",
       "4424  The judge evaluates the potential impact of Mr...                False   \n",
       "4425  The paragraph discusses the potential financia...                False   \n",
       "4426  This statement reflects the judge's assessment...                 True   \n",
       "4427  This paragraph states the absence of public po...                 True   \n",
       "\n",
       "                       application_of_law_phrases_llama  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3     ['Once a document has been read or referred to...   \n",
       "4     ['the public interest generally requires the p...   \n",
       "...                                                 ...   \n",
       "4423                                                 []   \n",
       "4424                                                 []   \n",
       "4425                                                 []   \n",
       "4426  ['I am satisfied that if this application were...   \n",
       "4427  ['there is no public policy reason for not gra...   \n",
       "\n",
       "                                           reason_llama if_law_applied_claude  \\\n",
       "0     This paragraph provides a general overview of ...                 False   \n",
       "1     This paragraph discusses general legal princip...                 False   \n",
       "2     This paragraph discusses general principles an...                 False   \n",
       "3     The paragraph applies legal principles regardi...                 False   \n",
       "4     The judge applies the principle of open justic...                  True   \n",
       "...                                                 ...                   ...   \n",
       "4423  This paragraph presents factual information ab...                  True   \n",
       "4424  This paragraph presents the expert opinion of ...                 False   \n",
       "4425  This paragraph is a summary of arguments made ...                 False   \n",
       "4426  The judge applies the legal principle of consi...                  True   \n",
       "4427  The judge applies the legal principle of publi...                  True   \n",
       "\n",
       "                      application_of_law_phrases_claude  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4     [the public interest generally requires the pr...   \n",
       "...                                                 ...   \n",
       "4423  [as their legal father, it was his duty to do ...   \n",
       "4424                                                 []   \n",
       "4425                                                 []   \n",
       "4426  [I am satisfied that if this application were ...   \n",
       "4427  [there is no public policy reason for not gran...   \n",
       "\n",
       "                                          reason_claude confidence  \\\n",
       "0     After careful analysis, I agree with Model B (...       High   \n",
       "1     After careful analysis, Model B's classificati...       High   \n",
       "2     Model B's analysis is more accurate. This para...       High   \n",
       "3     This paragraph primarily serves as a scholarly...       High   \n",
       "4     Model B's analysis is more accurate. While thi...       High   \n",
       "...                                                 ...        ...   \n",
       "4423  Model A's analysis is more accurate. The parag...       High   \n",
       "4424  Model B's analysis is correct. This paragraph ...       High   \n",
       "4425  This paragraph is primarily a summary of argum...       High   \n",
       "4426  Model B's analysis is more accurate. This para...       High   \n",
       "4427  Model B's analysis is more accurate. While thi...     Medium   \n",
       "\n",
       "     agreement_with  \n",
       "0             Llama  \n",
       "1             Llama  \n",
       "2             Llama  \n",
       "3            OpenAI  \n",
       "4             Llama  \n",
       "...             ...  \n",
       "4423         OpenAI  \n",
       "4424          Llama  \n",
       "4425          Llama  \n",
       "4426          Llama  \n",
       "4427          Llama  \n",
       "\n",
       "[4428 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import extract_data_from_jsonl\n",
    "combined_csv_path = '../data/final_test/disagreement.csv'\n",
    "output_jsonl_path = '../data/final_test/disagreement_results.jsonl'\n",
    "output_csv_path = '../data/final_test/disagreement_output.csv'\n",
    "extract_data_from_jsonl.merge_combined_csv_and_claude_jsonl(combined_csv_path, output_jsonl_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output_csv_path = '../data/final_test/disagreement_output.csv'\n",
    "df_disagreement = pd.read_csv(output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_uri', 'para_id', 'paragraphs', 'references', 'if_law_applied',\n",
       "       'application_of_law_phrases', 'reason', 'if_law_applied_llama',\n",
       "       'application_of_law_phrases_llama', 'reason_llama',\n",
       "       'if_law_applied_claude', 'application_of_law_phrases_claude',\n",
       "       'reason_claude', 'confidence', 'agreement_with'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disagreement.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement_with\n",
       "Llama     3569\n",
       "OpenAI     849\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disagreement['agreement_with'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_uri</th>\n",
       "      <th>para_id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>references</th>\n",
       "      <th>if_law_applied</th>\n",
       "      <th>application_of_law_phrases</th>\n",
       "      <th>reason</th>\n",
       "      <th>if_law_applied_llama</th>\n",
       "      <th>application_of_law_phrases_llama</th>\n",
       "      <th>reason_llama</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 72</th>\n",
       "      <th>Unnamed: 73</th>\n",
       "      <th>Unnamed: 74</th>\n",
       "      <th>Unnamed: 75</th>\n",
       "      <th>Unnamed: 76</th>\n",
       "      <th>Unnamed: 77</th>\n",
       "      <th>Unnamed: 78</th>\n",
       "      <th>Unnamed: 79</th>\n",
       "      <th>Unnamed: 80</th>\n",
       "      <th>Unnamed: 81</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/a...</td>\n",
       "      <td>ewhc_admin_2015_1641#para_2</td>\n",
       "      <td>2. The claimantsâ€™ case proceeds under two broa...</td>\n",
       "      <td>[{'text': 'Asylum and Immigration (Treatment o...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>['incompatible with European Union law and sho...</td>\n",
       "      <td>The paragraph discusses specific legal argumen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               case_uri  \\\n",
       "2437  https://caselaw.nationalarchives.gov.uk/ewhc/a...   \n",
       "\n",
       "                          para_id  \\\n",
       "2437  ewhc_admin_2015_1641#para_2   \n",
       "\n",
       "                                             paragraphs  \\\n",
       "2437  2. The claimantsâ€™ case proceeds under two broa...   \n",
       "\n",
       "                                             references if_law_applied  \\\n",
       "2437  [{'text': 'Asylum and Immigration (Treatment o...           TRUE   \n",
       "\n",
       "                             application_of_law_phrases  \\\n",
       "2437  ['incompatible with European Union law and sho...   \n",
       "\n",
       "                                                 reason if_law_applied_llama  \\\n",
       "2437  The paragraph discusses specific legal argumen...                  NaN   \n",
       "\n",
       "     application_of_law_phrases_llama reason_llama  ... Unnamed: 72  \\\n",
       "2437                              NaN          NaN  ...         NaN   \n",
       "\n",
       "     Unnamed: 73 Unnamed: 74 Unnamed: 75 Unnamed: 76 Unnamed: 77 Unnamed: 78  \\\n",
       "2437         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     Unnamed: 79 Unnamed: 80 Unnamed: 81  \n",
       "2437         NaN         NaN         NaN  \n",
       "\n",
       "[1 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disagreement[df_disagreement['agreement_with']==\"Neither - both models incorrectly classified this paragraph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of case laws: 443\n",
      "Total number of paragraphs: 24537\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "disagrement_after_processing_path = '../data/final_test/disagreement_output.csv'\n",
    "agrement_after_processing_path = '../data/final_test/agreement.csv'\n",
    "\n",
    "df_disagreement = pd.read_csv(disagrement_after_processing_path)\n",
    "df_agreement = pd.read_csv(agrement_after_processing_path)\n",
    "\n",
    "Combined_cases = pd.concat([df_disagreement, df_agreement])\n",
    "\n",
    "#Total caselaws\n",
    "total_cases = Combined_cases['case_uri'].nunique()\n",
    "print(f\"Total number of case laws: {total_cases}\")\n",
    "\n",
    "#Total pargraphs\n",
    "total_paragraphs = len(Combined_cases)\n",
    "print(f\"Total number of paragraphs: {total_paragraphs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_uri</th>\n",
       "      <th>para_id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>references</th>\n",
       "      <th>if_law_applied</th>\n",
       "      <th>application_of_law_phrases</th>\n",
       "      <th>reason</th>\n",
       "      <th>if_law_applied_llama</th>\n",
       "      <th>application_of_law_phrases_llama</th>\n",
       "      <th>reason_llama</th>\n",
       "      <th>if_law_applied_claude</th>\n",
       "      <th>application_of_law_phrases_claude</th>\n",
       "      <th>reason_claude</th>\n",
       "      <th>confidence</th>\n",
       "      <th>agreement_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://caselaw.nationalarchives.gov.uk/ewhc/c...</td>\n",
       "      <td>ewhc_ch_2009_1229#para_13</td>\n",
       "      <td>13. Turning to the relevant law, the starting ...</td>\n",
       "      <td>[{'text': 'section 6(1)', 'href': 'http://www....</td>\n",
       "      <td>True</td>\n",
       "      <td>['public authorities, such as the Revenue, whi...</td>\n",
       "      <td>The judge connects the statutory framework of ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This paragraph provides a general overview of ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>After careful analysis, I agree with Model B (...</td>\n",
       "      <td>High</td>\n",
       "      <td>Llama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            case_uri  \\\n",
       "0  https://caselaw.nationalarchives.gov.uk/ewhc/c...   \n",
       "\n",
       "                     para_id  \\\n",
       "0  ewhc_ch_2009_1229#para_13   \n",
       "\n",
       "                                          paragraphs  \\\n",
       "0  13. Turning to the relevant law, the starting ...   \n",
       "\n",
       "                                          references if_law_applied  \\\n",
       "0  [{'text': 'section 6(1)', 'href': 'http://www....           True   \n",
       "\n",
       "                          application_of_law_phrases  \\\n",
       "0  ['public authorities, such as the Revenue, whi...   \n",
       "\n",
       "                                              reason if_law_applied_llama  \\\n",
       "0  The judge connects the statutory framework of ...                False   \n",
       "\n",
       "  application_of_law_phrases_llama  \\\n",
       "0                               []   \n",
       "\n",
       "                                        reason_llama if_law_applied_claude  \\\n",
       "0  This paragraph provides a general overview of ...                 False   \n",
       "\n",
       "  application_of_law_phrases_claude  \\\n",
       "0                                []   \n",
       "\n",
       "                                       reason_claude confidence agreement_with  \n",
       "0  After careful analysis, I agree with Model B (...       High          Llama  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Combined_cases.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819578595590333\n",
      "0.18042140440966703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Number of paragraphs with agreement with LLM also percentage\n",
    "print(len(df_agreement)/len(Combined_cases))\n",
    "#Number of paragraphs with disagreement with LLM also percentage\n",
    "print(len(df_disagreement)/len(Combined_cases))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.819578595590333 + 0.18042140440966703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement_with\n",
       "Llama     80.62\n",
       "OpenAI    19.18\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_disagreement['agreement_with'].value_counts() / len(df_disagreement) * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement_with\n",
       "Llama     3569\n",
       "OpenAI     849\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disagreement['agreement_with'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v6/ylm2sy9s6ygbm9wjf__vgfqw0000gn/T/ipykernel_47860/1627650295.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  Combined_cases['final_annotation'] = Combined_cases['if_law_applied_claude'].fillna(Combined_cases['if_law_applied_llama'])\n"
     ]
    }
   ],
   "source": [
    "Combined_cases['final_annotation'] = Combined_cases['if_law_applied_claude'].fillna(Combined_cases['if_law_applied_llama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_annotation\n",
       "False    15314\n",
       "True      9223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Combined_cases['final_annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37588132208501446"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9223 /(9223+15314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load combined_llama_output.csv\n",
    "import pandas as pd\n",
    "combined_llama_output_path = '../data/final_test/combined_llama_output.csv'\n",
    "df_llama = pd.read_csv(combined_llama_output_path)\n",
    "\n",
    "# load combined_openai_output.csv\n",
    "combined_openai_output_path = '../data/final_test/combined_openai_output.csv'\n",
    "df_openai = pd.read_csv(combined_openai_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if_law_applied\n",
       "False    62.72\n",
       "True     37.11\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_llama['if_law_applied'].value_counts() /len(df_llama) * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if_law_applied\n",
       "False    56.92\n",
       "True     42.96\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_openai['if_law_applied'].value_counts() /len(df_openai) * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_annotation\n",
       "False    62.41\n",
       "True     37.59\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(Combined_cases['final_annotation'].value_counts() /len(Combined_cases) * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confidence\n",
       "High      4377\n",
       "Medium      41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disagreement['confidence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_cases.to_csv('../data/final_test/combined_cases_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "positve_cases_df = Combined_cases[Combined_cases['final_annotation']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positve_cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positve_cases_df.case_uri.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "positve_cases_df.to_csv('../data/final_test/positve_cases.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Odyssey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
